{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from src.analyse_utils_pytorch import plot_history\n",
    "from src.vanilla_cnn_pytorch import VaniliaCNN\n",
    "from src.model_utils_pytorch import train_model, save_model\n",
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/1599:\ttrain Loss: 2.3026 Acc: 0.2458\tval Loss: 2.3025 Acc: 0.4000\t\n",
      "Epoch 1/1599:\ttrain Loss: 2.3023 Acc: 0.3559\tval Loss: 2.3020 Acc: 0.2333\t\n",
      "Epoch 2/1599:\ttrain Loss: 2.3009 Acc: 0.3559\tval Loss: 2.2991 Acc: 0.3333\t\n",
      "Epoch 3/1599:\ttrain Loss: 2.2931 Acc: 0.3983\tval Loss: 2.2820 Acc: 0.4333\t\n",
      "Epoch 4/1599:\ttrain Loss: 2.2657 Acc: 0.4153\tval Loss: 2.2309 Acc: 0.2667\t\n",
      "Epoch 5/1599:\ttrain Loss: 2.2164 Acc: 0.3983\tval Loss: 2.1710 Acc: 0.3667\t\n",
      "Epoch 6/1599:\ttrain Loss: 2.1733 Acc: 0.4237\tval Loss: 2.1288 Acc: 0.4000\t\n",
      "Epoch 7/1599:\ttrain Loss: 2.1399 Acc: 0.4364\tval Loss: 2.1290 Acc: 0.5000\t\n",
      "Epoch 8/1599:\ttrain Loss: 2.1397 Acc: 0.3729\tval Loss: 2.1130 Acc: 0.4333\t\n",
      "Epoch 9/1599:\ttrain Loss: 2.1216 Acc: 0.4195\tval Loss: 2.1399 Acc: 0.4667\t\n",
      "Epoch 10/1599:\ttrain Loss: 2.1363 Acc: 0.4195\tval Loss: 2.1564 Acc: 0.4000\t\n",
      "Epoch 11/1599:\ttrain Loss: 2.1327 Acc: 0.3771\tval Loss: 2.1723 Acc: 0.3667\t\n",
      "Epoch 12/1599:\ttrain Loss: 2.1337 Acc: 0.3559\tval Loss: 2.1495 Acc: 0.4000\t\n",
      "Epoch 13/1599:\ttrain Loss: 2.1536 Acc: 0.3475\tval Loss: 2.1212 Acc: 0.4000\t\n",
      "Epoch 14/1599:\ttrain Loss: 2.1210 Acc: 0.3814\tval Loss: 2.1529 Acc: 0.4000\t\n",
      "Epoch 15/1599:\ttrain Loss: 2.1312 Acc: 0.3898\tval Loss: 2.2101 Acc: 0.4000\t\n",
      "Epoch 16/1599:\ttrain Loss: 2.1209 Acc: 0.3856\tval Loss: 2.1876 Acc: 0.3333\t\n",
      "Epoch 17/1599:\ttrain Loss: 2.1295 Acc: 0.3856\tval Loss: 2.1906 Acc: 0.3667\t\n",
      "Epoch 18/1599:\ttrain Loss: 2.1351 Acc: 0.3983\tval Loss: 2.1708 Acc: 0.3667\t\n",
      "Epoch 19/1599:\ttrain Loss: 2.1202 Acc: 0.4068\tval Loss: 2.1428 Acc: 0.4333\t\n",
      "Epoch 20/1599:\ttrain Loss: 2.1172 Acc: 0.4237\tval Loss: 2.1812 Acc: 0.5000\t\n",
      "Epoch 21/1599:\ttrain Loss: 2.1329 Acc: 0.4068\tval Loss: 2.1483 Acc: 0.3333\t\n",
      "Epoch 22/1599:\ttrain Loss: 2.1135 Acc: 0.4322\tval Loss: 2.1426 Acc: 0.3667\t\n",
      "Epoch 23/1599:\ttrain Loss: 2.1320 Acc: 0.3771\tval Loss: 2.1177 Acc: 0.4000\t\n",
      "Epoch 24/1599:\ttrain Loss: 2.1441 Acc: 0.3686\tval Loss: 2.1277 Acc: 0.4333\t\n",
      "Epoch 25/1599:\ttrain Loss: 2.1183 Acc: 0.4280\tval Loss: 2.1590 Acc: 0.5000\t\n",
      "Epoch 26/1599:\ttrain Loss: 2.1035 Acc: 0.4195\tval Loss: 2.1194 Acc: 0.4333\t\n",
      "Epoch 27/1599:\ttrain Loss: 2.1242 Acc: 0.4153\tval Loss: 2.1371 Acc: 0.4000\t\n",
      "Epoch 28/1599:\ttrain Loss: 2.1275 Acc: 0.4280\tval Loss: 2.1200 Acc: 0.4667\t\n",
      "Epoch 29/1599:\ttrain Loss: 2.1079 Acc: 0.4449\tval Loss: 2.1173 Acc: 0.4333\t\n",
      "Epoch 30/1599:\ttrain Loss: 2.1074 Acc: 0.4534\tval Loss: 2.0984 Acc: 0.4667\t\n",
      "Epoch 31/1599:\ttrain Loss: 2.1063 Acc: 0.4703\tval Loss: 2.1006 Acc: 0.4667\t\n",
      "Epoch 32/1599:\ttrain Loss: 2.1019 Acc: 0.4576\tval Loss: 2.1348 Acc: 0.4667\t\n",
      "Epoch 33/1599:\ttrain Loss: 2.0997 Acc: 0.4492\tval Loss: 2.1560 Acc: 0.4333\t\n",
      "Epoch 34/1599:\ttrain Loss: 2.1139 Acc: 0.4364\tval Loss: 2.1174 Acc: 0.5000\t\n",
      "Epoch 35/1599:\ttrain Loss: 2.1034 Acc: 0.4407\tval Loss: 2.0947 Acc: 0.5000\t\n",
      "Epoch 36/1599:\ttrain Loss: 2.0906 Acc: 0.4492\tval Loss: 2.0854 Acc: 0.4333\t\n",
      "Epoch 37/1599:\ttrain Loss: 2.0982 Acc: 0.4619\tval Loss: 2.0929 Acc: 0.5000\t\n",
      "Epoch 38/1599:\ttrain Loss: 2.0982 Acc: 0.4534\tval Loss: 2.1250 Acc: 0.4667\t\n",
      "Epoch 39/1599:\ttrain Loss: 2.1084 Acc: 0.4322\tval Loss: 2.1466 Acc: 0.4333\t\n",
      "Epoch 40/1599:\ttrain Loss: 2.0931 Acc: 0.4788\tval Loss: 2.1173 Acc: 0.5000\t\n",
      "Epoch 41/1599:\ttrain Loss: 2.1229 Acc: 0.4449\tval Loss: 2.1750 Acc: 0.4000\t\n",
      "Epoch 42/1599:\ttrain Loss: 2.1068 Acc: 0.4831\tval Loss: 2.1597 Acc: 0.4000\t\n",
      "Epoch 43/1599:\ttrain Loss: 2.1099 Acc: 0.5085\tval Loss: 2.1117 Acc: 0.4333\t\n",
      "Epoch 44/1599:\ttrain Loss: 2.0906 Acc: 0.5254\tval Loss: 2.1556 Acc: 0.5000\t\n",
      "Epoch 45/1599:\ttrain Loss: 2.1086 Acc: 0.4534\tval Loss: 2.1182 Acc: 0.4333\t\n",
      "Epoch 46/1599:\ttrain Loss: 2.0940 Acc: 0.4873\tval Loss: 2.0967 Acc: 0.5000\t\n",
      "Epoch 47/1599:\ttrain Loss: 2.0827 Acc: 0.5127\tval Loss: 2.0883 Acc: 0.4667\t\n",
      "Epoch 48/1599:\ttrain Loss: 2.0990 Acc: 0.4703\tval Loss: 2.1245 Acc: 0.4667\t\n",
      "Epoch 49/1599:\ttrain Loss: 2.1060 Acc: 0.5000\tval Loss: 2.1111 Acc: 0.4667\t\n",
      "Epoch 50/1599:\ttrain Loss: 2.1230 Acc: 0.4873\tval Loss: 2.1082 Acc: 0.4333\t\n",
      "Epoch 51/1599:\ttrain Loss: 2.0961 Acc: 0.4831\tval Loss: 2.1194 Acc: 0.4667\t\n",
      "Epoch 52/1599:\ttrain Loss: 2.0930 Acc: 0.4788\tval Loss: 2.0906 Acc: 0.4333\t\n",
      "Epoch 53/1599:\ttrain Loss: 2.1017 Acc: 0.5085\tval Loss: 2.1063 Acc: 0.4667\t\n",
      "Epoch 54/1599:\ttrain Loss: 2.0837 Acc: 0.5169\tval Loss: 2.0883 Acc: 0.4667\t\n",
      "Epoch 55/1599:\ttrain Loss: 2.1077 Acc: 0.4873\tval Loss: 2.0920 Acc: 0.5000\t\n",
      "Epoch 56/1599:\ttrain Loss: 2.0919 Acc: 0.4534\tval Loss: 2.1026 Acc: 0.5000\t\n",
      "Epoch 57/1599:\ttrain Loss: 2.1053 Acc: 0.4576\tval Loss: 2.1479 Acc: 0.4333\t\n",
      "Epoch 58/1599:\ttrain Loss: 2.1013 Acc: 0.4280\tval Loss: 2.1221 Acc: 0.4667\t\n",
      "Epoch 59/1599:\ttrain Loss: 2.0827 Acc: 0.4746\tval Loss: 2.1409 Acc: 0.3667\t\n",
      "Epoch 60/1599:\ttrain Loss: 2.1026 Acc: 0.4831\tval Loss: 2.1173 Acc: 0.4667\t\n",
      "Epoch 61/1599:\ttrain Loss: 2.1086 Acc: 0.4534\tval Loss: 2.1160 Acc: 0.4667\t\n",
      "Epoch 62/1599:\ttrain Loss: 2.1001 Acc: 0.4576\tval Loss: 2.1133 Acc: 0.4333\t\n",
      "Epoch 63/1599:\ttrain Loss: 2.1080 Acc: 0.4703\tval Loss: 2.1204 Acc: 0.4333\t\n",
      "Epoch 64/1599:\ttrain Loss: 2.0920 Acc: 0.4534\tval Loss: 2.1469 Acc: 0.4667\t\n",
      "Epoch 65/1599:\ttrain Loss: 2.0882 Acc: 0.4958\tval Loss: 2.1204 Acc: 0.5000\t\n",
      "Epoch 66/1599:\ttrain Loss: 2.0843 Acc: 0.4915\tval Loss: 2.1203 Acc: 0.4667\t\n",
      "Epoch 67/1599:\ttrain Loss: 2.0783 Acc: 0.5212\tval Loss: 2.1186 Acc: 0.4667\t\n",
      "Epoch 68/1599:\ttrain Loss: 2.0997 Acc: 0.4576\tval Loss: 2.1215 Acc: 0.4667\t\n",
      "Epoch 69/1599:\ttrain Loss: 2.0941 Acc: 0.5127\tval Loss: 2.1406 Acc: 0.5000\t\n",
      "Epoch 70/1599:\ttrain Loss: 2.0972 Acc: 0.5127\tval Loss: 2.0878 Acc: 0.5333\t\n",
      "Epoch 71/1599:\ttrain Loss: 2.0769 Acc: 0.5042\tval Loss: 2.0915 Acc: 0.4667\t\n",
      "Epoch 72/1599:\ttrain Loss: 2.0854 Acc: 0.5339\tval Loss: 2.1346 Acc: 0.5000\t\n",
      "Epoch 73/1599:\ttrain Loss: 2.0899 Acc: 0.5339\tval Loss: 2.1439 Acc: 0.5000\t\n",
      "Epoch 74/1599:\ttrain Loss: 2.0913 Acc: 0.5212\tval Loss: 2.0997 Acc: 0.4333\t\n",
      "Epoch 75/1599:\ttrain Loss: 2.1024 Acc: 0.5212\tval Loss: 2.1196 Acc: 0.4000\t\n",
      "Epoch 76/1599:\ttrain Loss: 2.0726 Acc: 0.5551\tval Loss: 2.0906 Acc: 0.4333\t\n",
      "Epoch 77/1599:\ttrain Loss: 2.1005 Acc: 0.4915\tval Loss: 2.1198 Acc: 0.4667\t\n",
      "Epoch 78/1599:\ttrain Loss: 2.0781 Acc: 0.5593\tval Loss: 2.1684 Acc: 0.4333\t\n",
      "Epoch 79/1599:\ttrain Loss: 2.0982 Acc: 0.5000\tval Loss: 2.1219 Acc: 0.4000\t\n",
      "Epoch 80/1599:\ttrain Loss: 2.0805 Acc: 0.5339\tval Loss: 2.0968 Acc: 0.5000\t\n",
      "Epoch 81/1599:\ttrain Loss: 2.0971 Acc: 0.5127\tval Loss: 2.0919 Acc: 0.4667\t\n",
      "Epoch 82/1599:\ttrain Loss: 2.0946 Acc: 0.5000\tval Loss: 2.0909 Acc: 0.4333\t\n",
      "Epoch 83/1599:\ttrain Loss: 2.0957 Acc: 0.5212\tval Loss: 2.0917 Acc: 0.4333\t\n",
      "Epoch 84/1599:\ttrain Loss: 2.0927 Acc: 0.5042\tval Loss: 2.0868 Acc: 0.4000\t\n",
      "Epoch 85/1599:\ttrain Loss: 2.0817 Acc: 0.5085\tval Loss: 2.0960 Acc: 0.4333\t\n",
      "Epoch 86/1599:\ttrain Loss: 2.0785 Acc: 0.5169\tval Loss: 2.0864 Acc: 0.5000\t\n",
      "Epoch 87/1599:\ttrain Loss: 2.0853 Acc: 0.5424\tval Loss: 2.1018 Acc: 0.4667\t\n",
      "Epoch 88/1599:\ttrain Loss: 2.0860 Acc: 0.5127\tval Loss: 2.1092 Acc: 0.4667\t\n",
      "Epoch 89/1599:\ttrain Loss: 2.0940 Acc: 0.5085\tval Loss: 2.0983 Acc: 0.5333\t\n",
      "Epoch 90/1599:\ttrain Loss: 2.0762 Acc: 0.5254\tval Loss: 2.1178 Acc: 0.4667\t\n",
      "Epoch 91/1599:\ttrain Loss: 2.0852 Acc: 0.5339\tval Loss: 2.1171 Acc: 0.4333\t\n",
      "Epoch 92/1599:\ttrain Loss: 2.0907 Acc: 0.5212\tval Loss: 2.0866 Acc: 0.4667\t\n",
      "Epoch 93/1599:\ttrain Loss: 2.0826 Acc: 0.5042\tval Loss: 2.1177 Acc: 0.4333\t\n",
      "Epoch 94/1599:\ttrain Loss: 2.1078 Acc: 0.5169\tval Loss: 2.1219 Acc: 0.4667\t\n",
      "Epoch 95/1599:\ttrain Loss: 2.0899 Acc: 0.5381\tval Loss: 2.1037 Acc: 0.4667\t\n",
      "Epoch 96/1599:\ttrain Loss: 2.0915 Acc: 0.5466\tval Loss: 2.0905 Acc: 0.4000\t\n",
      "Epoch 97/1599:\ttrain Loss: 2.0987 Acc: 0.4873\tval Loss: 2.0936 Acc: 0.4333\t\n",
      "Epoch 98/1599:\ttrain Loss: 2.0715 Acc: 0.5297\tval Loss: 2.0811 Acc: 0.4667\t\n",
      "Epoch 99/1599:\ttrain Loss: 2.0577 Acc: 0.5551\tval Loss: 2.0891 Acc: 0.4667\t\n",
      "Epoch 100/1599:\ttrain Loss: 2.0866 Acc: 0.5424\tval Loss: 2.0979 Acc: 0.4333\t\n",
      "Epoch 101/1599:\ttrain Loss: 2.0591 Acc: 0.5551\tval Loss: 2.0986 Acc: 0.4333\t\n",
      "Epoch 102/1599:\ttrain Loss: 2.0966 Acc: 0.5085\tval Loss: 2.0957 Acc: 0.4333\t\n",
      "Epoch 103/1599:\ttrain Loss: 2.0868 Acc: 0.5636\tval Loss: 2.0920 Acc: 0.4333\t\n",
      "Epoch 104/1599:\ttrain Loss: 2.0619 Acc: 0.6017\tval Loss: 2.0895 Acc: 0.5000\t\n",
      "Epoch 105/1599:\ttrain Loss: 2.0889 Acc: 0.5466\tval Loss: 2.0863 Acc: 0.4667\t\n",
      "Epoch 106/1599:\ttrain Loss: 2.0980 Acc: 0.5127\tval Loss: 2.0854 Acc: 0.5667\t\n",
      "Epoch 107/1599:\ttrain Loss: 2.0861 Acc: 0.5466\tval Loss: 2.0871 Acc: 0.5000\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 108/1599:\ttrain Loss: 2.0653 Acc: 0.5508\tval Loss: 2.1035 Acc: 0.5000\t\n",
      "Epoch 109/1599:\ttrain Loss: 2.0978 Acc: 0.5339\tval Loss: 2.0899 Acc: 0.5000\t\n",
      "Epoch 110/1599:\ttrain Loss: 2.0808 Acc: 0.5720\tval Loss: 2.1042 Acc: 0.5333\t\n",
      "Epoch 111/1599:\ttrain Loss: 2.0727 Acc: 0.5890\tval Loss: 2.0807 Acc: 0.5333\t\n",
      "Epoch 112/1599:\ttrain Loss: 2.0909 Acc: 0.5466\tval Loss: 2.1272 Acc: 0.4667\t\n",
      "Epoch 113/1599:\ttrain Loss: 2.0771 Acc: 0.5381\tval Loss: 2.0993 Acc: 0.4333\t\n",
      "Epoch 114/1599:\ttrain Loss: 2.0705 Acc: 0.5508\tval Loss: 2.0996 Acc: 0.4333\t\n",
      "Epoch 115/1599:\ttrain Loss: 2.0759 Acc: 0.5254\tval Loss: 2.1076 Acc: 0.4667\t\n",
      "Epoch 116/1599:\ttrain Loss: 2.0730 Acc: 0.5466\tval Loss: 2.0905 Acc: 0.4667\t\n",
      "Epoch 117/1599:\ttrain Loss: 2.1006 Acc: 0.5000\tval Loss: 2.1079 Acc: 0.4667\t\n",
      "Epoch 118/1599:\ttrain Loss: 2.0766 Acc: 0.5381\tval Loss: 2.1149 Acc: 0.4667\t\n",
      "Epoch 119/1599:\ttrain Loss: 2.1008 Acc: 0.4788\tval Loss: 2.1373 Acc: 0.4000\t\n",
      "Epoch 120/1599:\ttrain Loss: 2.0779 Acc: 0.5042\tval Loss: 2.0926 Acc: 0.5667\t\n",
      "Epoch 121/1599:\ttrain Loss: 2.0721 Acc: 0.5127\tval Loss: 2.0967 Acc: 0.4667\t\n",
      "Epoch 122/1599:\ttrain Loss: 2.0820 Acc: 0.5127\tval Loss: 2.1209 Acc: 0.4000\t\n",
      "Epoch 123/1599:\ttrain Loss: 2.0777 Acc: 0.5085\tval Loss: 2.1378 Acc: 0.4000\t\n",
      "Epoch 124/1599:\ttrain Loss: 2.0732 Acc: 0.5254\tval Loss: 2.0871 Acc: 0.4333\t\n",
      "Epoch 125/1599:\ttrain Loss: 2.0783 Acc: 0.5297\tval Loss: 2.1204 Acc: 0.4667\t\n",
      "Epoch 126/1599:\ttrain Loss: 2.0827 Acc: 0.5381\tval Loss: 2.0886 Acc: 0.5667\t\n",
      "Epoch 127/1599:\ttrain Loss: 2.0895 Acc: 0.5339\tval Loss: 2.0856 Acc: 0.5000\t\n",
      "Epoch 128/1599:\ttrain Loss: 2.1035 Acc: 0.5127\tval Loss: 2.0631 Acc: 0.5667\t\n",
      "Epoch 129/1599:\ttrain Loss: 2.0914 Acc: 0.5212\tval Loss: 2.0832 Acc: 0.5667\t\n",
      "Epoch 130/1599:\ttrain Loss: 2.0771 Acc: 0.5508\tval Loss: 2.1014 Acc: 0.5000\t\n",
      "Epoch 131/1599:\ttrain Loss: 2.1138 Acc: 0.4661\tval Loss: 2.0697 Acc: 0.4667\t\n",
      "Epoch 132/1599:\ttrain Loss: 2.0901 Acc: 0.5297\tval Loss: 2.0875 Acc: 0.4667\t\n",
      "Epoch 133/1599:\ttrain Loss: 2.1167 Acc: 0.4746\tval Loss: 2.0874 Acc: 0.5333\t\n",
      "Epoch 134/1599:\ttrain Loss: 2.0789 Acc: 0.5169\tval Loss: 2.0848 Acc: 0.4667\t\n",
      "Epoch 135/1599:\ttrain Loss: 2.0945 Acc: 0.5551\tval Loss: 2.0879 Acc: 0.4333\t\n",
      "Epoch 136/1599:\ttrain Loss: 2.0991 Acc: 0.4576\tval Loss: 2.0778 Acc: 0.5333\t\n",
      "Epoch 137/1599:\ttrain Loss: 2.0821 Acc: 0.5212\tval Loss: 2.1062 Acc: 0.4333\t\n",
      "Epoch 138/1599:\ttrain Loss: 2.0802 Acc: 0.5212\tval Loss: 2.0887 Acc: 0.4667\t\n",
      "Epoch 139/1599:\ttrain Loss: 2.0899 Acc: 0.5212\tval Loss: 2.0977 Acc: 0.4667\t\n",
      "Epoch 140/1599:\ttrain Loss: 2.0833 Acc: 0.5593\tval Loss: 2.1336 Acc: 0.4667\t\n",
      "Epoch 141/1599:\ttrain Loss: 2.0994 Acc: 0.5212\tval Loss: 2.0899 Acc: 0.4333\t\n",
      "Epoch 142/1599:\ttrain Loss: 2.0910 Acc: 0.5127\tval Loss: 2.1133 Acc: 0.5000\t\n",
      "Epoch 143/1599:\ttrain Loss: 2.0817 Acc: 0.5466\tval Loss: 2.0878 Acc: 0.5000\t\n",
      "Epoch 144/1599:\ttrain Loss: 2.0590 Acc: 0.5593\tval Loss: 2.0572 Acc: 0.4667\t\n",
      "Epoch 145/1599:\ttrain Loss: 2.0608 Acc: 0.5890\tval Loss: 2.0851 Acc: 0.5333\t\n",
      "Epoch 146/1599:\ttrain Loss: 2.0577 Acc: 0.5805\tval Loss: 2.0842 Acc: 0.5000\t\n",
      "Epoch 147/1599:\ttrain Loss: 2.0834 Acc: 0.5508\tval Loss: 2.0899 Acc: 0.5333\t\n",
      "Epoch 148/1599:\ttrain Loss: 2.0846 Acc: 0.5381\tval Loss: 2.0873 Acc: 0.5000\t\n",
      "Epoch 149/1599:\ttrain Loss: 2.0853 Acc: 0.5720\tval Loss: 2.0859 Acc: 0.6000\t\n",
      "Epoch 150/1599:\ttrain Loss: 2.0640 Acc: 0.5678\tval Loss: 2.0774 Acc: 0.5333\t\n",
      "Epoch 151/1599:\ttrain Loss: 2.0547 Acc: 0.6186\tval Loss: 2.0808 Acc: 0.5000\t\n",
      "Epoch 152/1599:\ttrain Loss: 2.1026 Acc: 0.5678\tval Loss: 2.0845 Acc: 0.4667\t\n",
      "Epoch 153/1599:\ttrain Loss: 2.0803 Acc: 0.5593\tval Loss: 2.0867 Acc: 0.5000\t\n",
      "Epoch 154/1599:\ttrain Loss: 2.0842 Acc: 0.5339\tval Loss: 2.0869 Acc: 0.5000\t\n",
      "Epoch 155/1599:\ttrain Loss: 2.0733 Acc: 0.6229\tval Loss: 2.0801 Acc: 0.5333\t\n",
      "Epoch 156/1599:\ttrain Loss: 2.0991 Acc: 0.5169\tval Loss: 2.2157 Acc: 0.3333\t\n",
      "Epoch 157/1599:\ttrain Loss: 2.1408 Acc: 0.4831\tval Loss: 2.0950 Acc: 0.4667\t\n",
      "Epoch 158/1599:\ttrain Loss: 2.0891 Acc: 0.5424\tval Loss: 2.0854 Acc: 0.5333\t\n",
      "Epoch 159/1599:\ttrain Loss: 2.1084 Acc: 0.5254\tval Loss: 2.0879 Acc: 0.5000\t\n",
      "Epoch 160/1599:\ttrain Loss: 2.0929 Acc: 0.5424\tval Loss: 2.0895 Acc: 0.4333\t\n",
      "Epoch 161/1599:\ttrain Loss: 2.0797 Acc: 0.5636\tval Loss: 2.0851 Acc: 0.5000\t\n",
      "Epoch 162/1599:\ttrain Loss: 2.0906 Acc: 0.5466\tval Loss: 2.1071 Acc: 0.4667\t\n",
      "Epoch 163/1599:\ttrain Loss: 2.0795 Acc: 0.5720\tval Loss: 2.0901 Acc: 0.4667\t\n",
      "Epoch 164/1599:\ttrain Loss: 2.0786 Acc: 0.5636\tval Loss: 2.1157 Acc: 0.4333\t\n",
      "Epoch 165/1599:\ttrain Loss: 2.0748 Acc: 0.5763\tval Loss: 2.0904 Acc: 0.4667\t\n",
      "Epoch 166/1599:\ttrain Loss: 2.0781 Acc: 0.5720\tval Loss: 2.0865 Acc: 0.5333\t\n",
      "Epoch 167/1599:\ttrain Loss: 2.0690 Acc: 0.6271\tval Loss: 2.0896 Acc: 0.5000\t\n",
      "Epoch 168/1599:\ttrain Loss: 2.0872 Acc: 0.5890\tval Loss: 2.0966 Acc: 0.4667\t\n",
      "Epoch 169/1599:\ttrain Loss: 2.0945 Acc: 0.5805\tval Loss: 2.0902 Acc: 0.5333\t\n",
      "Epoch 170/1599:\ttrain Loss: 2.0707 Acc: 0.5890\tval Loss: 2.0885 Acc: 0.5000\t\n",
      "Epoch 171/1599:\ttrain Loss: 2.0750 Acc: 0.6144\tval Loss: 2.0850 Acc: 0.5000\t\n",
      "Epoch 172/1599:\ttrain Loss: 2.0794 Acc: 0.5593\tval Loss: 2.0861 Acc: 0.5333\t\n",
      "Epoch 173/1599:\ttrain Loss: 2.0803 Acc: 0.5890\tval Loss: 2.0871 Acc: 0.5333\t\n",
      "Epoch 174/1599:\ttrain Loss: 2.0645 Acc: 0.5932\tval Loss: 2.0837 Acc: 0.4667\t\n",
      "Epoch 175/1599:\ttrain Loss: 2.0691 Acc: 0.5975\tval Loss: 2.0994 Acc: 0.5667\t\n",
      "Epoch 176/1599:\ttrain Loss: 2.0740 Acc: 0.5720\tval Loss: 2.0936 Acc: 0.5333\t\n",
      "Epoch 177/1599:\ttrain Loss: 2.0812 Acc: 0.5508\tval Loss: 2.0900 Acc: 0.5000\t\n",
      "Epoch 178/1599:\ttrain Loss: 2.0815 Acc: 0.5847\tval Loss: 2.0864 Acc: 0.4667\t\n",
      "Epoch 179/1599:\ttrain Loss: 2.0626 Acc: 0.6059\tval Loss: 2.0918 Acc: 0.5000\t\n",
      "Epoch 180/1599:\ttrain Loss: 2.0660 Acc: 0.6102\tval Loss: 2.0718 Acc: 0.5333\t\n",
      "Epoch 181/1599:\ttrain Loss: 2.0708 Acc: 0.5890\tval Loss: 2.0874 Acc: 0.5667\t\n",
      "Epoch 182/1599:\ttrain Loss: 2.0801 Acc: 0.5805\tval Loss: 2.0880 Acc: 0.6000\t\n",
      "Epoch 183/1599:\ttrain Loss: 2.0765 Acc: 0.5636\tval Loss: 2.0857 Acc: 0.5333\t\n",
      "Epoch 184/1599:\ttrain Loss: 2.0718 Acc: 0.6102\tval Loss: 2.0860 Acc: 0.6000\t\n",
      "Epoch 185/1599:\ttrain Loss: 2.0738 Acc: 0.5975\tval Loss: 2.0862 Acc: 0.5000\t\n",
      "Epoch 186/1599:\ttrain Loss: 2.0625 Acc: 0.6102\tval Loss: 2.0867 Acc: 0.6000\t\n",
      "Epoch 187/1599:\ttrain Loss: 2.0598 Acc: 0.5805\tval Loss: 2.0862 Acc: 0.5667\t\n",
      "Epoch 188/1599:\ttrain Loss: 2.0630 Acc: 0.6017\tval Loss: 2.0836 Acc: 0.5333\t\n",
      "Epoch 189/1599:\ttrain Loss: 2.0705 Acc: 0.5847\tval Loss: 2.0904 Acc: 0.6000\t\n",
      "Epoch 190/1599:\ttrain Loss: 2.0868 Acc: 0.5381\tval Loss: 2.1081 Acc: 0.6333\t\n",
      "Epoch 191/1599:\ttrain Loss: 2.0640 Acc: 0.6271\tval Loss: 2.0849 Acc: 0.6000\t\n",
      "Epoch 192/1599:\ttrain Loss: 2.0638 Acc: 0.5847\tval Loss: 2.0763 Acc: 0.5333\t\n",
      "Epoch 193/1599:\ttrain Loss: 2.0692 Acc: 0.5890\tval Loss: 2.0897 Acc: 0.5333\t\n",
      "Epoch 194/1599:\ttrain Loss: 2.0731 Acc: 0.5720\tval Loss: 2.0886 Acc: 0.5333\t\n",
      "Epoch 195/1599:\ttrain Loss: 2.0758 Acc: 0.5466\tval Loss: 2.0931 Acc: 0.5667\t\n",
      "Epoch 196/1599:\ttrain Loss: 2.0728 Acc: 0.5975\tval Loss: 2.0866 Acc: 0.5667\t\n",
      "Epoch 197/1599:\ttrain Loss: 2.0583 Acc: 0.6271\tval Loss: 2.0967 Acc: 0.5333\t\n",
      "Epoch 198/1599:\ttrain Loss: 2.0788 Acc: 0.6144\tval Loss: 2.0527 Acc: 0.6333\t\n",
      "Epoch 199/1599:\ttrain Loss: 2.0586 Acc: 0.6271\tval Loss: 2.0676 Acc: 0.6333\t\n",
      "Epoch 200/1599:\ttrain Loss: 2.0822 Acc: 0.5763\tval Loss: 2.0816 Acc: 0.6000\t\n",
      "Epoch 201/1599:\ttrain Loss: 2.0670 Acc: 0.5932\tval Loss: 2.0990 Acc: 0.6000\t\n",
      "Epoch 202/1599:\ttrain Loss: 2.0596 Acc: 0.6441\tval Loss: 2.0858 Acc: 0.6333\t\n",
      "Epoch 203/1599:\ttrain Loss: 2.0785 Acc: 0.5508\tval Loss: 2.0947 Acc: 0.5333\t\n",
      "Epoch 204/1599:\ttrain Loss: 2.0766 Acc: 0.5932\tval Loss: 2.0863 Acc: 0.5667\t\n",
      "Epoch 205/1599:\ttrain Loss: 2.0619 Acc: 0.5975\tval Loss: 2.0936 Acc: 0.5667\t\n",
      "Epoch 206/1599:\ttrain Loss: 2.0654 Acc: 0.6186\tval Loss: 2.1155 Acc: 0.6000\t\n",
      "Epoch 207/1599:\ttrain Loss: 2.0899 Acc: 0.5678\tval Loss: 2.0941 Acc: 0.5667\t\n",
      "Epoch 208/1599:\ttrain Loss: 2.0825 Acc: 0.5805\tval Loss: 2.1080 Acc: 0.5667\t\n",
      "Epoch 209/1599:\ttrain Loss: 2.0749 Acc: 0.6229\tval Loss: 2.1069 Acc: 0.6000\t\n",
      "Epoch 210/1599:\ttrain Loss: 2.0752 Acc: 0.5678\tval Loss: 2.0994 Acc: 0.5667\t\n",
      "Epoch 211/1599:\ttrain Loss: 2.0698 Acc: 0.6356\tval Loss: 2.1035 Acc: 0.5667\t\n",
      "Epoch 212/1599:\ttrain Loss: 2.0707 Acc: 0.6144\tval Loss: 2.0719 Acc: 0.6000\t\n",
      "Epoch 213/1599:\ttrain Loss: 2.0607 Acc: 0.5805\tval Loss: 2.1101 Acc: 0.5333\t\n",
      "Epoch 214/1599:\ttrain Loss: 2.0688 Acc: 0.5636\tval Loss: 2.0863 Acc: 0.5667\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 215/1599:\ttrain Loss: 2.0827 Acc: 0.5890\tval Loss: 2.0905 Acc: 0.6667\t\n",
      "Epoch 216/1599:\ttrain Loss: 2.0731 Acc: 0.6059\tval Loss: 2.0846 Acc: 0.6000\t\n",
      "Epoch 217/1599:\ttrain Loss: 2.0666 Acc: 0.6102\tval Loss: 2.0881 Acc: 0.6000\t\n",
      "Epoch 218/1599:\ttrain Loss: 2.0654 Acc: 0.6017\tval Loss: 2.0866 Acc: 0.6000\t\n",
      "Epoch 219/1599:\ttrain Loss: 2.0763 Acc: 0.6229\tval Loss: 2.0932 Acc: 0.6000\t\n",
      "Epoch 220/1599:\ttrain Loss: 2.0713 Acc: 0.6144\tval Loss: 2.0844 Acc: 0.5333\t\n",
      "Epoch 221/1599:\ttrain Loss: 2.0807 Acc: 0.5593\tval Loss: 2.1048 Acc: 0.5333\t\n",
      "Epoch 222/1599:\ttrain Loss: 2.0538 Acc: 0.6610\tval Loss: 2.1094 Acc: 0.5667\t\n",
      "Epoch 223/1599:\ttrain Loss: 2.0815 Acc: 0.5551\tval Loss: 2.0879 Acc: 0.6667\t\n",
      "Epoch 224/1599:\ttrain Loss: 2.0617 Acc: 0.6271\tval Loss: 2.0798 Acc: 0.6333\t\n",
      "Epoch 225/1599:\ttrain Loss: 2.0764 Acc: 0.5847\tval Loss: 2.0526 Acc: 0.7000\t\n",
      "Epoch 226/1599:\ttrain Loss: 2.0705 Acc: 0.6314\tval Loss: 2.0872 Acc: 0.5333\t\n",
      "Epoch 227/1599:\ttrain Loss: 2.0725 Acc: 0.6017\tval Loss: 2.1121 Acc: 0.5667\t\n",
      "Epoch 228/1599:\ttrain Loss: 2.0703 Acc: 0.5975\tval Loss: 2.0874 Acc: 0.5333\t\n",
      "Epoch 229/1599:\ttrain Loss: 2.0619 Acc: 0.6017\tval Loss: 2.0841 Acc: 0.6333\t\n",
      "Epoch 230/1599:\ttrain Loss: 2.0550 Acc: 0.6356\tval Loss: 2.0909 Acc: 0.6000\t\n",
      "Epoch 231/1599:\ttrain Loss: 2.0796 Acc: 0.5636\tval Loss: 2.0843 Acc: 0.6333\t\n",
      "Epoch 232/1599:\ttrain Loss: 2.0652 Acc: 0.5975\tval Loss: 2.0895 Acc: 0.5333\t\n",
      "Epoch 233/1599:\ttrain Loss: 2.0747 Acc: 0.6059\tval Loss: 2.1220 Acc: 0.4667\t\n",
      "Epoch 234/1599:\ttrain Loss: 2.0541 Acc: 0.6144\tval Loss: 2.1380 Acc: 0.4667\t\n",
      "Epoch 235/1599:\ttrain Loss: 2.0662 Acc: 0.5805\tval Loss: 2.1419 Acc: 0.5667\t\n",
      "Epoch 236/1599:\ttrain Loss: 2.0654 Acc: 0.6059\tval Loss: 2.1307 Acc: 0.5667\t\n",
      "Epoch 237/1599:\ttrain Loss: 2.0612 Acc: 0.6102\tval Loss: 2.1087 Acc: 0.5667\t\n",
      "Epoch 238/1599:\ttrain Loss: 2.0524 Acc: 0.6695\tval Loss: 2.0881 Acc: 0.6333\t\n",
      "Epoch 239/1599:\ttrain Loss: 2.0724 Acc: 0.5636\tval Loss: 2.0874 Acc: 0.6333\t\n",
      "Epoch 240/1599:\ttrain Loss: 2.0670 Acc: 0.6059\tval Loss: 2.0537 Acc: 0.6000\t\n",
      "Epoch 241/1599:\ttrain Loss: 2.0688 Acc: 0.6017\tval Loss: 2.0836 Acc: 0.5667\t\n",
      "Epoch 242/1599:\ttrain Loss: 2.0586 Acc: 0.6483\tval Loss: 2.0733 Acc: 0.6333\t\n",
      "Epoch 243/1599:\ttrain Loss: 2.0777 Acc: 0.6186\tval Loss: 2.0878 Acc: 0.5667\t\n",
      "Epoch 244/1599:\ttrain Loss: 2.0602 Acc: 0.6271\tval Loss: 2.0572 Acc: 0.7000\t\n",
      "Epoch 245/1599:\ttrain Loss: 2.0501 Acc: 0.6653\tval Loss: 2.0704 Acc: 0.6000\t\n",
      "Epoch 246/1599:\ttrain Loss: 2.0739 Acc: 0.6059\tval Loss: 2.1035 Acc: 0.6333\t\n",
      "Epoch 247/1599:\ttrain Loss: 2.0581 Acc: 0.6483\tval Loss: 2.0870 Acc: 0.6667\t\n",
      "Epoch 248/1599:\ttrain Loss: 2.0660 Acc: 0.5890\tval Loss: 2.0720 Acc: 0.6333\t\n",
      "Epoch 249/1599:\ttrain Loss: 2.0638 Acc: 0.6398\tval Loss: 2.0829 Acc: 0.6333\t\n",
      "Epoch 250/1599:\ttrain Loss: 2.0728 Acc: 0.6229\tval Loss: 2.0754 Acc: 0.6667\t\n",
      "Epoch 251/1599:\ttrain Loss: 2.0561 Acc: 0.6229\tval Loss: 2.0713 Acc: 0.6333\t\n",
      "Epoch 252/1599:\ttrain Loss: 2.0650 Acc: 0.6356\tval Loss: 2.0866 Acc: 0.6000\t\n",
      "Epoch 253/1599:\ttrain Loss: 2.0591 Acc: 0.6314\tval Loss: 2.0910 Acc: 0.5333\t\n",
      "Epoch 254/1599:\ttrain Loss: 2.0657 Acc: 0.6483\tval Loss: 2.1061 Acc: 0.5667\t\n",
      "Epoch 255/1599:\ttrain Loss: 2.0645 Acc: 0.6695\tval Loss: 2.0542 Acc: 0.7667\t\n",
      "Epoch 256/1599:\ttrain Loss: 2.0574 Acc: 0.6483\tval Loss: 2.0686 Acc: 0.6667\t\n",
      "Epoch 257/1599:\ttrain Loss: 2.0727 Acc: 0.6610\tval Loss: 2.0572 Acc: 0.6000\t\n",
      "Epoch 258/1599:\ttrain Loss: 2.0767 Acc: 0.6017\tval Loss: 2.0848 Acc: 0.5333\t\n",
      "Epoch 259/1599:\ttrain Loss: 2.0432 Acc: 0.6695\tval Loss: 2.0844 Acc: 0.5667\t\n",
      "Epoch 260/1599:\ttrain Loss: 2.0791 Acc: 0.6186\tval Loss: 2.0816 Acc: 0.5333\t\n",
      "Epoch 261/1599:\ttrain Loss: 2.0570 Acc: 0.6525\tval Loss: 2.0853 Acc: 0.6333\t\n",
      "Epoch 262/1599:\ttrain Loss: 2.0721 Acc: 0.6102\tval Loss: 2.0867 Acc: 0.5667\t\n",
      "Epoch 263/1599:\ttrain Loss: 2.0621 Acc: 0.6102\tval Loss: 2.0471 Acc: 0.6333\t\n",
      "Epoch 264/1599:\ttrain Loss: 2.0607 Acc: 0.6780\tval Loss: 2.0913 Acc: 0.5667\t\n",
      "Epoch 265/1599:\ttrain Loss: 2.0648 Acc: 0.6059\tval Loss: 2.0691 Acc: 0.6000\t\n",
      "Epoch 266/1599:\ttrain Loss: 2.0698 Acc: 0.5508\tval Loss: 2.1156 Acc: 0.4667\t\n",
      "Epoch 267/1599:\ttrain Loss: 2.0749 Acc: 0.5212\tval Loss: 2.0532 Acc: 0.5667\t\n",
      "Epoch 268/1599:\ttrain Loss: 2.0564 Acc: 0.6568\tval Loss: 2.0615 Acc: 0.6667\t\n",
      "Epoch 269/1599:\ttrain Loss: 2.0761 Acc: 0.5763\tval Loss: 2.0889 Acc: 0.6000\t\n",
      "Epoch 270/1599:\ttrain Loss: 2.0627 Acc: 0.6144\tval Loss: 2.0613 Acc: 0.6667\t\n",
      "Epoch 271/1599:\ttrain Loss: 2.0608 Acc: 0.6314\tval Loss: 2.0853 Acc: 0.5667\t\n",
      "Epoch 272/1599:\ttrain Loss: 2.0608 Acc: 0.6441\tval Loss: 2.0864 Acc: 0.5333\t\n",
      "Epoch 273/1599:\ttrain Loss: 2.0559 Acc: 0.6144\tval Loss: 2.0537 Acc: 0.6333\t\n",
      "Epoch 274/1599:\ttrain Loss: 2.0695 Acc: 0.5636\tval Loss: 2.0711 Acc: 0.6000\t\n",
      "Epoch 275/1599:\ttrain Loss: 2.0706 Acc: 0.5975\tval Loss: 2.0641 Acc: 0.7333\t\n",
      "Epoch 276/1599:\ttrain Loss: 2.0515 Acc: 0.6907\tval Loss: 2.0886 Acc: 0.6333\t\n",
      "Epoch 277/1599:\ttrain Loss: 2.0638 Acc: 0.5932\tval Loss: 2.1078 Acc: 0.5667\t\n",
      "Epoch 278/1599:\ttrain Loss: 2.0577 Acc: 0.6186\tval Loss: 2.0517 Acc: 0.7000\t\n",
      "Epoch 279/1599:\ttrain Loss: 2.0521 Acc: 0.6822\tval Loss: 2.0742 Acc: 0.7000\t\n",
      "Epoch 280/1599:\ttrain Loss: 2.0705 Acc: 0.6441\tval Loss: 2.0598 Acc: 0.7333\t\n",
      "Epoch 281/1599:\ttrain Loss: 2.0637 Acc: 0.6229\tval Loss: 2.0953 Acc: 0.7667\t\n",
      "Epoch 282/1599:\ttrain Loss: 2.0734 Acc: 0.6568\tval Loss: 2.1171 Acc: 0.7000\t\n",
      "Epoch 283/1599:\ttrain Loss: 2.0739 Acc: 0.6398\tval Loss: 2.0691 Acc: 0.6000\t\n",
      "Epoch 284/1599:\ttrain Loss: 2.0683 Acc: 0.6186\tval Loss: 2.0730 Acc: 0.6000\t\n",
      "Epoch 285/1599:\ttrain Loss: 2.0721 Acc: 0.6610\tval Loss: 2.0947 Acc: 0.6333\t\n",
      "Epoch 286/1599:\ttrain Loss: 2.0641 Acc: 0.6314\tval Loss: 2.0793 Acc: 0.7667\t\n",
      "Epoch 287/1599:\ttrain Loss: 2.0578 Acc: 0.6610\tval Loss: 2.0934 Acc: 0.7333\t\n",
      "Epoch 288/1599:\ttrain Loss: 2.0724 Acc: 0.6186\tval Loss: 2.0967 Acc: 0.5667\t\n",
      "Epoch 289/1599:\ttrain Loss: 2.0670 Acc: 0.6144\tval Loss: 2.0904 Acc: 0.6333\t\n",
      "Epoch 290/1599:\ttrain Loss: 2.0599 Acc: 0.6271\tval Loss: 2.0891 Acc: 0.6667\t\n",
      "Epoch 291/1599:\ttrain Loss: 2.0565 Acc: 0.6441\tval Loss: 2.0807 Acc: 0.6333\t\n",
      "Epoch 292/1599:\ttrain Loss: 2.0519 Acc: 0.7034\tval Loss: 2.0871 Acc: 0.7667\t\n",
      "Epoch 293/1599:\ttrain Loss: 2.0599 Acc: 0.6610\tval Loss: 2.0505 Acc: 0.7667\t\n",
      "Epoch 294/1599:\ttrain Loss: 2.0793 Acc: 0.6483\tval Loss: 2.0830 Acc: 0.7667\t\n",
      "Epoch 295/1599:\ttrain Loss: 2.0647 Acc: 0.6356\tval Loss: 2.0727 Acc: 0.7000\t\n",
      "Epoch 296/1599:\ttrain Loss: 2.0860 Acc: 0.5339\tval Loss: 2.0716 Acc: 0.7333\t\n",
      "Epoch 297/1599:\ttrain Loss: 2.0619 Acc: 0.6314\tval Loss: 2.0926 Acc: 0.6000\t\n",
      "Epoch 298/1599:\ttrain Loss: 2.0704 Acc: 0.5975\tval Loss: 2.0888 Acc: 0.7333\t\n",
      "Epoch 299/1599:\ttrain Loss: 2.0558 Acc: 0.6568\tval Loss: 2.0911 Acc: 0.7000\t\n",
      "Epoch 300/1599:\ttrain Loss: 2.0695 Acc: 0.6271\tval Loss: 2.0865 Acc: 0.6667\t\n",
      "Epoch 301/1599:\ttrain Loss: 2.0494 Acc: 0.6737\tval Loss: 2.0579 Acc: 0.7000\t\n",
      "Epoch 302/1599:\ttrain Loss: 2.0768 Acc: 0.6271\tval Loss: 2.0889 Acc: 0.7000\t\n",
      "Epoch 303/1599:\ttrain Loss: 2.0627 Acc: 0.6610\tval Loss: 2.0899 Acc: 0.7333\t\n",
      "Epoch 304/1599:\ttrain Loss: 2.0535 Acc: 0.7076\tval Loss: 2.0978 Acc: 0.7333\t\n",
      "Epoch 305/1599:\ttrain Loss: 2.0722 Acc: 0.6314\tval Loss: 2.0950 Acc: 0.5667\t\n",
      "Epoch 306/1599:\ttrain Loss: 2.0667 Acc: 0.6822\tval Loss: 2.0930 Acc: 0.6667\t\n",
      "Epoch 307/1599:\ttrain Loss: 2.0494 Acc: 0.6822\tval Loss: 2.0739 Acc: 0.7667\t\n",
      "Epoch 308/1599:\ttrain Loss: 2.0470 Acc: 0.7331\tval Loss: 2.0982 Acc: 0.7667\t\n",
      "Epoch 309/1599:\ttrain Loss: 2.0630 Acc: 0.6653\tval Loss: 2.0655 Acc: 0.8000\t\n",
      "Epoch 310/1599:\ttrain Loss: 2.0683 Acc: 0.6525\tval Loss: 2.0823 Acc: 0.7000\t\n",
      "Epoch 311/1599:\ttrain Loss: 2.0436 Acc: 0.7119\tval Loss: 2.0879 Acc: 0.6333\t\n",
      "Epoch 312/1599:\ttrain Loss: 2.0582 Acc: 0.6737\tval Loss: 2.1070 Acc: 0.7000\t\n",
      "Epoch 313/1599:\ttrain Loss: 2.0646 Acc: 0.6780\tval Loss: 2.0836 Acc: 0.7333\t\n",
      "Epoch 314/1599:\ttrain Loss: 2.0791 Acc: 0.6102\tval Loss: 2.1241 Acc: 0.6333\t\n",
      "Epoch 315/1599:\ttrain Loss: 2.0601 Acc: 0.6737\tval Loss: 2.1223 Acc: 0.5667\t\n",
      "Epoch 316/1599:\ttrain Loss: 2.0704 Acc: 0.6271\tval Loss: 2.0851 Acc: 0.6333\t\n",
      "Epoch 317/1599:\ttrain Loss: 2.0451 Acc: 0.6610\tval Loss: 2.1027 Acc: 0.7000\t\n",
      "Epoch 318/1599:\ttrain Loss: 2.0646 Acc: 0.6525\tval Loss: 2.0676 Acc: 0.6667\t\n",
      "Epoch 319/1599:\ttrain Loss: 2.0679 Acc: 0.6610\tval Loss: 2.0760 Acc: 0.7000\t\n",
      "Epoch 320/1599:\ttrain Loss: 2.0488 Acc: 0.6822\tval Loss: 2.0929 Acc: 0.6000\t\n",
      "Epoch 321/1599:\ttrain Loss: 2.0797 Acc: 0.5890\tval Loss: 2.1551 Acc: 0.5333\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 322/1599:\ttrain Loss: 2.0640 Acc: 0.6398\tval Loss: 2.0810 Acc: 0.7000\t\n",
      "Epoch 323/1599:\ttrain Loss: 2.0637 Acc: 0.6610\tval Loss: 2.1254 Acc: 0.6667\t\n",
      "Epoch 324/1599:\ttrain Loss: 2.0622 Acc: 0.7161\tval Loss: 2.0877 Acc: 0.6667\t\n",
      "Epoch 325/1599:\ttrain Loss: 2.0734 Acc: 0.6483\tval Loss: 2.1037 Acc: 0.7333\t\n",
      "Epoch 326/1599:\ttrain Loss: 2.0670 Acc: 0.6144\tval Loss: 2.1059 Acc: 0.7000\t\n",
      "Epoch 327/1599:\ttrain Loss: 2.0699 Acc: 0.6398\tval Loss: 2.0424 Acc: 0.7333\t\n",
      "Epoch 328/1599:\ttrain Loss: 2.0540 Acc: 0.6695\tval Loss: 2.0847 Acc: 0.7000\t\n",
      "Epoch 329/1599:\ttrain Loss: 2.0715 Acc: 0.6356\tval Loss: 2.0561 Acc: 0.7000\t\n",
      "Epoch 330/1599:\ttrain Loss: 2.0627 Acc: 0.6568\tval Loss: 2.0877 Acc: 0.7000\t\n",
      "Epoch 331/1599:\ttrain Loss: 2.0676 Acc: 0.6186\tval Loss: 2.0870 Acc: 0.7000\t\n",
      "Epoch 332/1599:\ttrain Loss: 2.0705 Acc: 0.6102\tval Loss: 2.1172 Acc: 0.5667\t\n",
      "Epoch 333/1599:\ttrain Loss: 2.0594 Acc: 0.6271\tval Loss: 2.0591 Acc: 0.7000\t\n",
      "Epoch 334/1599:\ttrain Loss: 2.0575 Acc: 0.6653\tval Loss: 2.0582 Acc: 0.7667\t\n",
      "Epoch 335/1599:\ttrain Loss: 2.0687 Acc: 0.6398\tval Loss: 2.0587 Acc: 0.7000\t\n",
      "Epoch 336/1599:\ttrain Loss: 2.0739 Acc: 0.6059\tval Loss: 2.0719 Acc: 0.6333\t\n",
      "Epoch 337/1599:\ttrain Loss: 2.0563 Acc: 0.6780\tval Loss: 2.0519 Acc: 0.6667\t\n",
      "Epoch 338/1599:\ttrain Loss: 2.0504 Acc: 0.6525\tval Loss: 2.0671 Acc: 0.6333\t\n",
      "Epoch 339/1599:\ttrain Loss: 2.0638 Acc: 0.6568\tval Loss: 2.0332 Acc: 0.7333\t\n",
      "Epoch 340/1599:\ttrain Loss: 2.0472 Acc: 0.6822\tval Loss: 2.0840 Acc: 0.6667\t\n",
      "Epoch 341/1599:\ttrain Loss: 2.0558 Acc: 0.6992\tval Loss: 2.0396 Acc: 0.8000\t\n",
      "Epoch 342/1599:\ttrain Loss: 2.0665 Acc: 0.6441\tval Loss: 2.0765 Acc: 0.6667\t\n",
      "Epoch 343/1599:\ttrain Loss: 2.0666 Acc: 0.6695\tval Loss: 2.0567 Acc: 0.6333\t\n",
      "Epoch 344/1599:\ttrain Loss: 2.0838 Acc: 0.6271\tval Loss: 2.0722 Acc: 0.7333\t\n",
      "Epoch 345/1599:\ttrain Loss: 2.0637 Acc: 0.6653\tval Loss: 2.0520 Acc: 0.8000\t\n",
      "Epoch 346/1599:\ttrain Loss: 2.0661 Acc: 0.7076\tval Loss: 2.0844 Acc: 0.7667\t\n",
      "Epoch 347/1599:\ttrain Loss: 2.0524 Acc: 0.6864\tval Loss: 2.0542 Acc: 0.7667\t\n",
      "Epoch 348/1599:\ttrain Loss: 2.0639 Acc: 0.6653\tval Loss: 2.0613 Acc: 0.8000\t\n",
      "Epoch 349/1599:\ttrain Loss: 2.0682 Acc: 0.6398\tval Loss: 2.0730 Acc: 0.8000\t\n",
      "Epoch 350/1599:\ttrain Loss: 2.0519 Acc: 0.7246\tval Loss: 2.0382 Acc: 0.7333\t\n",
      "Epoch 351/1599:\ttrain Loss: 2.0439 Acc: 0.6864\tval Loss: 2.0635 Acc: 0.7333\t\n",
      "Epoch 352/1599:\ttrain Loss: 2.0614 Acc: 0.7119\tval Loss: 2.0628 Acc: 0.6333\t\n",
      "Epoch 353/1599:\ttrain Loss: 2.0641 Acc: 0.7119\tval Loss: 2.0794 Acc: 0.6667\t\n",
      "Epoch 354/1599:\ttrain Loss: 2.0562 Acc: 0.6992\tval Loss: 2.0439 Acc: 0.7333\t\n",
      "Epoch 355/1599:\ttrain Loss: 2.0606 Acc: 0.6653\tval Loss: 2.0462 Acc: 0.7667\t\n",
      "Epoch 356/1599:\ttrain Loss: 2.0588 Acc: 0.6822\tval Loss: 2.0323 Acc: 0.7000\t\n",
      "Epoch 357/1599:\ttrain Loss: 2.0531 Acc: 0.7669\tval Loss: 2.0542 Acc: 0.6667\t\n",
      "Epoch 358/1599:\ttrain Loss: 2.0663 Acc: 0.6907\tval Loss: 2.0537 Acc: 0.7667\t\n",
      "Epoch 359/1599:\ttrain Loss: 2.0637 Acc: 0.7119\tval Loss: 2.0237 Acc: 0.7000\t\n",
      "Epoch 360/1599:\ttrain Loss: 2.0462 Acc: 0.7034\tval Loss: 2.0396 Acc: 0.6667\t\n",
      "Epoch 361/1599:\ttrain Loss: 2.0685 Acc: 0.6653\tval Loss: 2.0544 Acc: 0.8000\t\n",
      "Epoch 362/1599:\ttrain Loss: 2.0761 Acc: 0.6229\tval Loss: 2.0725 Acc: 0.7667\t\n",
      "Epoch 363/1599:\ttrain Loss: 2.0502 Acc: 0.7119\tval Loss: 2.0513 Acc: 0.7333\t\n",
      "Epoch 364/1599:\ttrain Loss: 2.0664 Acc: 0.6695\tval Loss: 2.0595 Acc: 0.7667\t\n",
      "Epoch 365/1599:\ttrain Loss: 2.0542 Acc: 0.7161\tval Loss: 2.0546 Acc: 0.6667\t\n",
      "Epoch 366/1599:\ttrain Loss: 2.0726 Acc: 0.6525\tval Loss: 2.0524 Acc: 0.8333\t\n",
      "Epoch 367/1599:\ttrain Loss: 2.0601 Acc: 0.6992\tval Loss: 2.0476 Acc: 0.7333\t\n",
      "Epoch 368/1599:\ttrain Loss: 2.0619 Acc: 0.6737\tval Loss: 2.0517 Acc: 0.7000\t\n",
      "Epoch 369/1599:\ttrain Loss: 2.0480 Acc: 0.7500\tval Loss: 2.0510 Acc: 0.6333\t\n",
      "Epoch 370/1599:\ttrain Loss: 2.0517 Acc: 0.7119\tval Loss: 2.0488 Acc: 0.7333\t\n",
      "Epoch 371/1599:\ttrain Loss: 2.0394 Acc: 0.7542\tval Loss: 2.0530 Acc: 0.7000\t\n",
      "Epoch 372/1599:\ttrain Loss: 2.0624 Acc: 0.7119\tval Loss: 2.0554 Acc: 0.7333\t\n",
      "Epoch 373/1599:\ttrain Loss: 2.0550 Acc: 0.6780\tval Loss: 2.0650 Acc: 0.7333\t\n",
      "Epoch 374/1599:\ttrain Loss: 2.0460 Acc: 0.7712\tval Loss: 2.0198 Acc: 0.6333\t\n",
      "Epoch 375/1599:\ttrain Loss: 2.0723 Acc: 0.6822\tval Loss: 2.0297 Acc: 0.8000\t\n",
      "Epoch 376/1599:\ttrain Loss: 2.0459 Acc: 0.7373\tval Loss: 2.0624 Acc: 0.7667\t\n",
      "Epoch 377/1599:\ttrain Loss: 2.0534 Acc: 0.7161\tval Loss: 2.0276 Acc: 0.8333\t\n",
      "Epoch 378/1599:\ttrain Loss: 2.0460 Acc: 0.7754\tval Loss: 2.0375 Acc: 0.6333\t\n",
      "Epoch 379/1599:\ttrain Loss: 2.0569 Acc: 0.6822\tval Loss: 2.0749 Acc: 0.5667\t\n",
      "Epoch 380/1599:\ttrain Loss: 2.0566 Acc: 0.7331\tval Loss: 2.0677 Acc: 0.6333\t\n",
      "Epoch 381/1599:\ttrain Loss: 2.0585 Acc: 0.6695\tval Loss: 2.0688 Acc: 0.7000\t\n",
      "Epoch 382/1599:\ttrain Loss: 2.0680 Acc: 0.7246\tval Loss: 2.0741 Acc: 0.6667\t\n",
      "Epoch 383/1599:\ttrain Loss: 2.0639 Acc: 0.6949\tval Loss: 2.0251 Acc: 0.7000\t\n",
      "Epoch 384/1599:\ttrain Loss: 2.0634 Acc: 0.6822\tval Loss: 2.0827 Acc: 0.7000\t\n",
      "Epoch 385/1599:\ttrain Loss: 2.0444 Acc: 0.6653\tval Loss: 2.0858 Acc: 0.5667\t\n",
      "Epoch 386/1599:\ttrain Loss: 2.0399 Acc: 0.7203\tval Loss: 2.0512 Acc: 0.6667\t\n",
      "Epoch 387/1599:\ttrain Loss: 2.0641 Acc: 0.6483\tval Loss: 2.0581 Acc: 0.7000\t\n",
      "Epoch 388/1599:\ttrain Loss: 2.0422 Acc: 0.7331\tval Loss: 2.0986 Acc: 0.5333\t\n",
      "Epoch 389/1599:\ttrain Loss: 2.0646 Acc: 0.6780\tval Loss: 2.0847 Acc: 0.6667\t\n",
      "Epoch 390/1599:\ttrain Loss: 2.0508 Acc: 0.6356\tval Loss: 2.0856 Acc: 0.6667\t\n",
      "Epoch 391/1599:\ttrain Loss: 2.0648 Acc: 0.6568\tval Loss: 2.0552 Acc: 0.8000\t\n",
      "Epoch 392/1599:\ttrain Loss: 2.0476 Acc: 0.6992\tval Loss: 2.0539 Acc: 0.7667\t\n",
      "Epoch 393/1599:\ttrain Loss: 2.0496 Acc: 0.6907\tval Loss: 2.0587 Acc: 0.7667\t\n",
      "Epoch 394/1599:\ttrain Loss: 2.0552 Acc: 0.7034\tval Loss: 2.0724 Acc: 0.8000\t\n",
      "Epoch 395/1599:\ttrain Loss: 2.0534 Acc: 0.7373\tval Loss: 2.0869 Acc: 0.7333\t\n",
      "Epoch 396/1599:\ttrain Loss: 2.0492 Acc: 0.7161\tval Loss: 2.0667 Acc: 0.7333\t\n",
      "Epoch 397/1599:\ttrain Loss: 2.0525 Acc: 0.7034\tval Loss: 2.0416 Acc: 0.7333\t\n",
      "Epoch 398/1599:\ttrain Loss: 2.0544 Acc: 0.7331\tval Loss: 2.0634 Acc: 0.7000\t\n",
      "Epoch 399/1599:\ttrain Loss: 2.0447 Acc: 0.7203\tval Loss: 2.0910 Acc: 0.7000\t\n",
      "Epoch 400/1599:\ttrain Loss: 2.0560 Acc: 0.6907\tval Loss: 2.0669 Acc: 0.7333\t\n",
      "Epoch 401/1599:\ttrain Loss: 2.0690 Acc: 0.6356\tval Loss: 2.0301 Acc: 0.7000\t\n",
      "Epoch 402/1599:\ttrain Loss: 2.0657 Acc: 0.6610\tval Loss: 2.0257 Acc: 0.8000\t\n",
      "Epoch 403/1599:\ttrain Loss: 2.0560 Acc: 0.6780\tval Loss: 2.0533 Acc: 0.7333\t\n",
      "Epoch 404/1599:\ttrain Loss: 2.0616 Acc: 0.7034\tval Loss: 2.0592 Acc: 0.7667\t\n",
      "Epoch 405/1599:\ttrain Loss: 2.0430 Acc: 0.7458\tval Loss: 2.0524 Acc: 0.7667\t\n",
      "Epoch 406/1599:\ttrain Loss: 2.0478 Acc: 0.7203\tval Loss: 2.0348 Acc: 0.7333\t\n",
      "Epoch 407/1599:\ttrain Loss: 2.0543 Acc: 0.7542\tval Loss: 2.0535 Acc: 0.7000\t\n",
      "Epoch 408/1599:\ttrain Loss: 2.0563 Acc: 0.7034\tval Loss: 2.0462 Acc: 0.7000\t\n",
      "Epoch 409/1599:\ttrain Loss: 2.0477 Acc: 0.7585\tval Loss: 2.0587 Acc: 0.7000\t\n",
      "Epoch 410/1599:\ttrain Loss: 2.0516 Acc: 0.7161\tval Loss: 2.0751 Acc: 0.6000\t\n",
      "Epoch 411/1599:\ttrain Loss: 2.0579 Acc: 0.6864\tval Loss: 2.0443 Acc: 0.7333\t\n",
      "Epoch 412/1599:\ttrain Loss: 2.0563 Acc: 0.6907\tval Loss: 2.0842 Acc: 0.6000\t\n",
      "Epoch 413/1599:\ttrain Loss: 2.0381 Acc: 0.7415\tval Loss: 2.0351 Acc: 0.7667\t\n",
      "Epoch 414/1599:\ttrain Loss: 2.0358 Acc: 0.7331\tval Loss: 2.0611 Acc: 0.5667\t\n",
      "Epoch 415/1599:\ttrain Loss: 2.0683 Acc: 0.6949\tval Loss: 2.0531 Acc: 0.7000\t\n",
      "Epoch 416/1599:\ttrain Loss: 2.0483 Acc: 0.6525\tval Loss: 2.0557 Acc: 0.6667\t\n",
      "Epoch 417/1599:\ttrain Loss: 2.0595 Acc: 0.7119\tval Loss: 2.0564 Acc: 0.7667\t\n",
      "Epoch 418/1599:\ttrain Loss: 2.0471 Acc: 0.7203\tval Loss: 2.0593 Acc: 0.6333\t\n",
      "Epoch 419/1599:\ttrain Loss: 2.0516 Acc: 0.7246\tval Loss: 2.0540 Acc: 0.7000\t\n",
      "Epoch 420/1599:\ttrain Loss: 2.0595 Acc: 0.6949\tval Loss: 2.0537 Acc: 0.7000\t\n",
      "Epoch 421/1599:\ttrain Loss: 2.0672 Acc: 0.7161\tval Loss: 2.0305 Acc: 0.7000\t\n",
      "Epoch 422/1599:\ttrain Loss: 2.0448 Acc: 0.7288\tval Loss: 2.0506 Acc: 0.7333\t\n",
      "Epoch 423/1599:\ttrain Loss: 2.0541 Acc: 0.7288\tval Loss: 2.0253 Acc: 0.7333\t\n",
      "Epoch 424/1599:\ttrain Loss: 2.0494 Acc: 0.6992\tval Loss: 2.0538 Acc: 0.6667\t\n",
      "Epoch 425/1599:\ttrain Loss: 2.0522 Acc: 0.7034\tval Loss: 2.0696 Acc: 0.6667\t\n",
      "Epoch 426/1599:\ttrain Loss: 2.0577 Acc: 0.7246\tval Loss: 2.0421 Acc: 0.8000\t\n",
      "Epoch 427/1599:\ttrain Loss: 2.0512 Acc: 0.7246\tval Loss: 2.0243 Acc: 0.6667\t\n",
      "Epoch 428/1599:\ttrain Loss: 2.0649 Acc: 0.7203\tval Loss: 2.0448 Acc: 0.6667\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 429/1599:\ttrain Loss: 2.0395 Acc: 0.6864\tval Loss: 2.0742 Acc: 0.7000\t\n",
      "Epoch 430/1599:\ttrain Loss: 2.0557 Acc: 0.6949\tval Loss: 2.0491 Acc: 0.7333\t\n",
      "Epoch 431/1599:\ttrain Loss: 2.0452 Acc: 0.6653\tval Loss: 2.0428 Acc: 0.7667\t\n",
      "Epoch 432/1599:\ttrain Loss: 2.0377 Acc: 0.7627\tval Loss: 2.0202 Acc: 0.6333\t\n",
      "Epoch 433/1599:\ttrain Loss: 2.0640 Acc: 0.6907\tval Loss: 2.0217 Acc: 0.6667\t\n",
      "Epoch 434/1599:\ttrain Loss: 2.0641 Acc: 0.6864\tval Loss: 2.0678 Acc: 0.7000\t\n",
      "Epoch 435/1599:\ttrain Loss: 2.0663 Acc: 0.7585\tval Loss: 2.0530 Acc: 0.6667\t\n",
      "Epoch 436/1599:\ttrain Loss: 2.0567 Acc: 0.7331\tval Loss: 2.0543 Acc: 0.7000\t\n",
      "Epoch 437/1599:\ttrain Loss: 2.0550 Acc: 0.7076\tval Loss: 2.0849 Acc: 0.7333\t\n",
      "Epoch 438/1599:\ttrain Loss: 2.0415 Acc: 0.7331\tval Loss: 2.0588 Acc: 0.8333\t\n",
      "Epoch 439/1599:\ttrain Loss: 2.0490 Acc: 0.7712\tval Loss: 2.0486 Acc: 0.7667\t\n",
      "Epoch 440/1599:\ttrain Loss: 2.0512 Acc: 0.7669\tval Loss: 2.0797 Acc: 0.6667\t\n",
      "Epoch 441/1599:\ttrain Loss: 2.0530 Acc: 0.7076\tval Loss: 2.0750 Acc: 0.6667\t\n",
      "Epoch 442/1599:\ttrain Loss: 2.0588 Acc: 0.7119\tval Loss: 2.0588 Acc: 0.7333\t\n",
      "Epoch 443/1599:\ttrain Loss: 2.0461 Acc: 0.7288\tval Loss: 2.0541 Acc: 0.7000\t\n",
      "Epoch 444/1599:\ttrain Loss: 2.0427 Acc: 0.7500\tval Loss: 2.0527 Acc: 0.7333\t\n",
      "Epoch 445/1599:\ttrain Loss: 2.0532 Acc: 0.7585\tval Loss: 2.0430 Acc: 0.7000\t\n",
      "Epoch 446/1599:\ttrain Loss: 2.0491 Acc: 0.7500\tval Loss: 2.0555 Acc: 0.7333\t\n",
      "Epoch 447/1599:\ttrain Loss: 2.0441 Acc: 0.7966\tval Loss: 2.0558 Acc: 0.7333\t\n",
      "Epoch 448/1599:\ttrain Loss: 2.0572 Acc: 0.7373\tval Loss: 2.0349 Acc: 0.8333\t\n",
      "Epoch 449/1599:\ttrain Loss: 2.0505 Acc: 0.7373\tval Loss: 2.0352 Acc: 0.7667\t\n",
      "Epoch 450/1599:\ttrain Loss: 2.0477 Acc: 0.6780\tval Loss: 2.0647 Acc: 0.6667\t\n",
      "Epoch 451/1599:\ttrain Loss: 2.0574 Acc: 0.7203\tval Loss: 2.0514 Acc: 0.7333\t\n",
      "Epoch 452/1599:\ttrain Loss: 2.0429 Acc: 0.7712\tval Loss: 2.0516 Acc: 0.7667\t\n",
      "Epoch 453/1599:\ttrain Loss: 2.0519 Acc: 0.7288\tval Loss: 2.0204 Acc: 0.7333\t\n",
      "Epoch 454/1599:\ttrain Loss: 2.0423 Acc: 0.7542\tval Loss: 2.0443 Acc: 0.7667\t\n",
      "Epoch 455/1599:\ttrain Loss: 2.0397 Acc: 0.7966\tval Loss: 2.0542 Acc: 0.8000\t\n",
      "Epoch 456/1599:\ttrain Loss: 2.0563 Acc: 0.7754\tval Loss: 2.0213 Acc: 0.7333\t\n",
      "Epoch 457/1599:\ttrain Loss: 2.0345 Acc: 0.7500\tval Loss: 2.0517 Acc: 0.7667\t\n",
      "Epoch 458/1599:\ttrain Loss: 2.0390 Acc: 0.7669\tval Loss: 2.0417 Acc: 0.7667\t\n",
      "Epoch 459/1599:\ttrain Loss: 2.0368 Acc: 0.7881\tval Loss: 2.0227 Acc: 0.8667\t\n",
      "Epoch 460/1599:\ttrain Loss: 2.0466 Acc: 0.7415\tval Loss: 2.0392 Acc: 0.7667\t\n",
      "Epoch 461/1599:\ttrain Loss: 2.0470 Acc: 0.8136\tval Loss: 2.0418 Acc: 0.8000\t\n",
      "Epoch 462/1599:\ttrain Loss: 2.0362 Acc: 0.8178\tval Loss: 2.0448 Acc: 0.7667\t\n",
      "Epoch 463/1599:\ttrain Loss: 2.0364 Acc: 0.7712\tval Loss: 2.0395 Acc: 0.8667\t\n",
      "Epoch 464/1599:\ttrain Loss: 2.0421 Acc: 0.8263\tval Loss: 2.0728 Acc: 0.7667\t\n",
      "Epoch 465/1599:\ttrain Loss: 2.0508 Acc: 0.7966\tval Loss: 2.0352 Acc: 0.8000\t\n",
      "Epoch 466/1599:\ttrain Loss: 2.0385 Acc: 0.8390\tval Loss: 2.0836 Acc: 0.8000\t\n",
      "Epoch 467/1599:\ttrain Loss: 2.0393 Acc: 0.7881\tval Loss: 2.0317 Acc: 0.8333\t\n",
      "Epoch 468/1599:\ttrain Loss: 2.0324 Acc: 0.8475\tval Loss: 2.0536 Acc: 0.8667\t\n",
      "Epoch 469/1599:\ttrain Loss: 2.0399 Acc: 0.8008\tval Loss: 2.0504 Acc: 0.8667\t\n",
      "Epoch 470/1599:\ttrain Loss: 2.0446 Acc: 0.7881\tval Loss: 2.0502 Acc: 0.8333\t\n",
      "Epoch 471/1599:\ttrain Loss: 2.0454 Acc: 0.8051\tval Loss: 2.0177 Acc: 0.8667\t\n",
      "Epoch 472/1599:\ttrain Loss: 2.0433 Acc: 0.8220\tval Loss: 2.0414 Acc: 0.8667\t\n",
      "Epoch 473/1599:\ttrain Loss: 2.0465 Acc: 0.8559\tval Loss: 2.0539 Acc: 0.8667\t\n",
      "Epoch 474/1599:\ttrain Loss: 2.0426 Acc: 0.8517\tval Loss: 2.0317 Acc: 0.8667\t\n",
      "Epoch 475/1599:\ttrain Loss: 2.0468 Acc: 0.8008\tval Loss: 2.0511 Acc: 0.8333\t\n",
      "Epoch 476/1599:\ttrain Loss: 2.0516 Acc: 0.7500\tval Loss: 2.0460 Acc: 0.9000\t\n",
      "Epoch 477/1599:\ttrain Loss: 2.0340 Acc: 0.7839\tval Loss: 2.0511 Acc: 0.8667\t\n",
      "Epoch 478/1599:\ttrain Loss: 2.0437 Acc: 0.8051\tval Loss: 2.0437 Acc: 0.8333\t\n",
      "Epoch 479/1599:\ttrain Loss: 2.0619 Acc: 0.7119\tval Loss: 2.0569 Acc: 0.7667\t\n",
      "Epoch 480/1599:\ttrain Loss: 2.0352 Acc: 0.8517\tval Loss: 2.0480 Acc: 0.8333\t\n",
      "Epoch 481/1599:\ttrain Loss: 2.0516 Acc: 0.7712\tval Loss: 2.0538 Acc: 0.7000\t\n",
      "Epoch 482/1599:\ttrain Loss: 2.0328 Acc: 0.8220\tval Loss: 2.0801 Acc: 0.6333\t\n",
      "Epoch 483/1599:\ttrain Loss: 2.0523 Acc: 0.7415\tval Loss: 2.0481 Acc: 0.7333\t\n",
      "Epoch 484/1599:\ttrain Loss: 2.0474 Acc: 0.7839\tval Loss: 2.0791 Acc: 0.7667\t\n",
      "Epoch 485/1599:\ttrain Loss: 2.0554 Acc: 0.7966\tval Loss: 2.0501 Acc: 0.8000\t\n",
      "Epoch 486/1599:\ttrain Loss: 2.0447 Acc: 0.7458\tval Loss: 2.0526 Acc: 0.8333\t\n",
      "Epoch 487/1599:\ttrain Loss: 2.0483 Acc: 0.7797\tval Loss: 2.0550 Acc: 0.8333\t\n",
      "Epoch 488/1599:\ttrain Loss: 2.0607 Acc: 0.7542\tval Loss: 2.0429 Acc: 0.8333\t\n",
      "Epoch 489/1599:\ttrain Loss: 2.0222 Acc: 0.8390\tval Loss: 2.0345 Acc: 0.8333\t\n",
      "Epoch 490/1599:\ttrain Loss: 2.0521 Acc: 0.8136\tval Loss: 2.0515 Acc: 0.8000\t\n",
      "Epoch 491/1599:\ttrain Loss: 2.0475 Acc: 0.7881\tval Loss: 2.0522 Acc: 0.7667\t\n",
      "Epoch 492/1599:\ttrain Loss: 2.0495 Acc: 0.8432\tval Loss: 2.0487 Acc: 0.7667\t\n",
      "Epoch 493/1599:\ttrain Loss: 2.0473 Acc: 0.7966\tval Loss: 2.0468 Acc: 0.7000\t\n",
      "Epoch 494/1599:\ttrain Loss: 2.0354 Acc: 0.8093\tval Loss: 2.0393 Acc: 0.8333\t\n",
      "Epoch 495/1599:\ttrain Loss: 2.0349 Acc: 0.8602\tval Loss: 2.0404 Acc: 0.8000\t\n",
      "Epoch 496/1599:\ttrain Loss: 2.0428 Acc: 0.8008\tval Loss: 2.0489 Acc: 0.7667\t\n",
      "Epoch 497/1599:\ttrain Loss: 2.0505 Acc: 0.7966\tval Loss: 2.0272 Acc: 0.8000\t\n",
      "Epoch 498/1599:\ttrain Loss: 2.0362 Acc: 0.8559\tval Loss: 2.0459 Acc: 0.7667\t\n",
      "Epoch 499/1599:\ttrain Loss: 2.0556 Acc: 0.8051\tval Loss: 2.0290 Acc: 0.9000\t\n",
      "Epoch 500/1599:\ttrain Loss: 2.0379 Acc: 0.8220\tval Loss: 2.0384 Acc: 0.7667\t\n",
      "Epoch 501/1599:\ttrain Loss: 2.0428 Acc: 0.7839\tval Loss: 2.0533 Acc: 0.7333\t\n",
      "Epoch 502/1599:\ttrain Loss: 2.0354 Acc: 0.8008\tval Loss: 2.0440 Acc: 0.8333\t\n",
      "Epoch 503/1599:\ttrain Loss: 2.0297 Acc: 0.8644\tval Loss: 2.0213 Acc: 0.7333\t\n",
      "Epoch 504/1599:\ttrain Loss: 2.0663 Acc: 0.7839\tval Loss: 2.0300 Acc: 0.8333\t\n",
      "Epoch 505/1599:\ttrain Loss: 2.0360 Acc: 0.8093\tval Loss: 2.0221 Acc: 0.8333\t\n",
      "Epoch 506/1599:\ttrain Loss: 2.0418 Acc: 0.7924\tval Loss: 2.0657 Acc: 0.8333\t\n",
      "Epoch 507/1599:\ttrain Loss: 2.0469 Acc: 0.7500\tval Loss: 2.0183 Acc: 0.9000\t\n",
      "Epoch 508/1599:\ttrain Loss: 2.0384 Acc: 0.8051\tval Loss: 2.0391 Acc: 0.8667\t\n",
      "Epoch 509/1599:\ttrain Loss: 2.0384 Acc: 0.8136\tval Loss: 2.0532 Acc: 0.8333\t\n",
      "Epoch 510/1599:\ttrain Loss: 2.0334 Acc: 0.8517\tval Loss: 2.0366 Acc: 0.8667\t\n",
      "Epoch 511/1599:\ttrain Loss: 2.0551 Acc: 0.7542\tval Loss: 2.0250 Acc: 0.8000\t\n",
      "Epoch 512/1599:\ttrain Loss: 2.0349 Acc: 0.8347\tval Loss: 2.0344 Acc: 0.8667\t\n",
      "Epoch 513/1599:\ttrain Loss: 2.0335 Acc: 0.8263\tval Loss: 2.0278 Acc: 0.8667\t\n",
      "Epoch 514/1599:\ttrain Loss: 2.0304 Acc: 0.8432\tval Loss: 2.0550 Acc: 0.7333\t\n",
      "Epoch 515/1599:\ttrain Loss: 2.0425 Acc: 0.8305\tval Loss: 2.0640 Acc: 0.8333\t\n",
      "Epoch 516/1599:\ttrain Loss: 2.0386 Acc: 0.8051\tval Loss: 2.0530 Acc: 0.8000\t\n",
      "Epoch 517/1599:\ttrain Loss: 2.0269 Acc: 0.8559\tval Loss: 2.0688 Acc: 0.7333\t\n",
      "Epoch 518/1599:\ttrain Loss: 2.0528 Acc: 0.8305\tval Loss: 2.0259 Acc: 0.8333\t\n",
      "Epoch 519/1599:\ttrain Loss: 2.0383 Acc: 0.8093\tval Loss: 2.0560 Acc: 0.8333\t\n",
      "Epoch 520/1599:\ttrain Loss: 2.0430 Acc: 0.8178\tval Loss: 2.0745 Acc: 0.9000\t\n",
      "Epoch 521/1599:\ttrain Loss: 2.0328 Acc: 0.8347\tval Loss: 2.0183 Acc: 0.9333\t\n",
      "Epoch 522/1599:\ttrain Loss: 2.0333 Acc: 0.8644\tval Loss: 2.0507 Acc: 0.8333\t\n",
      "Epoch 523/1599:\ttrain Loss: 2.0390 Acc: 0.8390\tval Loss: 2.0272 Acc: 0.8667\t\n",
      "Epoch 524/1599:\ttrain Loss: 2.0421 Acc: 0.8178\tval Loss: 2.0500 Acc: 0.8333\t\n",
      "Epoch 525/1599:\ttrain Loss: 2.0260 Acc: 0.8729\tval Loss: 2.0402 Acc: 0.8667\t\n",
      "Epoch 526/1599:\ttrain Loss: 2.0456 Acc: 0.8390\tval Loss: 2.0187 Acc: 0.9000\t\n",
      "Epoch 527/1599:\ttrain Loss: 2.0411 Acc: 0.8432\tval Loss: 2.0291 Acc: 0.8333\t\n",
      "Epoch 528/1599:\ttrain Loss: 2.0409 Acc: 0.8644\tval Loss: 2.0198 Acc: 0.8667\t\n",
      "Epoch 529/1599:\ttrain Loss: 2.0338 Acc: 0.8686\tval Loss: 2.0199 Acc: 0.8667\t\n",
      "Epoch 530/1599:\ttrain Loss: 2.0455 Acc: 0.8432\tval Loss: 2.0411 Acc: 0.8000\t\n",
      "Epoch 531/1599:\ttrain Loss: 2.0209 Acc: 0.8941\tval Loss: 2.0532 Acc: 0.8333\t\n",
      "Epoch 532/1599:\ttrain Loss: 2.0390 Acc: 0.8602\tval Loss: 2.0485 Acc: 0.9333\t\n",
      "Epoch 533/1599:\ttrain Loss: 2.0294 Acc: 0.9110\tval Loss: 2.0524 Acc: 0.9000\t\n",
      "Epoch 534/1599:\ttrain Loss: 2.0365 Acc: 0.8644\tval Loss: 2.0530 Acc: 0.8667\t\n",
      "Epoch 535/1599:\ttrain Loss: 2.0409 Acc: 0.8178\tval Loss: 2.0196 Acc: 0.9000\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 536/1599:\ttrain Loss: 2.0326 Acc: 0.8347\tval Loss: 2.0273 Acc: 0.8667\t\n",
      "Epoch 537/1599:\ttrain Loss: 2.0371 Acc: 0.8305\tval Loss: 2.0288 Acc: 0.8333\t\n",
      "Epoch 538/1599:\ttrain Loss: 2.0278 Acc: 0.8898\tval Loss: 2.0370 Acc: 0.9333\t\n",
      "Epoch 539/1599:\ttrain Loss: 2.0374 Acc: 0.8390\tval Loss: 2.0234 Acc: 0.9333\t\n",
      "Epoch 540/1599:\ttrain Loss: 2.0364 Acc: 0.8432\tval Loss: 2.0165 Acc: 0.9667\t\n",
      "Epoch 541/1599:\ttrain Loss: 2.0299 Acc: 0.8432\tval Loss: 2.0229 Acc: 0.9000\t\n",
      "Epoch 542/1599:\ttrain Loss: 2.0250 Acc: 0.8771\tval Loss: 2.0245 Acc: 0.9000\t\n",
      "Epoch 543/1599:\ttrain Loss: 2.0342 Acc: 0.8347\tval Loss: 2.0197 Acc: 0.8333\t\n",
      "Epoch 544/1599:\ttrain Loss: 2.0334 Acc: 0.8602\tval Loss: 2.0198 Acc: 0.8333\t\n",
      "Epoch 545/1599:\ttrain Loss: 2.0345 Acc: 0.8178\tval Loss: 2.0434 Acc: 0.9667\t\n",
      "Epoch 546/1599:\ttrain Loss: 2.0264 Acc: 0.8644\tval Loss: 2.0515 Acc: 0.9000\t\n",
      "Epoch 547/1599:\ttrain Loss: 2.0376 Acc: 0.7924\tval Loss: 2.0457 Acc: 0.9333\t\n",
      "Epoch 548/1599:\ttrain Loss: 2.0499 Acc: 0.7881\tval Loss: 2.0377 Acc: 0.9333\t\n",
      "Epoch 549/1599:\ttrain Loss: 2.0423 Acc: 0.8432\tval Loss: 2.0539 Acc: 0.9000\t\n",
      "Epoch 550/1599:\ttrain Loss: 2.0457 Acc: 0.8051\tval Loss: 2.0543 Acc: 0.7667\t\n",
      "Epoch 551/1599:\ttrain Loss: 2.0268 Acc: 0.8517\tval Loss: 2.0348 Acc: 0.8333\t\n",
      "Epoch 552/1599:\ttrain Loss: 2.0420 Acc: 0.8093\tval Loss: 2.0330 Acc: 0.8000\t\n",
      "Epoch 553/1599:\ttrain Loss: 2.0388 Acc: 0.8220\tval Loss: 2.0220 Acc: 0.9000\t\n",
      "Epoch 554/1599:\ttrain Loss: 2.0290 Acc: 0.8644\tval Loss: 2.0245 Acc: 0.9333\t\n",
      "Epoch 555/1599:\ttrain Loss: 2.0430 Acc: 0.8559\tval Loss: 2.0279 Acc: 0.9000\t\n",
      "Epoch 556/1599:\ttrain Loss: 2.0379 Acc: 0.8602\tval Loss: 2.0541 Acc: 0.9333\t\n",
      "Epoch 557/1599:\ttrain Loss: 2.0402 Acc: 0.8475\tval Loss: 2.0289 Acc: 0.8000\t\n",
      "Epoch 558/1599:\ttrain Loss: 2.0532 Acc: 0.8136\tval Loss: 2.0346 Acc: 0.9333\t\n",
      "Epoch 559/1599:\ttrain Loss: 2.0351 Acc: 0.8814\tval Loss: 2.0498 Acc: 0.8000\t\n",
      "Epoch 560/1599:\ttrain Loss: 2.0415 Acc: 0.8220\tval Loss: 2.0279 Acc: 0.9000\t\n",
      "Epoch 561/1599:\ttrain Loss: 2.0421 Acc: 0.8814\tval Loss: 2.0246 Acc: 0.8667\t\n",
      "Epoch 562/1599:\ttrain Loss: 2.0327 Acc: 0.8517\tval Loss: 2.0200 Acc: 0.9667\t\n",
      "Epoch 563/1599:\ttrain Loss: 2.0247 Acc: 0.8941\tval Loss: 2.0178 Acc: 0.9333\t\n",
      "Epoch 564/1599:\ttrain Loss: 2.0211 Acc: 0.8771\tval Loss: 2.0307 Acc: 0.9333\t\n",
      "Epoch 565/1599:\ttrain Loss: 2.0321 Acc: 0.8602\tval Loss: 2.0462 Acc: 0.9333\t\n",
      "Epoch 566/1599:\ttrain Loss: 2.0369 Acc: 0.8390\tval Loss: 2.0191 Acc: 0.9333\t\n",
      "Epoch 567/1599:\ttrain Loss: 2.0403 Acc: 0.8559\tval Loss: 2.0257 Acc: 0.8667\t\n",
      "Epoch 568/1599:\ttrain Loss: 2.0257 Acc: 0.8814\tval Loss: 2.0297 Acc: 0.8000\t\n",
      "Epoch 569/1599:\ttrain Loss: 2.0368 Acc: 0.8475\tval Loss: 2.0397 Acc: 0.9000\t\n",
      "Epoch 570/1599:\ttrain Loss: 2.0364 Acc: 0.8983\tval Loss: 2.0329 Acc: 0.9333\t\n",
      "Epoch 571/1599:\ttrain Loss: 2.0337 Acc: 0.8559\tval Loss: 2.0199 Acc: 0.9000\t\n",
      "Epoch 572/1599:\ttrain Loss: 2.0283 Acc: 0.8941\tval Loss: 2.0347 Acc: 0.8667\t\n",
      "Epoch 573/1599:\ttrain Loss: 2.0416 Acc: 0.8305\tval Loss: 2.0253 Acc: 0.8667\t\n",
      "Epoch 574/1599:\ttrain Loss: 2.0292 Acc: 0.9153\tval Loss: 2.0190 Acc: 0.9333\t\n",
      "Epoch 575/1599:\ttrain Loss: 2.0491 Acc: 0.8644\tval Loss: 2.0413 Acc: 0.9000\t\n",
      "Epoch 576/1599:\ttrain Loss: 2.0355 Acc: 0.8771\tval Loss: 2.0211 Acc: 0.8667\t\n",
      "Epoch 577/1599:\ttrain Loss: 2.0306 Acc: 0.8898\tval Loss: 2.0319 Acc: 0.9333\t\n",
      "Epoch 578/1599:\ttrain Loss: 2.0300 Acc: 0.8941\tval Loss: 2.0262 Acc: 0.8667\t\n",
      "Epoch 579/1599:\ttrain Loss: 2.0336 Acc: 0.8475\tval Loss: 2.0159 Acc: 0.9000\t\n",
      "Epoch 580/1599:\ttrain Loss: 2.0441 Acc: 0.8559\tval Loss: 2.0318 Acc: 0.9000\t\n",
      "Epoch 581/1599:\ttrain Loss: 2.0284 Acc: 0.8686\tval Loss: 2.0176 Acc: 0.9000\t\n",
      "Epoch 582/1599:\ttrain Loss: 2.0421 Acc: 0.8347\tval Loss: 2.0251 Acc: 0.9000\t\n",
      "Epoch 583/1599:\ttrain Loss: 2.0575 Acc: 0.7839\tval Loss: 2.0205 Acc: 0.9333\t\n",
      "Epoch 584/1599:\ttrain Loss: 2.0419 Acc: 0.8347\tval Loss: 2.0240 Acc: 0.8000\t\n",
      "Epoch 585/1599:\ttrain Loss: 2.0300 Acc: 0.9110\tval Loss: 2.0523 Acc: 0.8000\t\n",
      "Epoch 586/1599:\ttrain Loss: 2.0629 Acc: 0.8178\tval Loss: 2.0291 Acc: 0.8333\t\n",
      "Epoch 587/1599:\ttrain Loss: 2.0348 Acc: 0.8178\tval Loss: 2.0531 Acc: 0.8333\t\n",
      "Epoch 588/1599:\ttrain Loss: 2.0331 Acc: 0.8559\tval Loss: 2.0172 Acc: 0.9000\t\n",
      "Epoch 589/1599:\ttrain Loss: 2.0431 Acc: 0.8136\tval Loss: 2.0181 Acc: 0.9333\t\n",
      "Epoch 590/1599:\ttrain Loss: 2.0490 Acc: 0.8517\tval Loss: 2.0221 Acc: 0.8333\t\n",
      "Epoch 591/1599:\ttrain Loss: 2.0506 Acc: 0.8602\tval Loss: 2.0284 Acc: 0.8333\t\n",
      "Epoch 592/1599:\ttrain Loss: 2.0391 Acc: 0.8347\tval Loss: 2.0240 Acc: 0.8333\t\n",
      "Epoch 593/1599:\ttrain Loss: 2.0458 Acc: 0.8305\tval Loss: 2.0488 Acc: 0.8000\t\n",
      "Epoch 594/1599:\ttrain Loss: 2.0397 Acc: 0.8347\tval Loss: 2.0452 Acc: 0.9000\t\n",
      "Epoch 595/1599:\ttrain Loss: 2.0403 Acc: 0.8305\tval Loss: 2.0170 Acc: 0.9333\t\n",
      "Epoch 596/1599:\ttrain Loss: 2.0384 Acc: 0.8432\tval Loss: 2.0681 Acc: 0.7333\t\n",
      "Epoch 597/1599:\ttrain Loss: 2.0540 Acc: 0.7331\tval Loss: 2.0188 Acc: 0.9333\t\n",
      "Epoch 598/1599:\ttrain Loss: 2.0387 Acc: 0.8432\tval Loss: 2.0169 Acc: 0.9333\t\n",
      "Epoch 599/1599:\ttrain Loss: 2.0496 Acc: 0.8178\tval Loss: 2.0502 Acc: 0.8333\t\n",
      "Epoch 600/1599:\ttrain Loss: 2.0359 Acc: 0.7585\tval Loss: 2.0504 Acc: 0.8667\t\n",
      "Epoch 601/1599:\ttrain Loss: 2.0319 Acc: 0.8093\tval Loss: 2.0218 Acc: 0.8333\t\n",
      "Epoch 602/1599:\ttrain Loss: 2.0431 Acc: 0.8263\tval Loss: 2.0209 Acc: 0.9000\t\n",
      "Epoch 603/1599:\ttrain Loss: 2.0319 Acc: 0.8305\tval Loss: 2.0170 Acc: 0.9000\t\n",
      "Epoch 604/1599:\ttrain Loss: 2.0532 Acc: 0.7881\tval Loss: 2.0489 Acc: 0.9000\t\n",
      "Epoch 605/1599:\ttrain Loss: 2.0341 Acc: 0.8559\tval Loss: 2.0247 Acc: 0.9000\t\n",
      "Epoch 606/1599:\ttrain Loss: 2.0335 Acc: 0.8559\tval Loss: 2.0188 Acc: 0.8333\t\n",
      "Epoch 607/1599:\ttrain Loss: 2.0210 Acc: 0.8856\tval Loss: 2.0190 Acc: 0.9333\t\n",
      "Epoch 608/1599:\ttrain Loss: 2.0383 Acc: 0.8347\tval Loss: 2.0516 Acc: 0.8667\t\n",
      "Epoch 609/1599:\ttrain Loss: 2.0333 Acc: 0.8814\tval Loss: 2.0192 Acc: 0.9667\t\n",
      "Epoch 610/1599:\ttrain Loss: 2.0405 Acc: 0.8983\tval Loss: 2.0265 Acc: 0.8667\t\n",
      "Epoch 611/1599:\ttrain Loss: 2.0468 Acc: 0.8136\tval Loss: 2.0199 Acc: 0.9000\t\n",
      "Epoch 612/1599:\ttrain Loss: 2.0361 Acc: 0.8559\tval Loss: 2.0269 Acc: 0.9333\t\n",
      "Epoch 613/1599:\ttrain Loss: 2.0310 Acc: 0.8475\tval Loss: 2.0286 Acc: 0.8667\t\n",
      "Epoch 614/1599:\ttrain Loss: 2.0370 Acc: 0.8602\tval Loss: 2.0190 Acc: 0.9000\t\n",
      "Epoch 615/1599:\ttrain Loss: 2.0473 Acc: 0.8305\tval Loss: 2.0205 Acc: 0.9000\t\n",
      "Epoch 616/1599:\ttrain Loss: 2.0536 Acc: 0.8178\tval Loss: 2.0165 Acc: 0.9333\t\n",
      "Epoch 617/1599:\ttrain Loss: 2.0344 Acc: 0.8771\tval Loss: 2.0177 Acc: 0.9333\t\n",
      "Epoch 618/1599:\ttrain Loss: 2.0395 Acc: 0.8517\tval Loss: 2.0188 Acc: 0.9000\t\n",
      "Epoch 619/1599:\ttrain Loss: 2.0325 Acc: 0.8729\tval Loss: 2.0576 Acc: 0.7667\t\n",
      "Epoch 620/1599:\ttrain Loss: 2.0295 Acc: 0.8983\tval Loss: 2.0304 Acc: 0.8667\t\n",
      "Epoch 621/1599:\ttrain Loss: 2.0342 Acc: 0.8559\tval Loss: 2.0201 Acc: 0.8667\t\n",
      "Epoch 622/1599:\ttrain Loss: 2.0379 Acc: 0.8602\tval Loss: 2.0443 Acc: 0.8333\t\n",
      "Epoch 623/1599:\ttrain Loss: 2.0350 Acc: 0.8644\tval Loss: 2.0431 Acc: 0.8667\t\n",
      "Epoch 624/1599:\ttrain Loss: 2.0421 Acc: 0.8263\tval Loss: 2.0189 Acc: 0.9333\t\n",
      "Epoch 625/1599:\ttrain Loss: 2.0483 Acc: 0.8602\tval Loss: 2.0205 Acc: 0.8333\t\n",
      "Epoch 626/1599:\ttrain Loss: 2.0328 Acc: 0.8898\tval Loss: 2.0252 Acc: 0.8333\t\n",
      "Epoch 627/1599:\ttrain Loss: 2.0335 Acc: 0.8983\tval Loss: 2.0181 Acc: 0.9333\t\n",
      "Epoch 628/1599:\ttrain Loss: 2.0502 Acc: 0.8517\tval Loss: 2.0255 Acc: 0.9333\t\n",
      "Epoch 629/1599:\ttrain Loss: 2.0354 Acc: 0.8941\tval Loss: 2.0285 Acc: 0.7667\t\n",
      "Epoch 630/1599:\ttrain Loss: 2.0459 Acc: 0.8178\tval Loss: 2.0298 Acc: 0.9333\t\n",
      "Epoch 631/1599:\ttrain Loss: 2.0317 Acc: 0.8898\tval Loss: 2.0208 Acc: 0.9000\t\n",
      "Epoch 632/1599:\ttrain Loss: 2.0478 Acc: 0.8559\tval Loss: 2.0458 Acc: 0.7333\t\n",
      "Epoch 633/1599:\ttrain Loss: 2.0342 Acc: 0.8856\tval Loss: 2.0193 Acc: 0.8333\t\n",
      "Epoch 634/1599:\ttrain Loss: 2.0330 Acc: 0.8771\tval Loss: 2.0162 Acc: 0.9667\t\n",
      "Epoch 635/1599:\ttrain Loss: 2.0300 Acc: 0.9153\tval Loss: 2.0360 Acc: 0.9000\t\n",
      "Epoch 636/1599:\ttrain Loss: 2.0333 Acc: 0.8814\tval Loss: 2.0166 Acc: 0.9333\t\n",
      "Epoch 637/1599:\ttrain Loss: 2.0447 Acc: 0.8771\tval Loss: 2.0138 Acc: 0.9667\t\n",
      "Epoch 638/1599:\ttrain Loss: 2.0299 Acc: 0.9110\tval Loss: 2.0216 Acc: 0.8667\t\n",
      "Epoch 639/1599:\ttrain Loss: 2.0358 Acc: 0.8602\tval Loss: 2.0182 Acc: 0.8667\t\n",
      "Epoch 640/1599:\ttrain Loss: 2.0402 Acc: 0.9025\tval Loss: 2.0178 Acc: 0.9000\t\n",
      "Epoch 641/1599:\ttrain Loss: 2.0417 Acc: 0.8602\tval Loss: 2.0184 Acc: 0.9000\t\n",
      "Epoch 642/1599:\ttrain Loss: 2.0376 Acc: 0.8856\tval Loss: 2.0168 Acc: 0.9667\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 643/1599:\ttrain Loss: 2.0405 Acc: 0.8686\tval Loss: 2.0178 Acc: 0.9000\t\n",
      "Epoch 644/1599:\ttrain Loss: 2.0369 Acc: 0.9025\tval Loss: 2.0220 Acc: 0.9000\t\n",
      "Epoch 645/1599:\ttrain Loss: 2.0289 Acc: 0.9237\tval Loss: 2.0163 Acc: 0.9667\t\n",
      "Epoch 646/1599:\ttrain Loss: 2.0361 Acc: 0.8686\tval Loss: 2.0182 Acc: 0.9667\t\n",
      "Epoch 647/1599:\ttrain Loss: 2.0350 Acc: 0.8644\tval Loss: 2.0240 Acc: 0.9667\t\n",
      "Epoch 648/1599:\ttrain Loss: 2.0286 Acc: 0.9237\tval Loss: 2.0183 Acc: 0.8667\t\n",
      "Epoch 649/1599:\ttrain Loss: 2.0326 Acc: 0.8856\tval Loss: 2.0156 Acc: 0.9333\t\n",
      "Epoch 650/1599:\ttrain Loss: 2.0442 Acc: 0.8771\tval Loss: 2.0154 Acc: 0.9333\t\n",
      "Epoch 651/1599:\ttrain Loss: 2.0409 Acc: 0.8729\tval Loss: 2.0619 Acc: 0.7667\t\n",
      "Epoch 652/1599:\ttrain Loss: 2.0246 Acc: 0.8898\tval Loss: 2.0217 Acc: 0.8667\t\n",
      "Epoch 653/1599:\ttrain Loss: 2.0372 Acc: 0.8178\tval Loss: 2.0451 Acc: 0.9000\t\n",
      "Epoch 654/1599:\ttrain Loss: 2.0415 Acc: 0.8729\tval Loss: 2.0360 Acc: 0.8667\t\n",
      "Epoch 655/1599:\ttrain Loss: 2.0355 Acc: 0.8814\tval Loss: 2.0176 Acc: 0.9667\t\n",
      "Epoch 656/1599:\ttrain Loss: 2.0448 Acc: 0.8983\tval Loss: 2.0326 Acc: 0.9000\t\n",
      "Epoch 657/1599:\ttrain Loss: 2.0383 Acc: 0.8898\tval Loss: 2.0213 Acc: 0.8667\t\n",
      "Epoch 658/1599:\ttrain Loss: 2.0399 Acc: 0.8729\tval Loss: 2.0561 Acc: 0.8333\t\n",
      "Epoch 659/1599:\ttrain Loss: 2.0463 Acc: 0.8220\tval Loss: 2.0417 Acc: 0.8333\t\n",
      "Epoch 660/1599:\ttrain Loss: 2.0519 Acc: 0.7839\tval Loss: 2.0275 Acc: 0.9000\t\n",
      "Epoch 661/1599:\ttrain Loss: 2.0334 Acc: 0.8856\tval Loss: 2.0435 Acc: 0.7667\t\n",
      "Epoch 662/1599:\ttrain Loss: 2.0398 Acc: 0.8729\tval Loss: 2.0176 Acc: 0.8333\t\n",
      "Epoch 663/1599:\ttrain Loss: 2.0284 Acc: 0.8729\tval Loss: 2.0194 Acc: 0.9000\t\n",
      "Epoch 664/1599:\ttrain Loss: 2.0373 Acc: 0.8814\tval Loss: 2.0176 Acc: 0.9000\t\n",
      "Epoch 665/1599:\ttrain Loss: 2.0396 Acc: 0.8729\tval Loss: 2.0431 Acc: 0.9000\t\n",
      "Epoch 666/1599:\ttrain Loss: 2.0245 Acc: 0.9195\tval Loss: 2.0181 Acc: 0.9000\t\n",
      "Epoch 667/1599:\ttrain Loss: 2.0301 Acc: 0.8856\tval Loss: 2.0218 Acc: 0.8000\t\n",
      "Epoch 668/1599:\ttrain Loss: 2.0302 Acc: 0.9068\tval Loss: 2.0216 Acc: 0.8667\t\n",
      "Epoch 669/1599:\ttrain Loss: 2.0318 Acc: 0.9110\tval Loss: 2.0276 Acc: 0.8000\t\n",
      "Epoch 670/1599:\ttrain Loss: 2.0490 Acc: 0.8602\tval Loss: 2.0187 Acc: 0.9333\t\n",
      "Epoch 671/1599:\ttrain Loss: 2.0369 Acc: 0.9025\tval Loss: 2.0197 Acc: 0.8667\t\n",
      "Epoch 672/1599:\ttrain Loss: 2.0349 Acc: 0.8898\tval Loss: 2.0198 Acc: 0.9000\t\n",
      "Epoch 673/1599:\ttrain Loss: 2.0345 Acc: 0.8814\tval Loss: 2.0201 Acc: 0.9000\t\n",
      "Epoch 674/1599:\ttrain Loss: 2.0318 Acc: 0.9068\tval Loss: 2.0184 Acc: 0.9333\t\n",
      "Epoch 675/1599:\ttrain Loss: 2.0326 Acc: 0.9110\tval Loss: 2.0250 Acc: 0.8667\t\n",
      "Epoch 676/1599:\ttrain Loss: 2.0316 Acc: 0.9153\tval Loss: 2.0401 Acc: 0.8667\t\n",
      "Epoch 677/1599:\ttrain Loss: 2.0368 Acc: 0.8941\tval Loss: 2.0169 Acc: 0.9333\t\n",
      "Epoch 678/1599:\ttrain Loss: 2.0531 Acc: 0.8432\tval Loss: 2.0236 Acc: 0.8333\t\n",
      "Epoch 679/1599:\ttrain Loss: 2.0479 Acc: 0.8814\tval Loss: 2.0184 Acc: 0.9333\t\n",
      "Epoch 680/1599:\ttrain Loss: 2.0321 Acc: 0.9025\tval Loss: 2.0185 Acc: 0.9333\t\n",
      "Epoch 681/1599:\ttrain Loss: 2.0196 Acc: 0.9407\tval Loss: 2.0236 Acc: 0.8667\t\n",
      "Epoch 682/1599:\ttrain Loss: 2.0279 Acc: 0.9237\tval Loss: 2.0168 Acc: 0.9667\t\n",
      "Epoch 683/1599:\ttrain Loss: 2.0321 Acc: 0.8686\tval Loss: 2.0167 Acc: 0.9333\t\n",
      "Epoch 684/1599:\ttrain Loss: 2.0394 Acc: 0.8856\tval Loss: 2.0174 Acc: 0.9667\t\n",
      "Epoch 685/1599:\ttrain Loss: 2.0439 Acc: 0.9110\tval Loss: 2.0164 Acc: 0.9000\t\n",
      "Epoch 686/1599:\ttrain Loss: 2.0285 Acc: 0.9280\tval Loss: 2.0172 Acc: 0.9000\t\n",
      "Epoch 687/1599:\ttrain Loss: 2.0400 Acc: 0.9025\tval Loss: 2.0197 Acc: 0.9000\t\n",
      "Epoch 688/1599:\ttrain Loss: 2.0421 Acc: 0.9025\tval Loss: 2.0204 Acc: 0.9000\t\n",
      "Epoch 689/1599:\ttrain Loss: 2.0356 Acc: 0.8856\tval Loss: 2.0182 Acc: 0.9333\t\n",
      "Epoch 690/1599:\ttrain Loss: 2.0322 Acc: 0.8517\tval Loss: 2.0295 Acc: 0.8000\t\n",
      "Epoch 691/1599:\ttrain Loss: 2.0425 Acc: 0.8220\tval Loss: 2.0169 Acc: 0.9333\t\n",
      "Epoch 692/1599:\ttrain Loss: 2.0240 Acc: 0.8983\tval Loss: 2.0432 Acc: 0.8667\t\n",
      "Epoch 693/1599:\ttrain Loss: 2.0352 Acc: 0.8856\tval Loss: 2.0196 Acc: 0.9333\t\n",
      "Epoch 694/1599:\ttrain Loss: 2.0251 Acc: 0.9237\tval Loss: 2.0176 Acc: 0.9667\t\n",
      "Epoch 695/1599:\ttrain Loss: 2.0277 Acc: 0.9153\tval Loss: 2.0181 Acc: 0.9667\t\n",
      "Epoch 696/1599:\ttrain Loss: 2.0279 Acc: 0.9153\tval Loss: 2.0140 Acc: 0.9667\t\n",
      "Epoch 697/1599:\ttrain Loss: 2.0321 Acc: 0.8814\tval Loss: 2.0157 Acc: 0.9667\t\n",
      "Epoch 698/1599:\ttrain Loss: 2.0356 Acc: 0.9068\tval Loss: 2.0169 Acc: 0.9333\t\n",
      "Epoch 699/1599:\ttrain Loss: 2.0312 Acc: 0.9110\tval Loss: 2.0146 Acc: 0.9333\t\n",
      "Epoch 700/1599:\ttrain Loss: 2.0388 Acc: 0.8475\tval Loss: 2.0181 Acc: 0.9333\t\n",
      "Epoch 701/1599:\ttrain Loss: 2.0317 Acc: 0.8941\tval Loss: 2.0226 Acc: 0.8667\t\n",
      "Epoch 702/1599:\ttrain Loss: 2.0326 Acc: 0.9068\tval Loss: 2.0438 Acc: 0.8333\t\n",
      "Epoch 703/1599:\ttrain Loss: 2.0282 Acc: 0.8941\tval Loss: 2.0525 Acc: 0.8667\t\n",
      "Epoch 704/1599:\ttrain Loss: 2.0366 Acc: 0.8729\tval Loss: 2.0169 Acc: 0.9333\t\n",
      "Epoch 705/1599:\ttrain Loss: 2.0329 Acc: 0.8729\tval Loss: 2.0174 Acc: 0.9000\t\n",
      "Epoch 706/1599:\ttrain Loss: 2.0340 Acc: 0.8983\tval Loss: 2.0185 Acc: 0.9333\t\n",
      "Epoch 707/1599:\ttrain Loss: 2.0281 Acc: 0.9364\tval Loss: 2.0162 Acc: 0.9333\t\n",
      "Epoch 708/1599:\ttrain Loss: 2.0316 Acc: 0.8856\tval Loss: 2.0501 Acc: 0.8667\t\n",
      "Epoch 709/1599:\ttrain Loss: 2.0236 Acc: 0.9449\tval Loss: 2.0163 Acc: 0.9333\t\n",
      "Epoch 710/1599:\ttrain Loss: 2.0281 Acc: 0.9237\tval Loss: 2.0165 Acc: 0.9667\t\n",
      "Epoch 711/1599:\ttrain Loss: 2.0245 Acc: 0.9068\tval Loss: 2.0164 Acc: 0.9000\t\n",
      "Epoch 712/1599:\ttrain Loss: 2.0358 Acc: 0.9068\tval Loss: 2.0289 Acc: 0.8667\t\n",
      "Epoch 713/1599:\ttrain Loss: 2.0193 Acc: 0.9280\tval Loss: 2.0420 Acc: 0.8000\t\n",
      "Epoch 714/1599:\ttrain Loss: 2.0367 Acc: 0.8814\tval Loss: 2.0156 Acc: 0.9667\t\n",
      "Epoch 715/1599:\ttrain Loss: 2.0355 Acc: 0.8983\tval Loss: 2.0178 Acc: 0.9333\t\n",
      "Epoch 716/1599:\ttrain Loss: 2.0325 Acc: 0.9237\tval Loss: 2.0184 Acc: 0.8667\t\n",
      "Epoch 717/1599:\ttrain Loss: 2.0325 Acc: 0.9153\tval Loss: 2.0147 Acc: 0.9333\t\n",
      "Epoch 718/1599:\ttrain Loss: 2.0280 Acc: 0.8898\tval Loss: 2.0143 Acc: 0.9333\t\n",
      "Epoch 719/1599:\ttrain Loss: 2.0320 Acc: 0.8983\tval Loss: 2.0348 Acc: 0.8667\t\n",
      "Epoch 720/1599:\ttrain Loss: 2.0400 Acc: 0.8771\tval Loss: 2.0160 Acc: 0.9667\t\n",
      "Epoch 721/1599:\ttrain Loss: 2.0477 Acc: 0.8983\tval Loss: 2.0169 Acc: 0.9333\t\n",
      "Epoch 722/1599:\ttrain Loss: 2.0231 Acc: 0.9534\tval Loss: 2.0163 Acc: 0.9333\t\n",
      "Epoch 723/1599:\ttrain Loss: 2.0267 Acc: 0.9280\tval Loss: 2.0173 Acc: 0.8667\t\n",
      "Epoch 724/1599:\ttrain Loss: 2.0472 Acc: 0.9153\tval Loss: 2.0173 Acc: 0.9333\t\n",
      "Epoch 725/1599:\ttrain Loss: 2.0326 Acc: 0.8983\tval Loss: 2.0169 Acc: 0.8333\t\n",
      "Epoch 726/1599:\ttrain Loss: 2.0464 Acc: 0.8856\tval Loss: 2.0164 Acc: 0.9000\t\n",
      "Epoch 727/1599:\ttrain Loss: 2.0157 Acc: 0.9619\tval Loss: 2.0217 Acc: 0.9000\t\n",
      "Epoch 728/1599:\ttrain Loss: 2.0400 Acc: 0.8559\tval Loss: 2.0142 Acc: 0.9333\t\n",
      "Epoch 729/1599:\ttrain Loss: 2.0405 Acc: 0.9110\tval Loss: 2.0151 Acc: 0.9667\t\n",
      "Epoch 730/1599:\ttrain Loss: 2.0401 Acc: 0.9110\tval Loss: 2.0156 Acc: 0.9333\t\n",
      "Epoch 731/1599:\ttrain Loss: 2.0234 Acc: 0.9449\tval Loss: 2.0248 Acc: 0.8667\t\n",
      "Epoch 732/1599:\ttrain Loss: 2.0324 Acc: 0.9322\tval Loss: 2.0160 Acc: 0.9000\t\n",
      "Epoch 733/1599:\ttrain Loss: 2.0311 Acc: 0.9449\tval Loss: 2.0175 Acc: 0.9333\t\n",
      "Epoch 734/1599:\ttrain Loss: 2.0348 Acc: 0.9237\tval Loss: 2.0159 Acc: 0.9667\t\n",
      "Epoch 735/1599:\ttrain Loss: 2.0284 Acc: 0.9407\tval Loss: 2.0165 Acc: 0.9333\t\n",
      "Epoch 736/1599:\ttrain Loss: 2.0408 Acc: 0.9237\tval Loss: 2.0274 Acc: 0.9000\t\n",
      "Epoch 737/1599:\ttrain Loss: 2.0484 Acc: 0.8644\tval Loss: 2.0185 Acc: 0.9000\t\n",
      "Epoch 738/1599:\ttrain Loss: 2.0379 Acc: 0.9025\tval Loss: 2.0180 Acc: 0.9000\t\n",
      "Epoch 739/1599:\ttrain Loss: 2.0404 Acc: 0.9280\tval Loss: 2.0169 Acc: 0.8667\t\n",
      "Epoch 740/1599:\ttrain Loss: 2.0274 Acc: 0.9153\tval Loss: 2.0363 Acc: 0.9667\t\n",
      "Epoch 741/1599:\ttrain Loss: 2.0354 Acc: 0.9322\tval Loss: 2.0328 Acc: 0.8333\t\n",
      "Epoch 742/1599:\ttrain Loss: 2.0351 Acc: 0.9280\tval Loss: 2.0150 Acc: 0.9000\t\n",
      "Epoch 743/1599:\ttrain Loss: 2.0304 Acc: 0.9364\tval Loss: 2.0245 Acc: 0.8667\t\n",
      "Epoch 744/1599:\ttrain Loss: 2.0372 Acc: 0.9025\tval Loss: 2.0172 Acc: 0.9333\t\n",
      "Epoch 745/1599:\ttrain Loss: 2.0388 Acc: 0.8983\tval Loss: 2.0156 Acc: 0.9333\t\n",
      "Epoch 746/1599:\ttrain Loss: 2.0361 Acc: 0.8856\tval Loss: 2.0169 Acc: 0.9000\t\n",
      "Epoch 747/1599:\ttrain Loss: 2.0401 Acc: 0.8898\tval Loss: 2.0344 Acc: 0.9000\t\n",
      "Epoch 748/1599:\ttrain Loss: 2.0315 Acc: 0.9364\tval Loss: 2.0163 Acc: 0.9000\t\n",
      "Epoch 749/1599:\ttrain Loss: 2.0311 Acc: 0.9449\tval Loss: 2.0156 Acc: 0.9000\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 750/1599:\ttrain Loss: 2.0252 Acc: 0.9449\tval Loss: 2.0176 Acc: 0.9333\t\n",
      "Epoch 751/1599:\ttrain Loss: 2.0238 Acc: 0.9322\tval Loss: 2.0256 Acc: 0.9000\t\n",
      "Epoch 752/1599:\ttrain Loss: 2.0534 Acc: 0.8644\tval Loss: 2.0259 Acc: 0.9000\t\n",
      "Epoch 753/1599:\ttrain Loss: 2.0299 Acc: 0.9195\tval Loss: 2.0206 Acc: 0.8667\t\n",
      "Epoch 754/1599:\ttrain Loss: 2.0301 Acc: 0.8983\tval Loss: 2.0201 Acc: 0.9333\t\n",
      "Epoch 755/1599:\ttrain Loss: 2.0395 Acc: 0.9025\tval Loss: 2.0196 Acc: 0.8667\t\n",
      "Epoch 756/1599:\ttrain Loss: 2.0336 Acc: 0.8856\tval Loss: 2.0167 Acc: 0.9000\t\n",
      "Epoch 757/1599:\ttrain Loss: 2.0444 Acc: 0.8941\tval Loss: 2.0196 Acc: 0.8667\t\n",
      "Epoch 758/1599:\ttrain Loss: 2.0346 Acc: 0.8941\tval Loss: 2.0250 Acc: 0.9333\t\n",
      "Epoch 759/1599:\ttrain Loss: 2.0196 Acc: 0.9153\tval Loss: 2.0202 Acc: 0.9667\t\n",
      "Epoch 760/1599:\ttrain Loss: 2.0380 Acc: 0.8983\tval Loss: 2.0168 Acc: 0.9333\t\n",
      "Epoch 761/1599:\ttrain Loss: 2.0398 Acc: 0.8898\tval Loss: 2.0155 Acc: 1.0000\t\n",
      "Epoch 762/1599:\ttrain Loss: 2.0320 Acc: 0.9025\tval Loss: 2.0157 Acc: 0.9000\t\n",
      "Epoch 763/1599:\ttrain Loss: 2.0419 Acc: 0.8686\tval Loss: 2.0167 Acc: 0.9667\t\n",
      "Epoch 764/1599:\ttrain Loss: 2.0236 Acc: 0.9364\tval Loss: 2.0328 Acc: 0.9333\t\n",
      "Epoch 765/1599:\ttrain Loss: 2.0327 Acc: 0.9364\tval Loss: 2.0156 Acc: 0.9000\t\n",
      "Epoch 766/1599:\ttrain Loss: 2.0349 Acc: 0.8814\tval Loss: 2.0175 Acc: 0.9667\t\n",
      "Epoch 767/1599:\ttrain Loss: 2.0266 Acc: 0.9407\tval Loss: 2.0192 Acc: 0.9667\t\n",
      "Epoch 768/1599:\ttrain Loss: 2.0354 Acc: 0.9237\tval Loss: 2.0201 Acc: 0.9333\t\n",
      "Epoch 769/1599:\ttrain Loss: 2.0284 Acc: 0.9322\tval Loss: 2.0217 Acc: 0.8667\t\n",
      "Epoch 770/1599:\ttrain Loss: 2.0358 Acc: 0.8983\tval Loss: 2.0170 Acc: 0.8667\t\n",
      "Epoch 771/1599:\ttrain Loss: 2.0381 Acc: 0.8771\tval Loss: 2.0220 Acc: 0.9000\t\n",
      "Epoch 772/1599:\ttrain Loss: 2.0315 Acc: 0.9364\tval Loss: 2.0204 Acc: 0.8333\t\n",
      "Epoch 773/1599:\ttrain Loss: 2.0228 Acc: 0.9449\tval Loss: 2.0155 Acc: 0.9667\t\n",
      "Epoch 774/1599:\ttrain Loss: 2.0399 Acc: 0.9068\tval Loss: 2.0248 Acc: 0.9000\t\n",
      "Epoch 775/1599:\ttrain Loss: 2.0348 Acc: 0.9280\tval Loss: 2.0235 Acc: 0.8667\t\n",
      "Epoch 776/1599:\ttrain Loss: 2.0282 Acc: 0.9195\tval Loss: 2.0155 Acc: 0.9667\t\n",
      "Epoch 777/1599:\ttrain Loss: 2.0346 Acc: 0.9068\tval Loss: 2.0333 Acc: 0.8667\t\n",
      "Epoch 778/1599:\ttrain Loss: 2.0301 Acc: 0.9322\tval Loss: 2.0169 Acc: 0.9667\t\n",
      "Epoch 779/1599:\ttrain Loss: 2.0233 Acc: 0.9534\tval Loss: 2.0177 Acc: 0.9667\t\n",
      "Epoch 780/1599:\ttrain Loss: 2.0307 Acc: 0.9407\tval Loss: 2.0163 Acc: 0.9667\t\n",
      "Epoch 781/1599:\ttrain Loss: 2.0397 Acc: 0.8856\tval Loss: 2.0167 Acc: 0.9000\t\n",
      "Epoch 782/1599:\ttrain Loss: 2.0436 Acc: 0.8814\tval Loss: 2.0157 Acc: 0.9000\t\n",
      "Epoch 783/1599:\ttrain Loss: 2.0426 Acc: 0.8941\tval Loss: 2.0165 Acc: 0.9667\t\n",
      "Epoch 784/1599:\ttrain Loss: 2.0273 Acc: 0.9280\tval Loss: 2.0180 Acc: 0.8667\t\n",
      "Epoch 785/1599:\ttrain Loss: 2.0378 Acc: 0.9025\tval Loss: 2.0217 Acc: 0.9333\t\n",
      "Epoch 786/1599:\ttrain Loss: 2.0384 Acc: 0.9153\tval Loss: 2.0174 Acc: 0.8667\t\n",
      "Epoch 787/1599:\ttrain Loss: 2.0377 Acc: 0.9153\tval Loss: 2.0168 Acc: 0.9000\t\n",
      "Epoch 788/1599:\ttrain Loss: 2.0433 Acc: 0.9237\tval Loss: 2.0158 Acc: 0.9000\t\n",
      "Epoch 789/1599:\ttrain Loss: 2.0292 Acc: 0.9237\tval Loss: 2.0172 Acc: 0.9000\t\n",
      "Epoch 790/1599:\ttrain Loss: 2.0356 Acc: 0.9025\tval Loss: 2.0183 Acc: 0.9000\t\n",
      "Epoch 791/1599:\ttrain Loss: 2.0325 Acc: 0.9322\tval Loss: 2.0178 Acc: 0.8667\t\n",
      "Epoch 792/1599:\ttrain Loss: 2.0270 Acc: 0.9492\tval Loss: 2.0153 Acc: 0.9333\t\n",
      "Epoch 793/1599:\ttrain Loss: 2.0268 Acc: 0.9449\tval Loss: 2.0162 Acc: 0.9000\t\n",
      "Epoch 794/1599:\ttrain Loss: 2.0295 Acc: 0.9576\tval Loss: 2.0163 Acc: 0.9667\t\n",
      "Epoch 795/1599:\ttrain Loss: 2.0321 Acc: 0.9237\tval Loss: 2.0223 Acc: 0.8667\t\n",
      "Epoch 796/1599:\ttrain Loss: 2.0410 Acc: 0.9025\tval Loss: 2.0264 Acc: 0.9333\t\n",
      "Epoch 797/1599:\ttrain Loss: 2.0371 Acc: 0.8771\tval Loss: 2.0234 Acc: 0.8667\t\n",
      "Epoch 798/1599:\ttrain Loss: 2.0321 Acc: 0.9237\tval Loss: 2.0187 Acc: 0.8667\t\n",
      "Epoch 799/1599:\ttrain Loss: 2.0529 Acc: 0.8136\tval Loss: 2.0241 Acc: 0.8667\t\n",
      "Epoch 800/1599:\ttrain Loss: 2.0254 Acc: 0.9237\tval Loss: 2.0186 Acc: 0.9333\t\n",
      "Epoch 801/1599:\ttrain Loss: 2.0315 Acc: 0.9068\tval Loss: 2.0183 Acc: 0.9667\t\n",
      "Epoch 802/1599:\ttrain Loss: 2.0398 Acc: 0.9025\tval Loss: 2.0281 Acc: 0.9667\t\n",
      "Epoch 803/1599:\ttrain Loss: 2.0236 Acc: 0.9492\tval Loss: 2.0168 Acc: 0.9333\t\n",
      "Epoch 804/1599:\ttrain Loss: 2.0279 Acc: 0.9322\tval Loss: 2.0197 Acc: 0.8667\t\n",
      "Epoch 805/1599:\ttrain Loss: 2.0254 Acc: 0.9576\tval Loss: 2.0186 Acc: 0.9333\t\n",
      "Epoch 806/1599:\ttrain Loss: 2.0426 Acc: 0.8983\tval Loss: 2.0166 Acc: 0.8333\t\n",
      "Epoch 807/1599:\ttrain Loss: 2.0442 Acc: 0.8983\tval Loss: 2.0177 Acc: 0.8333\t\n",
      "Epoch 808/1599:\ttrain Loss: 2.0324 Acc: 0.9407\tval Loss: 2.0220 Acc: 0.9000\t\n",
      "Epoch 809/1599:\ttrain Loss: 2.0348 Acc: 0.9322\tval Loss: 2.0168 Acc: 0.9333\t\n",
      "Epoch 810/1599:\ttrain Loss: 2.0308 Acc: 0.9322\tval Loss: 2.0173 Acc: 0.9000\t\n",
      "Epoch 811/1599:\ttrain Loss: 2.0228 Acc: 0.9534\tval Loss: 2.0156 Acc: 0.9000\t\n",
      "Epoch 812/1599:\ttrain Loss: 2.0193 Acc: 0.9661\tval Loss: 2.0163 Acc: 0.9000\t\n",
      "Epoch 813/1599:\ttrain Loss: 2.0307 Acc: 0.9449\tval Loss: 2.0179 Acc: 0.8667\t\n",
      "Epoch 814/1599:\ttrain Loss: 2.0435 Acc: 0.9195\tval Loss: 2.0166 Acc: 0.9000\t\n",
      "Epoch 815/1599:\ttrain Loss: 2.0344 Acc: 0.9449\tval Loss: 2.0163 Acc: 0.9000\t\n",
      "Epoch 816/1599:\ttrain Loss: 2.0302 Acc: 0.9492\tval Loss: 2.0161 Acc: 0.9000\t\n",
      "Epoch 817/1599:\ttrain Loss: 2.0368 Acc: 0.9322\tval Loss: 2.0165 Acc: 0.9000\t\n",
      "Epoch 818/1599:\ttrain Loss: 2.0176 Acc: 0.9703\tval Loss: 2.0183 Acc: 0.9000\t\n",
      "Epoch 819/1599:\ttrain Loss: 2.0228 Acc: 0.9661\tval Loss: 2.0176 Acc: 1.0000\t\n",
      "Epoch 820/1599:\ttrain Loss: 2.0293 Acc: 0.9449\tval Loss: 2.0186 Acc: 0.9000\t\n",
      "Epoch 821/1599:\ttrain Loss: 2.0378 Acc: 0.9322\tval Loss: 2.0265 Acc: 0.9333\t\n",
      "Epoch 822/1599:\ttrain Loss: 2.0403 Acc: 0.8941\tval Loss: 2.0213 Acc: 0.8667\t\n",
      "Epoch 823/1599:\ttrain Loss: 2.0312 Acc: 0.9237\tval Loss: 2.0152 Acc: 0.8667\t\n",
      "Epoch 824/1599:\ttrain Loss: 2.0503 Acc: 0.8136\tval Loss: 2.0215 Acc: 0.8667\t\n",
      "Epoch 825/1599:\ttrain Loss: 2.0375 Acc: 0.8856\tval Loss: 2.0165 Acc: 0.9000\t\n",
      "Epoch 826/1599:\ttrain Loss: 2.0251 Acc: 0.8983\tval Loss: 2.0196 Acc: 0.8333\t\n",
      "Epoch 827/1599:\ttrain Loss: 2.0461 Acc: 0.8220\tval Loss: 2.0198 Acc: 0.8333\t\n",
      "Epoch 828/1599:\ttrain Loss: 2.0309 Acc: 0.8983\tval Loss: 2.0181 Acc: 0.9333\t\n",
      "Epoch 829/1599:\ttrain Loss: 2.0414 Acc: 0.8305\tval Loss: 2.0240 Acc: 0.8333\t\n",
      "Epoch 830/1599:\ttrain Loss: 2.0428 Acc: 0.8517\tval Loss: 2.0370 Acc: 0.8333\t\n",
      "Epoch 831/1599:\ttrain Loss: 2.0531 Acc: 0.8051\tval Loss: 2.0174 Acc: 0.9000\t\n",
      "Epoch 832/1599:\ttrain Loss: 2.0344 Acc: 0.8432\tval Loss: 2.0184 Acc: 0.9000\t\n",
      "Epoch 833/1599:\ttrain Loss: 2.0462 Acc: 0.8644\tval Loss: 2.0216 Acc: 0.8667\t\n",
      "Epoch 834/1599:\ttrain Loss: 2.0375 Acc: 0.8559\tval Loss: 2.0478 Acc: 0.8333\t\n",
      "Epoch 835/1599:\ttrain Loss: 2.0414 Acc: 0.8559\tval Loss: 2.0229 Acc: 0.9000\t\n",
      "Epoch 836/1599:\ttrain Loss: 2.0450 Acc: 0.8390\tval Loss: 2.0173 Acc: 0.9000\t\n",
      "Epoch 837/1599:\ttrain Loss: 2.0326 Acc: 0.9068\tval Loss: 2.0312 Acc: 0.8667\t\n",
      "Epoch 838/1599:\ttrain Loss: 2.0451 Acc: 0.8729\tval Loss: 2.0225 Acc: 0.9000\t\n",
      "Epoch 839/1599:\ttrain Loss: 2.0296 Acc: 0.9068\tval Loss: 2.0200 Acc: 0.8333\t\n",
      "Epoch 840/1599:\ttrain Loss: 2.0344 Acc: 0.9025\tval Loss: 2.0172 Acc: 0.8667\t\n",
      "Epoch 841/1599:\ttrain Loss: 2.0319 Acc: 0.9237\tval Loss: 2.0197 Acc: 0.9000\t\n",
      "Epoch 842/1599:\ttrain Loss: 2.0327 Acc: 0.9110\tval Loss: 2.0188 Acc: 0.8667\t\n",
      "Epoch 843/1599:\ttrain Loss: 2.0365 Acc: 0.9110\tval Loss: 2.0168 Acc: 0.8667\t\n",
      "Epoch 844/1599:\ttrain Loss: 2.0335 Acc: 0.8983\tval Loss: 2.0175 Acc: 0.8667\t\n",
      "Epoch 845/1599:\ttrain Loss: 2.0393 Acc: 0.8729\tval Loss: 2.0167 Acc: 0.9000\t\n",
      "Epoch 846/1599:\ttrain Loss: 2.0399 Acc: 0.8305\tval Loss: 2.0184 Acc: 0.8000\t\n",
      "Epoch 847/1599:\ttrain Loss: 2.0411 Acc: 0.8432\tval Loss: 2.0176 Acc: 0.9000\t\n",
      "Epoch 848/1599:\ttrain Loss: 2.0439 Acc: 0.8517\tval Loss: 2.0159 Acc: 0.9667\t\n",
      "Epoch 849/1599:\ttrain Loss: 2.0463 Acc: 0.8432\tval Loss: 2.0180 Acc: 0.9333\t\n",
      "Epoch 850/1599:\ttrain Loss: 2.0416 Acc: 0.8644\tval Loss: 2.0209 Acc: 0.9000\t\n",
      "Epoch 851/1599:\ttrain Loss: 2.0366 Acc: 0.8517\tval Loss: 2.0211 Acc: 0.8333\t\n",
      "Epoch 852/1599:\ttrain Loss: 2.0409 Acc: 0.9153\tval Loss: 2.0178 Acc: 0.9667\t\n",
      "Epoch 853/1599:\ttrain Loss: 2.0296 Acc: 0.9025\tval Loss: 2.0265 Acc: 0.8667\t\n",
      "Epoch 854/1599:\ttrain Loss: 2.0385 Acc: 0.8898\tval Loss: 2.0179 Acc: 0.9000\t\n",
      "Epoch 855/1599:\ttrain Loss: 2.0404 Acc: 0.9068\tval Loss: 2.0223 Acc: 0.9333\t\n",
      "Epoch 856/1599:\ttrain Loss: 2.0196 Acc: 0.9492\tval Loss: 2.0170 Acc: 0.9333\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 857/1599:\ttrain Loss: 2.0358 Acc: 0.9068\tval Loss: 2.0204 Acc: 0.9667\t\n",
      "Epoch 858/1599:\ttrain Loss: 2.0234 Acc: 0.9534\tval Loss: 2.0159 Acc: 0.9667\t\n",
      "Epoch 859/1599:\ttrain Loss: 2.0437 Acc: 0.8941\tval Loss: 2.0162 Acc: 0.9667\t\n",
      "Epoch 860/1599:\ttrain Loss: 2.0380 Acc: 0.8814\tval Loss: 2.0219 Acc: 0.9333\t\n",
      "Epoch 861/1599:\ttrain Loss: 2.0341 Acc: 0.9110\tval Loss: 2.0172 Acc: 1.0000\t\n",
      "Epoch 862/1599:\ttrain Loss: 2.0279 Acc: 0.9322\tval Loss: 2.0178 Acc: 0.9667\t\n",
      "Epoch 863/1599:\ttrain Loss: 2.0318 Acc: 0.9153\tval Loss: 2.0148 Acc: 0.9667\t\n",
      "Epoch 864/1599:\ttrain Loss: 2.0320 Acc: 0.9364\tval Loss: 2.0163 Acc: 0.9667\t\n",
      "Epoch 865/1599:\ttrain Loss: 2.0430 Acc: 0.9195\tval Loss: 2.0160 Acc: 1.0000\t\n",
      "Epoch 866/1599:\ttrain Loss: 2.0290 Acc: 0.9364\tval Loss: 2.0164 Acc: 0.9667\t\n",
      "Epoch 867/1599:\ttrain Loss: 2.0243 Acc: 0.9280\tval Loss: 2.0193 Acc: 0.9333\t\n",
      "Epoch 868/1599:\ttrain Loss: 2.0275 Acc: 0.9576\tval Loss: 2.0166 Acc: 0.9667\t\n",
      "Epoch 869/1599:\ttrain Loss: 2.0224 Acc: 0.9746\tval Loss: 2.0193 Acc: 0.9333\t\n",
      "Epoch 870/1599:\ttrain Loss: 2.0326 Acc: 0.9322\tval Loss: 2.0150 Acc: 0.9667\t\n",
      "Epoch 871/1599:\ttrain Loss: 2.0308 Acc: 0.9407\tval Loss: 2.0364 Acc: 0.9667\t\n",
      "Epoch 872/1599:\ttrain Loss: 2.0367 Acc: 0.9237\tval Loss: 2.0196 Acc: 1.0000\t\n",
      "Epoch 873/1599:\ttrain Loss: 2.0404 Acc: 0.9237\tval Loss: 2.0180 Acc: 0.9667\t\n",
      "Epoch 874/1599:\ttrain Loss: 2.0437 Acc: 0.8898\tval Loss: 2.0159 Acc: 0.9333\t\n",
      "Epoch 875/1599:\ttrain Loss: 2.0318 Acc: 0.9449\tval Loss: 2.0316 Acc: 0.9333\t\n",
      "Epoch 876/1599:\ttrain Loss: 2.0383 Acc: 0.8475\tval Loss: 2.0354 Acc: 0.9667\t\n",
      "Epoch 877/1599:\ttrain Loss: 2.0290 Acc: 0.9153\tval Loss: 2.0240 Acc: 0.9333\t\n",
      "Epoch 878/1599:\ttrain Loss: 2.0392 Acc: 0.8771\tval Loss: 2.0173 Acc: 1.0000\t\n",
      "Epoch 879/1599:\ttrain Loss: 2.0246 Acc: 0.9492\tval Loss: 2.0216 Acc: 0.9000\t\n",
      "Epoch 880/1599:\ttrain Loss: 2.0167 Acc: 0.9237\tval Loss: 2.0185 Acc: 0.9667\t\n",
      "Epoch 881/1599:\ttrain Loss: 2.0353 Acc: 0.9237\tval Loss: 2.0186 Acc: 0.9333\t\n",
      "Epoch 882/1599:\ttrain Loss: 2.0274 Acc: 0.9576\tval Loss: 2.0180 Acc: 0.9667\t\n",
      "Epoch 883/1599:\ttrain Loss: 2.0350 Acc: 0.9492\tval Loss: 2.0227 Acc: 0.9333\t\n",
      "Epoch 884/1599:\ttrain Loss: 2.0429 Acc: 0.8983\tval Loss: 2.0252 Acc: 0.9333\t\n",
      "Epoch 885/1599:\ttrain Loss: 2.0471 Acc: 0.8814\tval Loss: 2.0212 Acc: 1.0000\t\n",
      "Epoch 886/1599:\ttrain Loss: 2.0220 Acc: 0.9619\tval Loss: 2.0161 Acc: 1.0000\t\n",
      "Epoch 887/1599:\ttrain Loss: 2.0264 Acc: 0.9449\tval Loss: 2.0172 Acc: 0.9667\t\n",
      "Epoch 888/1599:\ttrain Loss: 2.0187 Acc: 0.9576\tval Loss: 2.0181 Acc: 0.9667\t\n",
      "Epoch 889/1599:\ttrain Loss: 2.0265 Acc: 0.9364\tval Loss: 2.0165 Acc: 0.9667\t\n",
      "Epoch 890/1599:\ttrain Loss: 2.0312 Acc: 0.9237\tval Loss: 2.0156 Acc: 0.9333\t\n",
      "Epoch 891/1599:\ttrain Loss: 2.0307 Acc: 0.9492\tval Loss: 2.0173 Acc: 0.9333\t\n",
      "Epoch 892/1599:\ttrain Loss: 2.0305 Acc: 0.9322\tval Loss: 2.0182 Acc: 0.9667\t\n",
      "Epoch 893/1599:\ttrain Loss: 2.0440 Acc: 0.9068\tval Loss: 2.0173 Acc: 0.9333\t\n",
      "Epoch 894/1599:\ttrain Loss: 2.0307 Acc: 0.9576\tval Loss: 2.0163 Acc: 1.0000\t\n",
      "Epoch 895/1599:\ttrain Loss: 2.0276 Acc: 0.9364\tval Loss: 2.0279 Acc: 0.8667\t\n",
      "Epoch 896/1599:\ttrain Loss: 2.0170 Acc: 0.9661\tval Loss: 2.0168 Acc: 1.0000\t\n",
      "Epoch 897/1599:\ttrain Loss: 2.0251 Acc: 0.9449\tval Loss: 2.0160 Acc: 0.9667\t\n",
      "Epoch 898/1599:\ttrain Loss: 2.0331 Acc: 0.9110\tval Loss: 2.0184 Acc: 0.9667\t\n",
      "Epoch 899/1599:\ttrain Loss: 2.0232 Acc: 0.9703\tval Loss: 2.0159 Acc: 1.0000\t\n",
      "Epoch 900/1599:\ttrain Loss: 2.0393 Acc: 0.9068\tval Loss: 2.0172 Acc: 0.9333\t\n",
      "Epoch 901/1599:\ttrain Loss: 2.0227 Acc: 0.9449\tval Loss: 2.0146 Acc: 0.9000\t\n",
      "Epoch 902/1599:\ttrain Loss: 2.0260 Acc: 0.9449\tval Loss: 2.0161 Acc: 0.9667\t\n",
      "Epoch 903/1599:\ttrain Loss: 2.0382 Acc: 0.9237\tval Loss: 2.0162 Acc: 0.9667\t\n",
      "Epoch 904/1599:\ttrain Loss: 2.0332 Acc: 0.9364\tval Loss: 2.0181 Acc: 0.9000\t\n",
      "Epoch 905/1599:\ttrain Loss: 2.0221 Acc: 0.9534\tval Loss: 2.0185 Acc: 0.9333\t\n",
      "Epoch 906/1599:\ttrain Loss: 2.0394 Acc: 0.9280\tval Loss: 2.0180 Acc: 0.9333\t\n",
      "Epoch 907/1599:\ttrain Loss: 2.0388 Acc: 0.9280\tval Loss: 2.0184 Acc: 0.9333\t\n",
      "Epoch 908/1599:\ttrain Loss: 2.0295 Acc: 0.9576\tval Loss: 2.0146 Acc: 0.9333\t\n",
      "Epoch 909/1599:\ttrain Loss: 2.0217 Acc: 0.9449\tval Loss: 2.0175 Acc: 0.9333\t\n",
      "Epoch 910/1599:\ttrain Loss: 2.0301 Acc: 0.9534\tval Loss: 2.0161 Acc: 0.9333\t\n",
      "Epoch 911/1599:\ttrain Loss: 2.0343 Acc: 0.9492\tval Loss: 2.0171 Acc: 0.9667\t\n",
      "Epoch 912/1599:\ttrain Loss: 2.0337 Acc: 0.9237\tval Loss: 2.0194 Acc: 0.9333\t\n",
      "Epoch 913/1599:\ttrain Loss: 2.0342 Acc: 0.9322\tval Loss: 2.0163 Acc: 0.9333\t\n",
      "Epoch 914/1599:\ttrain Loss: 2.0228 Acc: 0.9661\tval Loss: 2.0147 Acc: 0.9000\t\n",
      "Epoch 915/1599:\ttrain Loss: 2.0390 Acc: 0.9153\tval Loss: 2.0149 Acc: 0.9667\t\n",
      "Epoch 916/1599:\ttrain Loss: 2.0264 Acc: 0.9492\tval Loss: 2.0156 Acc: 0.9333\t\n",
      "Epoch 917/1599:\ttrain Loss: 2.0387 Acc: 0.9534\tval Loss: 2.0165 Acc: 0.9333\t\n",
      "Epoch 918/1599:\ttrain Loss: 2.0223 Acc: 0.9449\tval Loss: 2.0145 Acc: 1.0000\t\n",
      "Epoch 919/1599:\ttrain Loss: 2.0354 Acc: 0.9407\tval Loss: 2.0193 Acc: 0.9333\t\n",
      "Epoch 920/1599:\ttrain Loss: 2.0271 Acc: 0.9661\tval Loss: 2.0160 Acc: 0.9000\t\n",
      "Epoch 921/1599:\ttrain Loss: 2.0148 Acc: 0.9746\tval Loss: 2.0203 Acc: 0.9333\t\n",
      "Epoch 922/1599:\ttrain Loss: 2.0345 Acc: 0.9237\tval Loss: 2.0163 Acc: 0.9000\t\n",
      "Epoch 923/1599:\ttrain Loss: 2.0230 Acc: 0.9492\tval Loss: 2.0174 Acc: 0.9333\t\n",
      "Epoch 924/1599:\ttrain Loss: 2.0302 Acc: 0.9237\tval Loss: 2.0178 Acc: 0.9000\t\n",
      "Epoch 925/1599:\ttrain Loss: 2.0346 Acc: 0.9322\tval Loss: 2.0168 Acc: 0.9000\t\n",
      "Epoch 926/1599:\ttrain Loss: 2.0307 Acc: 0.9661\tval Loss: 2.0153 Acc: 1.0000\t\n",
      "Epoch 927/1599:\ttrain Loss: 2.0292 Acc: 0.9492\tval Loss: 2.0172 Acc: 0.9333\t\n",
      "Epoch 928/1599:\ttrain Loss: 2.0343 Acc: 0.9280\tval Loss: 2.0159 Acc: 0.9333\t\n",
      "Epoch 929/1599:\ttrain Loss: 2.0294 Acc: 0.9534\tval Loss: 2.0162 Acc: 0.9333\t\n",
      "Epoch 930/1599:\ttrain Loss: 2.0174 Acc: 0.9788\tval Loss: 2.0144 Acc: 0.9667\t\n",
      "Epoch 931/1599:\ttrain Loss: 2.0308 Acc: 0.9449\tval Loss: 2.0165 Acc: 0.9667\t\n",
      "Epoch 932/1599:\ttrain Loss: 2.0344 Acc: 0.9449\tval Loss: 2.0151 Acc: 0.9000\t\n",
      "Epoch 933/1599:\ttrain Loss: 2.0349 Acc: 0.9492\tval Loss: 2.0181 Acc: 0.8333\t\n",
      "Epoch 934/1599:\ttrain Loss: 2.0311 Acc: 0.9322\tval Loss: 2.0161 Acc: 0.9667\t\n",
      "Epoch 935/1599:\ttrain Loss: 2.0303 Acc: 0.9534\tval Loss: 2.0178 Acc: 0.9333\t\n",
      "Epoch 936/1599:\ttrain Loss: 2.0494 Acc: 0.9407\tval Loss: 2.0145 Acc: 0.9667\t\n",
      "Epoch 937/1599:\ttrain Loss: 2.0423 Acc: 0.9153\tval Loss: 2.0217 Acc: 0.9333\t\n",
      "Epoch 938/1599:\ttrain Loss: 2.0321 Acc: 0.9280\tval Loss: 2.0176 Acc: 0.8667\t\n",
      "Epoch 939/1599:\ttrain Loss: 2.0265 Acc: 0.9619\tval Loss: 2.0158 Acc: 0.9333\t\n",
      "Epoch 940/1599:\ttrain Loss: 2.0302 Acc: 0.9364\tval Loss: 2.0160 Acc: 0.9000\t\n",
      "Epoch 941/1599:\ttrain Loss: 2.0347 Acc: 0.9364\tval Loss: 2.0162 Acc: 0.8667\t\n",
      "Epoch 942/1599:\ttrain Loss: 2.0342 Acc: 0.9492\tval Loss: 2.0170 Acc: 0.9000\t\n",
      "Epoch 943/1599:\ttrain Loss: 2.0218 Acc: 0.9746\tval Loss: 2.0166 Acc: 0.8667\t\n",
      "Epoch 944/1599:\ttrain Loss: 2.0226 Acc: 0.9661\tval Loss: 2.0140 Acc: 0.9000\t\n",
      "Epoch 945/1599:\ttrain Loss: 2.0409 Acc: 0.9322\tval Loss: 2.0177 Acc: 0.9000\t\n",
      "Epoch 946/1599:\ttrain Loss: 2.0346 Acc: 0.9619\tval Loss: 2.0176 Acc: 0.9000\t\n",
      "Epoch 947/1599:\ttrain Loss: 2.0226 Acc: 0.9449\tval Loss: 2.0152 Acc: 0.9333\t\n",
      "Epoch 948/1599:\ttrain Loss: 2.0244 Acc: 0.9831\tval Loss: 2.0152 Acc: 0.9333\t\n",
      "Epoch 949/1599:\ttrain Loss: 2.0229 Acc: 0.9661\tval Loss: 2.0171 Acc: 0.9333\t\n",
      "Epoch 950/1599:\ttrain Loss: 2.0314 Acc: 0.9619\tval Loss: 2.0161 Acc: 0.9667\t\n",
      "Epoch 951/1599:\ttrain Loss: 2.0347 Acc: 0.9364\tval Loss: 2.0163 Acc: 0.9667\t\n",
      "Epoch 952/1599:\ttrain Loss: 2.0312 Acc: 0.9407\tval Loss: 2.0174 Acc: 0.8667\t\n",
      "Epoch 953/1599:\ttrain Loss: 2.0256 Acc: 0.9619\tval Loss: 2.0138 Acc: 0.9333\t\n",
      "Epoch 954/1599:\ttrain Loss: 2.0334 Acc: 0.9322\tval Loss: 2.0165 Acc: 0.9333\t\n",
      "Epoch 955/1599:\ttrain Loss: 2.0312 Acc: 0.9492\tval Loss: 2.0160 Acc: 0.9333\t\n",
      "Epoch 956/1599:\ttrain Loss: 2.0262 Acc: 0.9534\tval Loss: 2.0143 Acc: 0.9333\t\n",
      "Epoch 957/1599:\ttrain Loss: 2.0321 Acc: 0.9534\tval Loss: 2.0149 Acc: 0.9667\t\n",
      "Epoch 958/1599:\ttrain Loss: 2.0401 Acc: 0.9322\tval Loss: 2.0182 Acc: 0.9667\t\n",
      "Epoch 959/1599:\ttrain Loss: 2.0341 Acc: 0.9025\tval Loss: 2.0159 Acc: 0.9333\t\n",
      "Epoch 960/1599:\ttrain Loss: 2.0177 Acc: 0.9873\tval Loss: 2.0149 Acc: 0.9000\t\n",
      "Epoch 961/1599:\ttrain Loss: 2.0506 Acc: 0.9068\tval Loss: 2.0150 Acc: 0.9667\t\n",
      "Epoch 962/1599:\ttrain Loss: 2.0301 Acc: 0.9492\tval Loss: 2.0149 Acc: 0.9000\t\n",
      "Epoch 963/1599:\ttrain Loss: 2.0462 Acc: 0.9237\tval Loss: 2.0152 Acc: 0.9333\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 964/1599:\ttrain Loss: 2.0377 Acc: 0.9661\tval Loss: 2.0175 Acc: 0.9333\t\n",
      "Epoch 965/1599:\ttrain Loss: 2.0373 Acc: 0.9449\tval Loss: 2.0157 Acc: 1.0000\t\n",
      "Epoch 966/1599:\ttrain Loss: 2.0298 Acc: 0.9661\tval Loss: 2.0178 Acc: 0.9000\t\n",
      "Epoch 967/1599:\ttrain Loss: 2.0336 Acc: 0.9661\tval Loss: 2.0160 Acc: 0.9333\t\n",
      "Epoch 968/1599:\ttrain Loss: 2.0378 Acc: 0.9407\tval Loss: 2.0161 Acc: 0.9333\t\n",
      "Epoch 969/1599:\ttrain Loss: 2.0305 Acc: 0.9619\tval Loss: 2.0157 Acc: 0.9667\t\n",
      "Epoch 970/1599:\ttrain Loss: 2.0335 Acc: 0.9661\tval Loss: 2.0162 Acc: 0.8667\t\n",
      "Epoch 971/1599:\ttrain Loss: 2.0213 Acc: 0.9915\tval Loss: 2.0151 Acc: 0.9667\t\n",
      "Epoch 972/1599:\ttrain Loss: 2.0295 Acc: 0.9703\tval Loss: 2.0145 Acc: 0.9333\t\n",
      "Epoch 973/1599:\ttrain Loss: 2.0129 Acc: 0.9915\tval Loss: 2.0184 Acc: 0.9333\t\n",
      "Epoch 974/1599:\ttrain Loss: 2.0343 Acc: 0.9322\tval Loss: 2.0154 Acc: 0.9667\t\n",
      "Epoch 975/1599:\ttrain Loss: 2.0361 Acc: 0.9534\tval Loss: 2.0158 Acc: 0.9000\t\n",
      "Epoch 976/1599:\ttrain Loss: 2.0337 Acc: 0.9576\tval Loss: 2.0167 Acc: 0.9333\t\n",
      "Epoch 977/1599:\ttrain Loss: 2.0415 Acc: 0.9195\tval Loss: 2.0150 Acc: 0.9333\t\n",
      "Epoch 978/1599:\ttrain Loss: 2.0372 Acc: 0.9576\tval Loss: 2.0150 Acc: 0.9333\t\n",
      "Epoch 979/1599:\ttrain Loss: 2.0176 Acc: 0.9661\tval Loss: 2.0140 Acc: 0.9333\t\n",
      "Epoch 980/1599:\ttrain Loss: 2.0251 Acc: 0.9831\tval Loss: 2.0147 Acc: 0.9667\t\n",
      "Epoch 981/1599:\ttrain Loss: 2.0382 Acc: 0.9492\tval Loss: 2.0155 Acc: 0.9667\t\n",
      "Epoch 982/1599:\ttrain Loss: 2.0214 Acc: 0.9746\tval Loss: 2.0160 Acc: 0.9667\t\n",
      "Epoch 983/1599:\ttrain Loss: 2.0253 Acc: 0.9619\tval Loss: 2.0201 Acc: 0.9333\t\n",
      "Epoch 984/1599:\ttrain Loss: 2.0409 Acc: 0.9364\tval Loss: 2.0151 Acc: 1.0000\t\n",
      "Epoch 985/1599:\ttrain Loss: 2.0363 Acc: 0.9280\tval Loss: 2.0156 Acc: 0.9667\t\n",
      "Epoch 986/1599:\ttrain Loss: 2.0462 Acc: 0.8898\tval Loss: 2.0541 Acc: 0.8667\t\n",
      "Epoch 987/1599:\ttrain Loss: 2.0421 Acc: 0.8729\tval Loss: 2.0172 Acc: 0.9000\t\n",
      "Epoch 988/1599:\ttrain Loss: 2.0379 Acc: 0.9025\tval Loss: 2.0157 Acc: 0.9333\t\n",
      "Epoch 989/1599:\ttrain Loss: 2.0238 Acc: 0.9449\tval Loss: 2.0200 Acc: 0.8333\t\n",
      "Epoch 990/1599:\ttrain Loss: 2.0228 Acc: 0.9322\tval Loss: 2.0253 Acc: 0.8333\t\n",
      "Epoch 991/1599:\ttrain Loss: 2.0242 Acc: 0.9449\tval Loss: 2.0156 Acc: 0.9667\t\n",
      "Epoch 992/1599:\ttrain Loss: 2.0356 Acc: 0.9407\tval Loss: 2.0137 Acc: 0.9333\t\n",
      "Epoch 993/1599:\ttrain Loss: 2.0463 Acc: 0.9153\tval Loss: 2.0153 Acc: 0.9667\t\n",
      "Epoch 994/1599:\ttrain Loss: 2.0305 Acc: 0.9407\tval Loss: 2.0169 Acc: 0.9333\t\n",
      "Epoch 995/1599:\ttrain Loss: 2.0263 Acc: 0.9492\tval Loss: 2.0155 Acc: 0.8667\t\n",
      "Epoch 996/1599:\ttrain Loss: 2.0220 Acc: 0.9619\tval Loss: 2.0166 Acc: 0.9333\t\n",
      "Epoch 997/1599:\ttrain Loss: 2.0271 Acc: 0.9619\tval Loss: 2.0148 Acc: 0.9333\t\n",
      "Epoch 998/1599:\ttrain Loss: 2.0248 Acc: 0.9407\tval Loss: 2.0165 Acc: 0.9667\t\n",
      "Epoch 999/1599:\ttrain Loss: 2.0398 Acc: 0.8983\tval Loss: 2.0264 Acc: 0.9000\t\n",
      "Epoch 1000/1599:\ttrain Loss: 2.0333 Acc: 0.9068\tval Loss: 2.0203 Acc: 0.9000\t\n",
      "Epoch 1001/1599:\ttrain Loss: 2.0399 Acc: 0.9195\tval Loss: 2.0176 Acc: 0.8667\t\n",
      "Epoch 1002/1599:\ttrain Loss: 2.0231 Acc: 0.9449\tval Loss: 2.0158 Acc: 0.9667\t\n",
      "Epoch 1003/1599:\ttrain Loss: 2.0266 Acc: 0.9746\tval Loss: 2.0157 Acc: 0.9000\t\n",
      "Epoch 1004/1599:\ttrain Loss: 2.0362 Acc: 0.9449\tval Loss: 2.0225 Acc: 0.9000\t\n",
      "Epoch 1005/1599:\ttrain Loss: 2.0222 Acc: 0.9661\tval Loss: 2.0166 Acc: 0.9000\t\n",
      "Epoch 1006/1599:\ttrain Loss: 2.0434 Acc: 0.8814\tval Loss: 2.0149 Acc: 0.8667\t\n",
      "Epoch 1007/1599:\ttrain Loss: 2.0398 Acc: 0.8771\tval Loss: 2.0231 Acc: 0.9000\t\n",
      "Epoch 1008/1599:\ttrain Loss: 2.0287 Acc: 0.9153\tval Loss: 2.0638 Acc: 0.8000\t\n",
      "Epoch 1009/1599:\ttrain Loss: 2.0382 Acc: 0.8814\tval Loss: 2.0326 Acc: 0.9667\t\n",
      "Epoch 1010/1599:\ttrain Loss: 2.0398 Acc: 0.9195\tval Loss: 2.0169 Acc: 0.8667\t\n",
      "Epoch 1011/1599:\ttrain Loss: 2.0233 Acc: 0.9576\tval Loss: 2.0229 Acc: 0.9000\t\n",
      "Epoch 1012/1599:\ttrain Loss: 2.0285 Acc: 0.9322\tval Loss: 2.0179 Acc: 0.8667\t\n",
      "Epoch 1013/1599:\ttrain Loss: 2.0191 Acc: 0.9703\tval Loss: 2.0184 Acc: 0.8667\t\n",
      "Epoch 1014/1599:\ttrain Loss: 2.0394 Acc: 0.9237\tval Loss: 2.0165 Acc: 0.9333\t\n",
      "Epoch 1015/1599:\ttrain Loss: 2.0314 Acc: 0.9619\tval Loss: 2.0179 Acc: 0.9333\t\n",
      "Epoch 1016/1599:\ttrain Loss: 2.0425 Acc: 0.9153\tval Loss: 2.0179 Acc: 0.9333\t\n",
      "Epoch 1017/1599:\ttrain Loss: 2.0262 Acc: 0.9534\tval Loss: 2.0166 Acc: 0.9333\t\n",
      "Epoch 1018/1599:\ttrain Loss: 2.0343 Acc: 0.9407\tval Loss: 2.0156 Acc: 0.9333\t\n",
      "Epoch 1019/1599:\ttrain Loss: 2.0268 Acc: 0.9619\tval Loss: 2.0163 Acc: 0.9333\t\n",
      "Epoch 1020/1599:\ttrain Loss: 2.0417 Acc: 0.9322\tval Loss: 2.0166 Acc: 0.9000\t\n",
      "Epoch 1021/1599:\ttrain Loss: 2.0347 Acc: 0.9322\tval Loss: 2.0151 Acc: 0.9667\t\n",
      "Epoch 1022/1599:\ttrain Loss: 2.0311 Acc: 0.9534\tval Loss: 2.0198 Acc: 0.9333\t\n",
      "Epoch 1023/1599:\ttrain Loss: 2.0262 Acc: 0.9746\tval Loss: 2.0155 Acc: 0.9667\t\n",
      "Epoch 1024/1599:\ttrain Loss: 2.0303 Acc: 0.9280\tval Loss: 2.0165 Acc: 0.9333\t\n",
      "Epoch 1025/1599:\ttrain Loss: 2.0307 Acc: 0.9703\tval Loss: 2.0153 Acc: 0.9667\t\n",
      "Epoch 1026/1599:\ttrain Loss: 2.0229 Acc: 0.9703\tval Loss: 2.0146 Acc: 0.9667\t\n",
      "Epoch 1027/1599:\ttrain Loss: 2.0261 Acc: 0.9449\tval Loss: 2.0146 Acc: 0.9333\t\n",
      "Epoch 1028/1599:\ttrain Loss: 2.0221 Acc: 0.9746\tval Loss: 2.0151 Acc: 0.9333\t\n",
      "Epoch 1029/1599:\ttrain Loss: 2.0376 Acc: 0.9407\tval Loss: 2.0139 Acc: 0.9333\t\n",
      "Epoch 1030/1599:\ttrain Loss: 2.0261 Acc: 0.9576\tval Loss: 2.0169 Acc: 0.9333\t\n",
      "Epoch 1031/1599:\ttrain Loss: 2.0294 Acc: 0.9619\tval Loss: 2.0158 Acc: 0.9667\t\n",
      "Epoch 1032/1599:\ttrain Loss: 2.0171 Acc: 0.9915\tval Loss: 2.0159 Acc: 0.9667\t\n",
      "Epoch 1033/1599:\ttrain Loss: 2.0212 Acc: 0.9788\tval Loss: 2.0160 Acc: 0.9333\t\n",
      "Epoch 1034/1599:\ttrain Loss: 2.0331 Acc: 0.9619\tval Loss: 2.0161 Acc: 0.9000\t\n",
      "Epoch 1035/1599:\ttrain Loss: 2.0292 Acc: 0.9661\tval Loss: 2.0164 Acc: 1.0000\t\n",
      "Epoch 1036/1599:\ttrain Loss: 2.0371 Acc: 0.9153\tval Loss: 2.0170 Acc: 0.9333\t\n",
      "Epoch 1037/1599:\ttrain Loss: 2.0454 Acc: 0.9322\tval Loss: 2.0153 Acc: 0.9333\t\n",
      "Epoch 1038/1599:\ttrain Loss: 2.0139 Acc: 0.9873\tval Loss: 2.0150 Acc: 1.0000\t\n",
      "Epoch 1039/1599:\ttrain Loss: 2.0291 Acc: 0.9873\tval Loss: 2.0152 Acc: 1.0000\t\n",
      "Epoch 1040/1599:\ttrain Loss: 2.0496 Acc: 0.9280\tval Loss: 2.0190 Acc: 0.9000\t\n",
      "Epoch 1041/1599:\ttrain Loss: 2.0217 Acc: 0.9831\tval Loss: 2.0146 Acc: 0.9333\t\n",
      "Epoch 1042/1599:\ttrain Loss: 2.0243 Acc: 0.9788\tval Loss: 2.0211 Acc: 0.9667\t\n",
      "Epoch 1043/1599:\ttrain Loss: 2.0299 Acc: 0.9619\tval Loss: 2.0155 Acc: 0.9000\t\n",
      "Epoch 1044/1599:\ttrain Loss: 2.0216 Acc: 0.9788\tval Loss: 2.0168 Acc: 0.8667\t\n",
      "Epoch 1045/1599:\ttrain Loss: 2.0373 Acc: 0.9449\tval Loss: 2.0151 Acc: 1.0000\t\n",
      "Epoch 1046/1599:\ttrain Loss: 2.0217 Acc: 0.9788\tval Loss: 2.0163 Acc: 0.9000\t\n",
      "Epoch 1047/1599:\ttrain Loss: 2.0248 Acc: 0.9746\tval Loss: 2.0163 Acc: 0.9667\t\n",
      "Epoch 1048/1599:\ttrain Loss: 2.0211 Acc: 0.9831\tval Loss: 2.0179 Acc: 0.9667\t\n",
      "Epoch 1049/1599:\ttrain Loss: 2.0334 Acc: 0.9407\tval Loss: 2.0164 Acc: 0.9333\t\n",
      "Epoch 1050/1599:\ttrain Loss: 2.0209 Acc: 0.9746\tval Loss: 2.0188 Acc: 0.9333\t\n",
      "Epoch 1051/1599:\ttrain Loss: 2.0178 Acc: 0.9788\tval Loss: 2.0181 Acc: 0.9667\t\n",
      "Epoch 1052/1599:\ttrain Loss: 2.0177 Acc: 1.0000\tval Loss: 2.0175 Acc: 0.9000\t\n",
      "Epoch 1053/1599:\ttrain Loss: 2.0333 Acc: 0.9237\tval Loss: 2.0154 Acc: 0.9667\t\n",
      "Epoch 1054/1599:\ttrain Loss: 2.0339 Acc: 0.9407\tval Loss: 2.0154 Acc: 0.9333\t\n",
      "Epoch 1055/1599:\ttrain Loss: 2.0376 Acc: 0.9534\tval Loss: 2.0153 Acc: 0.9667\t\n",
      "Epoch 1056/1599:\ttrain Loss: 2.0333 Acc: 0.9661\tval Loss: 2.0162 Acc: 0.9667\t\n",
      "Epoch 1057/1599:\ttrain Loss: 2.0252 Acc: 0.9746\tval Loss: 2.0214 Acc: 0.9667\t\n",
      "Epoch 1058/1599:\ttrain Loss: 2.0409 Acc: 0.9661\tval Loss: 2.0225 Acc: 1.0000\t\n",
      "Epoch 1059/1599:\ttrain Loss: 2.0256 Acc: 0.9703\tval Loss: 2.0203 Acc: 0.9667\t\n",
      "Epoch 1060/1599:\ttrain Loss: 2.0353 Acc: 0.9619\tval Loss: 2.0170 Acc: 0.9000\t\n",
      "Epoch 1061/1599:\ttrain Loss: 2.0316 Acc: 0.9619\tval Loss: 2.0161 Acc: 0.9667\t\n",
      "Epoch 1062/1599:\ttrain Loss: 2.0309 Acc: 0.9661\tval Loss: 2.0218 Acc: 0.9333\t\n",
      "Epoch 1063/1599:\ttrain Loss: 2.0310 Acc: 0.9492\tval Loss: 2.0239 Acc: 0.9333\t\n",
      "Epoch 1064/1599:\ttrain Loss: 2.0253 Acc: 0.9619\tval Loss: 2.0180 Acc: 0.9000\t\n",
      "Epoch 1065/1599:\ttrain Loss: 2.0292 Acc: 0.9661\tval Loss: 2.0176 Acc: 0.9000\t\n",
      "Epoch 1066/1599:\ttrain Loss: 2.0372 Acc: 0.9449\tval Loss: 2.0168 Acc: 0.9000\t\n",
      "Epoch 1067/1599:\ttrain Loss: 2.0374 Acc: 0.9364\tval Loss: 2.0157 Acc: 0.9333\t\n",
      "Epoch 1068/1599:\ttrain Loss: 2.0331 Acc: 0.9534\tval Loss: 2.0159 Acc: 0.9333\t\n",
      "Epoch 1069/1599:\ttrain Loss: 2.0316 Acc: 0.9661\tval Loss: 2.0139 Acc: 0.9667\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1070/1599:\ttrain Loss: 2.0339 Acc: 0.9703\tval Loss: 2.0169 Acc: 0.9000\t\n",
      "Epoch 1071/1599:\ttrain Loss: 2.0334 Acc: 0.9746\tval Loss: 2.0170 Acc: 0.9000\t\n",
      "Epoch 1072/1599:\ttrain Loss: 2.0286 Acc: 0.9746\tval Loss: 2.0179 Acc: 0.9333\t\n",
      "Epoch 1073/1599:\ttrain Loss: 2.0340 Acc: 0.9661\tval Loss: 2.0147 Acc: 0.9000\t\n",
      "Epoch 1074/1599:\ttrain Loss: 2.0215 Acc: 0.9831\tval Loss: 2.0165 Acc: 0.9333\t\n",
      "Epoch 1075/1599:\ttrain Loss: 2.0274 Acc: 0.9788\tval Loss: 2.0151 Acc: 0.9667\t\n",
      "Epoch 1076/1599:\ttrain Loss: 2.0302 Acc: 0.9619\tval Loss: 2.0178 Acc: 0.9667\t\n",
      "Epoch 1077/1599:\ttrain Loss: 2.0175 Acc: 0.9873\tval Loss: 2.0169 Acc: 0.9000\t\n",
      "Epoch 1078/1599:\ttrain Loss: 2.0373 Acc: 0.9322\tval Loss: 2.0142 Acc: 0.9667\t\n",
      "Epoch 1079/1599:\ttrain Loss: 2.0212 Acc: 0.9873\tval Loss: 2.0173 Acc: 0.9333\t\n",
      "Epoch 1080/1599:\ttrain Loss: 2.0287 Acc: 0.9534\tval Loss: 2.0148 Acc: 0.9667\t\n",
      "Epoch 1081/1599:\ttrain Loss: 2.0338 Acc: 0.9619\tval Loss: 2.0149 Acc: 0.9333\t\n",
      "Epoch 1082/1599:\ttrain Loss: 2.0329 Acc: 0.9576\tval Loss: 2.0141 Acc: 0.9333\t\n",
      "Epoch 1083/1599:\ttrain Loss: 2.0252 Acc: 0.9831\tval Loss: 2.0145 Acc: 1.0000\t\n",
      "Epoch 1084/1599:\ttrain Loss: 2.0255 Acc: 0.9746\tval Loss: 2.0164 Acc: 0.9667\t\n",
      "Epoch 1085/1599:\ttrain Loss: 2.0290 Acc: 0.9619\tval Loss: 2.0163 Acc: 0.9333\t\n",
      "Epoch 1086/1599:\ttrain Loss: 2.0164 Acc: 0.9831\tval Loss: 2.0147 Acc: 0.9333\t\n",
      "Epoch 1087/1599:\ttrain Loss: 2.0256 Acc: 0.9576\tval Loss: 2.0160 Acc: 0.9000\t\n",
      "Epoch 1088/1599:\ttrain Loss: 2.0243 Acc: 0.9831\tval Loss: 2.0164 Acc: 0.9000\t\n",
      "Epoch 1089/1599:\ttrain Loss: 2.0247 Acc: 0.9831\tval Loss: 2.0158 Acc: 0.9333\t\n",
      "Epoch 1090/1599:\ttrain Loss: 2.0249 Acc: 0.9746\tval Loss: 2.0148 Acc: 0.9667\t\n",
      "Epoch 1091/1599:\ttrain Loss: 2.0329 Acc: 0.9619\tval Loss: 2.0144 Acc: 0.9333\t\n",
      "Epoch 1092/1599:\ttrain Loss: 2.0330 Acc: 0.9619\tval Loss: 2.0165 Acc: 0.9333\t\n",
      "Epoch 1093/1599:\ttrain Loss: 2.0330 Acc: 0.9576\tval Loss: 2.0151 Acc: 0.9667\t\n",
      "Epoch 1094/1599:\ttrain Loss: 2.0220 Acc: 0.9831\tval Loss: 2.0155 Acc: 1.0000\t\n",
      "Epoch 1095/1599:\ttrain Loss: 2.0408 Acc: 0.9407\tval Loss: 2.0160 Acc: 0.9667\t\n",
      "Epoch 1096/1599:\ttrain Loss: 2.0170 Acc: 0.9873\tval Loss: 2.0151 Acc: 0.9333\t\n",
      "Epoch 1097/1599:\ttrain Loss: 2.0363 Acc: 0.9619\tval Loss: 2.0177 Acc: 0.8667\t\n",
      "Epoch 1098/1599:\ttrain Loss: 2.0207 Acc: 0.9831\tval Loss: 2.0147 Acc: 0.9333\t\n",
      "Epoch 1099/1599:\ttrain Loss: 2.0412 Acc: 0.9364\tval Loss: 2.0152 Acc: 0.9333\t\n",
      "Epoch 1100/1599:\ttrain Loss: 2.0296 Acc: 0.9449\tval Loss: 2.0163 Acc: 0.9333\t\n",
      "Epoch 1101/1599:\ttrain Loss: 2.0256 Acc: 0.9661\tval Loss: 2.0158 Acc: 1.0000\t\n",
      "Epoch 1102/1599:\ttrain Loss: 2.0333 Acc: 0.9280\tval Loss: 2.0155 Acc: 0.9667\t\n",
      "Epoch 1103/1599:\ttrain Loss: 2.0288 Acc: 0.9703\tval Loss: 2.0149 Acc: 0.9333\t\n",
      "Epoch 1104/1599:\ttrain Loss: 2.0248 Acc: 0.9831\tval Loss: 2.0154 Acc: 0.9000\t\n",
      "Epoch 1105/1599:\ttrain Loss: 2.0175 Acc: 0.9788\tval Loss: 2.0160 Acc: 0.9667\t\n",
      "Epoch 1106/1599:\ttrain Loss: 2.0255 Acc: 0.9534\tval Loss: 2.0160 Acc: 0.9333\t\n",
      "Epoch 1107/1599:\ttrain Loss: 2.0203 Acc: 0.9915\tval Loss: 2.0164 Acc: 0.9667\t\n",
      "Epoch 1108/1599:\ttrain Loss: 2.0330 Acc: 0.9534\tval Loss: 2.0158 Acc: 0.9333\t\n",
      "Epoch 1109/1599:\ttrain Loss: 2.0426 Acc: 0.9322\tval Loss: 2.0150 Acc: 0.9667\t\n",
      "Epoch 1110/1599:\ttrain Loss: 2.0255 Acc: 0.9619\tval Loss: 2.0148 Acc: 0.9333\t\n",
      "Epoch 1111/1599:\ttrain Loss: 2.0258 Acc: 0.9576\tval Loss: 2.0148 Acc: 0.9000\t\n",
      "Epoch 1112/1599:\ttrain Loss: 2.0127 Acc: 0.9873\tval Loss: 2.0161 Acc: 0.9667\t\n",
      "Epoch 1113/1599:\ttrain Loss: 2.0287 Acc: 0.9788\tval Loss: 2.0166 Acc: 0.9667\t\n",
      "Epoch 1114/1599:\ttrain Loss: 2.0455 Acc: 0.9237\tval Loss: 2.0154 Acc: 0.9667\t\n",
      "Epoch 1115/1599:\ttrain Loss: 2.0211 Acc: 0.9873\tval Loss: 2.0158 Acc: 0.9667\t\n",
      "Epoch 1116/1599:\ttrain Loss: 2.0245 Acc: 0.9788\tval Loss: 2.0153 Acc: 0.9333\t\n",
      "Epoch 1117/1599:\ttrain Loss: 2.0283 Acc: 0.9873\tval Loss: 2.0150 Acc: 0.9333\t\n",
      "Epoch 1118/1599:\ttrain Loss: 2.0249 Acc: 0.9746\tval Loss: 2.0175 Acc: 0.9333\t\n",
      "Epoch 1119/1599:\ttrain Loss: 2.0289 Acc: 0.9746\tval Loss: 2.0161 Acc: 0.9000\t\n",
      "Epoch 1120/1599:\ttrain Loss: 2.0367 Acc: 0.9661\tval Loss: 2.0164 Acc: 0.9000\t\n",
      "Epoch 1121/1599:\ttrain Loss: 2.0286 Acc: 0.9746\tval Loss: 2.0148 Acc: 0.9667\t\n",
      "Epoch 1122/1599:\ttrain Loss: 2.0247 Acc: 0.9449\tval Loss: 2.0153 Acc: 0.9333\t\n",
      "Epoch 1123/1599:\ttrain Loss: 2.0286 Acc: 0.9746\tval Loss: 2.0161 Acc: 1.0000\t\n",
      "Epoch 1124/1599:\ttrain Loss: 2.0244 Acc: 0.9746\tval Loss: 2.0140 Acc: 0.9667\t\n",
      "Epoch 1125/1599:\ttrain Loss: 2.0282 Acc: 0.9703\tval Loss: 2.0162 Acc: 0.9667\t\n",
      "Epoch 1126/1599:\ttrain Loss: 2.0286 Acc: 0.9619\tval Loss: 2.0152 Acc: 0.9667\t\n",
      "Epoch 1127/1599:\ttrain Loss: 2.0335 Acc: 0.9576\tval Loss: 2.0161 Acc: 0.9000\t\n",
      "Epoch 1128/1599:\ttrain Loss: 2.0260 Acc: 0.9746\tval Loss: 2.0148 Acc: 0.9667\t\n",
      "Epoch 1129/1599:\ttrain Loss: 2.0190 Acc: 0.9788\tval Loss: 2.0152 Acc: 0.9667\t\n",
      "Epoch 1130/1599:\ttrain Loss: 2.0347 Acc: 0.9619\tval Loss: 2.0151 Acc: 0.9667\t\n",
      "Epoch 1131/1599:\ttrain Loss: 2.0290 Acc: 0.9661\tval Loss: 2.0150 Acc: 1.0000\t\n",
      "Epoch 1132/1599:\ttrain Loss: 2.0255 Acc: 0.9703\tval Loss: 2.0149 Acc: 1.0000\t\n",
      "Epoch 1133/1599:\ttrain Loss: 2.0210 Acc: 0.9873\tval Loss: 2.0150 Acc: 0.9667\t\n",
      "Epoch 1134/1599:\ttrain Loss: 2.0284 Acc: 0.9576\tval Loss: 2.0139 Acc: 0.9667\t\n",
      "Epoch 1135/1599:\ttrain Loss: 2.0218 Acc: 0.9746\tval Loss: 2.0147 Acc: 0.9667\t\n",
      "Epoch 1136/1599:\ttrain Loss: 2.0286 Acc: 0.9661\tval Loss: 2.0148 Acc: 0.9333\t\n",
      "Epoch 1137/1599:\ttrain Loss: 2.0333 Acc: 0.9407\tval Loss: 2.0149 Acc: 0.9667\t\n",
      "Epoch 1138/1599:\ttrain Loss: 2.0285 Acc: 0.9703\tval Loss: 2.0163 Acc: 0.9000\t\n",
      "Epoch 1139/1599:\ttrain Loss: 2.0282 Acc: 0.9619\tval Loss: 2.0158 Acc: 0.9667\t\n",
      "Epoch 1140/1599:\ttrain Loss: 2.0402 Acc: 0.9449\tval Loss: 2.0159 Acc: 0.9000\t\n",
      "Epoch 1141/1599:\ttrain Loss: 2.0414 Acc: 0.9407\tval Loss: 2.0167 Acc: 0.9333\t\n",
      "Epoch 1142/1599:\ttrain Loss: 2.0290 Acc: 0.9746\tval Loss: 2.0175 Acc: 0.9000\t\n",
      "Epoch 1143/1599:\ttrain Loss: 2.0247 Acc: 0.9788\tval Loss: 2.0173 Acc: 0.9667\t\n",
      "Epoch 1144/1599:\ttrain Loss: 2.0333 Acc: 0.9746\tval Loss: 2.0165 Acc: 0.9333\t\n",
      "Epoch 1145/1599:\ttrain Loss: 2.0284 Acc: 0.9534\tval Loss: 2.0173 Acc: 0.9333\t\n",
      "Epoch 1146/1599:\ttrain Loss: 2.0370 Acc: 0.9576\tval Loss: 2.0165 Acc: 0.9667\t\n",
      "Epoch 1147/1599:\ttrain Loss: 2.0264 Acc: 0.9661\tval Loss: 2.0209 Acc: 1.0000\t\n",
      "Epoch 1148/1599:\ttrain Loss: 2.0291 Acc: 0.9788\tval Loss: 2.0158 Acc: 0.9667\t\n",
      "Epoch 1149/1599:\ttrain Loss: 2.0370 Acc: 0.9619\tval Loss: 2.0160 Acc: 0.9667\t\n",
      "Epoch 1150/1599:\ttrain Loss: 2.0295 Acc: 0.9534\tval Loss: 2.0153 Acc: 0.9667\t\n",
      "Epoch 1151/1599:\ttrain Loss: 2.0284 Acc: 0.9534\tval Loss: 2.0147 Acc: 0.9333\t\n",
      "Epoch 1152/1599:\ttrain Loss: 2.0339 Acc: 0.9576\tval Loss: 2.0135 Acc: 1.0000\t\n",
      "Epoch 1153/1599:\ttrain Loss: 2.0241 Acc: 0.9788\tval Loss: 2.0150 Acc: 0.9667\t\n",
      "Epoch 1154/1599:\ttrain Loss: 2.0366 Acc: 0.9534\tval Loss: 2.0185 Acc: 0.9333\t\n",
      "Epoch 1155/1599:\ttrain Loss: 2.0332 Acc: 0.9619\tval Loss: 2.0178 Acc: 0.9667\t\n",
      "Epoch 1156/1599:\ttrain Loss: 2.0282 Acc: 0.9746\tval Loss: 2.0230 Acc: 0.9667\t\n",
      "Epoch 1157/1599:\ttrain Loss: 2.0199 Acc: 0.9873\tval Loss: 2.0158 Acc: 0.9333\t\n",
      "Epoch 1158/1599:\ttrain Loss: 2.0283 Acc: 0.9703\tval Loss: 2.0146 Acc: 0.9333\t\n",
      "Epoch 1159/1599:\ttrain Loss: 2.0282 Acc: 0.9746\tval Loss: 2.0149 Acc: 1.0000\t\n",
      "Epoch 1160/1599:\ttrain Loss: 2.0329 Acc: 0.9703\tval Loss: 2.0129 Acc: 0.9333\t\n",
      "Epoch 1161/1599:\ttrain Loss: 2.0366 Acc: 0.9492\tval Loss: 2.0219 Acc: 0.9333\t\n",
      "Epoch 1162/1599:\ttrain Loss: 2.0246 Acc: 0.9788\tval Loss: 2.0157 Acc: 0.9667\t\n",
      "Epoch 1163/1599:\ttrain Loss: 2.0325 Acc: 0.9661\tval Loss: 2.0150 Acc: 0.9333\t\n",
      "Epoch 1164/1599:\ttrain Loss: 2.0364 Acc: 0.9576\tval Loss: 2.0196 Acc: 0.9000\t\n",
      "Epoch 1165/1599:\ttrain Loss: 2.0322 Acc: 0.9788\tval Loss: 2.0168 Acc: 0.9667\t\n",
      "Epoch 1166/1599:\ttrain Loss: 2.0245 Acc: 0.9703\tval Loss: 2.0163 Acc: 1.0000\t\n",
      "Epoch 1167/1599:\ttrain Loss: 2.0245 Acc: 0.9661\tval Loss: 2.0170 Acc: 0.9333\t\n",
      "Epoch 1168/1599:\ttrain Loss: 2.0250 Acc: 0.9746\tval Loss: 2.0157 Acc: 0.9667\t\n",
      "Epoch 1169/1599:\ttrain Loss: 2.0249 Acc: 0.9746\tval Loss: 2.0164 Acc: 0.9333\t\n",
      "Epoch 1170/1599:\ttrain Loss: 2.0286 Acc: 0.9788\tval Loss: 2.0137 Acc: 0.9333\t\n",
      "Epoch 1171/1599:\ttrain Loss: 2.0399 Acc: 0.9534\tval Loss: 2.0168 Acc: 0.9000\t\n",
      "Epoch 1172/1599:\ttrain Loss: 2.0200 Acc: 0.9746\tval Loss: 2.0155 Acc: 0.9667\t\n",
      "Epoch 1173/1599:\ttrain Loss: 2.0323 Acc: 0.9576\tval Loss: 2.0172 Acc: 0.9000\t\n",
      "Epoch 1174/1599:\ttrain Loss: 2.0209 Acc: 0.9915\tval Loss: 2.0140 Acc: 1.0000\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1175/1599:\ttrain Loss: 2.0287 Acc: 0.9788\tval Loss: 2.0155 Acc: 0.9667\t\n",
      "Epoch 1176/1599:\ttrain Loss: 2.0320 Acc: 0.9703\tval Loss: 2.0150 Acc: 0.9333\t\n",
      "Epoch 1177/1599:\ttrain Loss: 2.0411 Acc: 0.9576\tval Loss: 2.0158 Acc: 0.9667\t\n",
      "Epoch 1178/1599:\ttrain Loss: 2.0330 Acc: 0.9661\tval Loss: 2.0148 Acc: 0.9667\t\n",
      "Epoch 1179/1599:\ttrain Loss: 2.0283 Acc: 0.9661\tval Loss: 2.0173 Acc: 0.9333\t\n",
      "Epoch 1180/1599:\ttrain Loss: 2.0368 Acc: 0.9534\tval Loss: 2.0147 Acc: 0.9667\t\n",
      "Epoch 1181/1599:\ttrain Loss: 2.0281 Acc: 0.9703\tval Loss: 2.0152 Acc: 1.0000\t\n",
      "Epoch 1182/1599:\ttrain Loss: 2.0284 Acc: 0.9788\tval Loss: 2.0178 Acc: 0.9000\t\n",
      "Epoch 1183/1599:\ttrain Loss: 2.0320 Acc: 0.9619\tval Loss: 2.0148 Acc: 0.9667\t\n",
      "Epoch 1184/1599:\ttrain Loss: 2.0287 Acc: 0.9746\tval Loss: 2.0144 Acc: 0.9333\t\n",
      "Epoch 1185/1599:\ttrain Loss: 2.0167 Acc: 0.9958\tval Loss: 2.0152 Acc: 0.9667\t\n",
      "Epoch 1186/1599:\ttrain Loss: 2.0321 Acc: 0.9703\tval Loss: 2.0149 Acc: 0.9333\t\n",
      "Epoch 1187/1599:\ttrain Loss: 2.0322 Acc: 0.9831\tval Loss: 2.0182 Acc: 0.8667\t\n",
      "Epoch 1188/1599:\ttrain Loss: 2.0283 Acc: 0.9703\tval Loss: 2.0134 Acc: 1.0000\t\n",
      "Epoch 1189/1599:\ttrain Loss: 2.0246 Acc: 0.9788\tval Loss: 2.0211 Acc: 0.9000\t\n",
      "Epoch 1190/1599:\ttrain Loss: 2.0202 Acc: 0.9746\tval Loss: 2.0153 Acc: 0.9333\t\n",
      "Epoch 1191/1599:\ttrain Loss: 2.0244 Acc: 0.9703\tval Loss: 2.0165 Acc: 0.9333\t\n",
      "Epoch 1192/1599:\ttrain Loss: 2.0327 Acc: 0.9534\tval Loss: 2.0164 Acc: 0.9000\t\n",
      "Epoch 1193/1599:\ttrain Loss: 2.0287 Acc: 0.9703\tval Loss: 2.0188 Acc: 0.9667\t\n",
      "Epoch 1194/1599:\ttrain Loss: 2.0404 Acc: 0.9407\tval Loss: 2.0168 Acc: 0.9333\t\n",
      "Epoch 1195/1599:\ttrain Loss: 2.0243 Acc: 0.9788\tval Loss: 2.0146 Acc: 0.9667\t\n",
      "Epoch 1196/1599:\ttrain Loss: 2.0323 Acc: 0.9703\tval Loss: 2.0169 Acc: 0.9667\t\n",
      "Epoch 1197/1599:\ttrain Loss: 2.0284 Acc: 0.9788\tval Loss: 2.0156 Acc: 0.9667\t\n",
      "Epoch 1198/1599:\ttrain Loss: 2.0243 Acc: 0.9831\tval Loss: 2.0199 Acc: 0.9000\t\n",
      "Epoch 1199/1599:\ttrain Loss: 2.0361 Acc: 0.9576\tval Loss: 2.0158 Acc: 0.9333\t\n",
      "Epoch 1200/1599:\ttrain Loss: 2.0244 Acc: 0.9746\tval Loss: 2.0199 Acc: 0.9000\t\n",
      "Epoch 1201/1599:\ttrain Loss: 2.0246 Acc: 0.9788\tval Loss: 2.0146 Acc: 0.9667\t\n",
      "Epoch 1202/1599:\ttrain Loss: 2.0163 Acc: 0.9873\tval Loss: 2.0165 Acc: 0.9667\t\n",
      "Epoch 1203/1599:\ttrain Loss: 2.0248 Acc: 0.9703\tval Loss: 2.0156 Acc: 0.9667\t\n",
      "Epoch 1204/1599:\ttrain Loss: 2.0284 Acc: 0.9746\tval Loss: 2.0145 Acc: 0.9333\t\n",
      "Epoch 1205/1599:\ttrain Loss: 2.0288 Acc: 0.9746\tval Loss: 2.0148 Acc: 0.9333\t\n",
      "Epoch 1206/1599:\ttrain Loss: 2.0246 Acc: 0.9873\tval Loss: 2.0157 Acc: 0.9667\t\n",
      "Epoch 1207/1599:\ttrain Loss: 2.0409 Acc: 0.9492\tval Loss: 2.0177 Acc: 0.9000\t\n",
      "Epoch 1208/1599:\ttrain Loss: 2.0283 Acc: 0.9746\tval Loss: 2.0134 Acc: 0.9333\t\n",
      "Epoch 1209/1599:\ttrain Loss: 2.0235 Acc: 0.9831\tval Loss: 2.0157 Acc: 0.9333\t\n",
      "Epoch 1210/1599:\ttrain Loss: 2.0365 Acc: 0.9576\tval Loss: 2.0153 Acc: 0.9333\t\n",
      "Epoch 1211/1599:\ttrain Loss: 2.0281 Acc: 0.9788\tval Loss: 2.0156 Acc: 0.9667\t\n",
      "Epoch 1212/1599:\ttrain Loss: 2.0281 Acc: 0.9873\tval Loss: 2.0157 Acc: 0.9000\t\n",
      "Epoch 1213/1599:\ttrain Loss: 2.0280 Acc: 0.9534\tval Loss: 2.0168 Acc: 0.9333\t\n",
      "Epoch 1214/1599:\ttrain Loss: 2.0405 Acc: 0.9449\tval Loss: 2.0164 Acc: 0.9000\t\n",
      "Epoch 1215/1599:\ttrain Loss: 2.0283 Acc: 0.9746\tval Loss: 2.0166 Acc: 0.9000\t\n",
      "Epoch 1216/1599:\ttrain Loss: 2.0243 Acc: 0.9831\tval Loss: 2.0157 Acc: 0.9000\t\n",
      "Epoch 1217/1599:\ttrain Loss: 2.0246 Acc: 0.9788\tval Loss: 2.0152 Acc: 0.9667\t\n",
      "Epoch 1218/1599:\ttrain Loss: 2.0244 Acc: 0.9746\tval Loss: 2.0149 Acc: 0.9667\t\n",
      "Epoch 1219/1599:\ttrain Loss: 2.0285 Acc: 0.9746\tval Loss: 2.0164 Acc: 0.9333\t\n",
      "Epoch 1220/1599:\ttrain Loss: 2.0280 Acc: 0.9661\tval Loss: 2.0159 Acc: 0.9667\t\n",
      "Epoch 1221/1599:\ttrain Loss: 2.0282 Acc: 0.9873\tval Loss: 2.0153 Acc: 0.9333\t\n",
      "Epoch 1222/1599:\ttrain Loss: 2.0278 Acc: 0.9661\tval Loss: 2.0153 Acc: 0.9667\t\n",
      "Epoch 1223/1599:\ttrain Loss: 2.0321 Acc: 0.9661\tval Loss: 2.0181 Acc: 0.9000\t\n",
      "Epoch 1224/1599:\ttrain Loss: 2.0163 Acc: 0.9915\tval Loss: 2.0151 Acc: 0.9333\t\n",
      "Epoch 1225/1599:\ttrain Loss: 2.0200 Acc: 0.9915\tval Loss: 2.0153 Acc: 1.0000\t\n",
      "Epoch 1226/1599:\ttrain Loss: 2.0201 Acc: 0.9788\tval Loss: 2.0167 Acc: 1.0000\t\n",
      "Epoch 1227/1599:\ttrain Loss: 2.0241 Acc: 0.9831\tval Loss: 2.0149 Acc: 0.9667\t\n",
      "Epoch 1228/1599:\ttrain Loss: 2.0323 Acc: 0.9661\tval Loss: 2.0160 Acc: 1.0000\t\n",
      "Epoch 1229/1599:\ttrain Loss: 2.0242 Acc: 0.9788\tval Loss: 2.0160 Acc: 0.9667\t\n",
      "Epoch 1230/1599:\ttrain Loss: 2.0119 Acc: 0.9915\tval Loss: 2.0137 Acc: 0.9667\t\n",
      "Epoch 1231/1599:\ttrain Loss: 2.0365 Acc: 0.9703\tval Loss: 2.0148 Acc: 1.0000\t\n",
      "Epoch 1232/1599:\ttrain Loss: 2.0316 Acc: 0.9576\tval Loss: 2.0159 Acc: 1.0000\t\n",
      "Epoch 1233/1599:\ttrain Loss: 2.0248 Acc: 0.9873\tval Loss: 2.0155 Acc: 1.0000\t\n",
      "Epoch 1234/1599:\ttrain Loss: 2.0241 Acc: 0.9788\tval Loss: 2.0161 Acc: 0.9667\t\n",
      "Epoch 1235/1599:\ttrain Loss: 2.0283 Acc: 0.9746\tval Loss: 2.0139 Acc: 0.9667\t\n",
      "Epoch 1236/1599:\ttrain Loss: 2.0202 Acc: 0.9788\tval Loss: 2.0142 Acc: 0.9667\t\n",
      "Epoch 1237/1599:\ttrain Loss: 2.0358 Acc: 0.9619\tval Loss: 2.0136 Acc: 0.9333\t\n",
      "Epoch 1238/1599:\ttrain Loss: 2.0361 Acc: 0.9534\tval Loss: 2.0158 Acc: 0.9000\t\n",
      "Epoch 1239/1599:\ttrain Loss: 2.0318 Acc: 0.9661\tval Loss: 2.0140 Acc: 1.0000\t\n",
      "Epoch 1240/1599:\ttrain Loss: 2.0284 Acc: 0.9534\tval Loss: 2.0146 Acc: 0.9333\t\n",
      "Epoch 1241/1599:\ttrain Loss: 2.0197 Acc: 0.9788\tval Loss: 2.0151 Acc: 0.9667\t\n",
      "Epoch 1242/1599:\ttrain Loss: 2.0322 Acc: 0.9576\tval Loss: 2.0153 Acc: 0.9667\t\n",
      "Epoch 1243/1599:\ttrain Loss: 2.0241 Acc: 0.9831\tval Loss: 2.0154 Acc: 1.0000\t\n",
      "Epoch 1244/1599:\ttrain Loss: 2.0285 Acc: 0.9746\tval Loss: 2.0158 Acc: 0.9667\t\n",
      "Epoch 1245/1599:\ttrain Loss: 2.0204 Acc: 0.9915\tval Loss: 2.0168 Acc: 0.9333\t\n",
      "Epoch 1246/1599:\ttrain Loss: 2.0356 Acc: 0.9619\tval Loss: 2.0182 Acc: 0.9333\t\n",
      "Epoch 1247/1599:\ttrain Loss: 2.0282 Acc: 0.9703\tval Loss: 2.0164 Acc: 1.0000\t\n",
      "Epoch 1248/1599:\ttrain Loss: 2.0176 Acc: 0.9873\tval Loss: 2.0173 Acc: 0.9667\t\n",
      "Epoch 1249/1599:\ttrain Loss: 2.0325 Acc: 0.9746\tval Loss: 2.0154 Acc: 0.9333\t\n",
      "Epoch 1250/1599:\ttrain Loss: 2.0321 Acc: 0.9661\tval Loss: 2.0150 Acc: 1.0000\t\n",
      "Epoch 1251/1599:\ttrain Loss: 2.0160 Acc: 0.9958\tval Loss: 2.0144 Acc: 0.9333\t\n",
      "Epoch 1252/1599:\ttrain Loss: 2.0323 Acc: 0.9661\tval Loss: 2.0147 Acc: 0.9333\t\n",
      "Epoch 1253/1599:\ttrain Loss: 2.0237 Acc: 0.9788\tval Loss: 2.0156 Acc: 0.9667\t\n",
      "Epoch 1254/1599:\ttrain Loss: 2.0197 Acc: 0.9746\tval Loss: 2.0153 Acc: 0.9333\t\n",
      "Epoch 1255/1599:\ttrain Loss: 2.0204 Acc: 0.9915\tval Loss: 2.0142 Acc: 0.9333\t\n",
      "Epoch 1256/1599:\ttrain Loss: 2.0318 Acc: 0.9576\tval Loss: 2.0152 Acc: 0.9000\t\n",
      "Epoch 1257/1599:\ttrain Loss: 2.0284 Acc: 0.9703\tval Loss: 2.0142 Acc: 0.9667\t\n",
      "Epoch 1258/1599:\ttrain Loss: 2.0163 Acc: 0.9958\tval Loss: 2.0149 Acc: 0.9333\t\n",
      "Epoch 1259/1599:\ttrain Loss: 2.0261 Acc: 0.9873\tval Loss: 2.0178 Acc: 0.9000\t\n",
      "Epoch 1260/1599:\ttrain Loss: 2.0300 Acc: 0.9746\tval Loss: 2.0181 Acc: 0.9667\t\n",
      "Epoch 1261/1599:\ttrain Loss: 2.0249 Acc: 0.9661\tval Loss: 2.0177 Acc: 0.9333\t\n",
      "Epoch 1262/1599:\ttrain Loss: 2.0317 Acc: 0.9746\tval Loss: 2.0150 Acc: 0.9667\t\n",
      "Epoch 1263/1599:\ttrain Loss: 2.0387 Acc: 0.9364\tval Loss: 2.0168 Acc: 0.9000\t\n",
      "Epoch 1264/1599:\ttrain Loss: 2.0338 Acc: 0.9280\tval Loss: 2.0153 Acc: 0.9333\t\n",
      "Epoch 1265/1599:\ttrain Loss: 2.0209 Acc: 0.9873\tval Loss: 2.0170 Acc: 0.9000\t\n",
      "Epoch 1266/1599:\ttrain Loss: 2.0216 Acc: 0.9873\tval Loss: 2.0149 Acc: 0.9000\t\n",
      "Epoch 1267/1599:\ttrain Loss: 2.0285 Acc: 0.9831\tval Loss: 2.0147 Acc: 0.9333\t\n",
      "Epoch 1268/1599:\ttrain Loss: 2.0334 Acc: 0.9703\tval Loss: 2.0156 Acc: 0.9333\t\n",
      "Epoch 1269/1599:\ttrain Loss: 2.0215 Acc: 0.9661\tval Loss: 2.0175 Acc: 0.9333\t\n",
      "Epoch 1270/1599:\ttrain Loss: 2.0325 Acc: 0.9788\tval Loss: 2.0149 Acc: 0.9667\t\n",
      "Epoch 1271/1599:\ttrain Loss: 2.0407 Acc: 0.9619\tval Loss: 2.0160 Acc: 0.9333\t\n",
      "Epoch 1272/1599:\ttrain Loss: 2.0122 Acc: 0.9958\tval Loss: 2.0168 Acc: 0.9667\t\n",
      "Epoch 1273/1599:\ttrain Loss: 2.0202 Acc: 0.9915\tval Loss: 2.0152 Acc: 0.9667\t\n",
      "Epoch 1274/1599:\ttrain Loss: 2.0324 Acc: 0.9703\tval Loss: 2.0150 Acc: 0.9333\t\n",
      "Epoch 1275/1599:\ttrain Loss: 2.0492 Acc: 0.9237\tval Loss: 2.0125 Acc: 0.9667\t\n",
      "Epoch 1276/1599:\ttrain Loss: 2.0403 Acc: 0.9364\tval Loss: 2.0153 Acc: 0.9667\t\n",
      "Epoch 1277/1599:\ttrain Loss: 2.0197 Acc: 0.9831\tval Loss: 2.0153 Acc: 0.9000\t\n",
      "Epoch 1278/1599:\ttrain Loss: 2.0400 Acc: 0.9492\tval Loss: 2.0149 Acc: 0.9667\t\n",
      "Epoch 1279/1599:\ttrain Loss: 2.0284 Acc: 0.9788\tval Loss: 2.0165 Acc: 0.9000\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1280/1599:\ttrain Loss: 2.0322 Acc: 0.9831\tval Loss: 2.0161 Acc: 1.0000\t\n",
      "Epoch 1281/1599:\ttrain Loss: 2.0365 Acc: 0.9619\tval Loss: 2.0145 Acc: 1.0000\t\n",
      "Epoch 1282/1599:\ttrain Loss: 2.0409 Acc: 0.9492\tval Loss: 2.0148 Acc: 0.9667\t\n",
      "Epoch 1283/1599:\ttrain Loss: 2.0286 Acc: 0.9576\tval Loss: 2.0160 Acc: 1.0000\t\n",
      "Epoch 1284/1599:\ttrain Loss: 2.0206 Acc: 0.9873\tval Loss: 2.0154 Acc: 0.9333\t\n",
      "Epoch 1285/1599:\ttrain Loss: 2.0198 Acc: 0.9831\tval Loss: 2.0163 Acc: 0.9667\t\n",
      "Epoch 1286/1599:\ttrain Loss: 2.0367 Acc: 0.9661\tval Loss: 2.0161 Acc: 0.9333\t\n",
      "Epoch 1287/1599:\ttrain Loss: 2.0435 Acc: 0.9407\tval Loss: 2.0150 Acc: 0.9667\t\n",
      "Epoch 1288/1599:\ttrain Loss: 2.0240 Acc: 0.9831\tval Loss: 2.0169 Acc: 0.9667\t\n",
      "Epoch 1289/1599:\ttrain Loss: 2.0237 Acc: 0.9788\tval Loss: 2.0164 Acc: 0.9000\t\n",
      "Epoch 1290/1599:\ttrain Loss: 2.0241 Acc: 0.9788\tval Loss: 2.0153 Acc: 0.9333\t\n",
      "Epoch 1291/1599:\ttrain Loss: 2.0328 Acc: 0.9576\tval Loss: 2.0134 Acc: 0.9667\t\n",
      "Epoch 1292/1599:\ttrain Loss: 2.0208 Acc: 0.9915\tval Loss: 2.0131 Acc: 0.9667\t\n",
      "Epoch 1293/1599:\ttrain Loss: 2.0352 Acc: 0.9661\tval Loss: 2.0193 Acc: 0.9000\t\n",
      "Epoch 1294/1599:\ttrain Loss: 2.0318 Acc: 0.9619\tval Loss: 2.0161 Acc: 0.9333\t\n",
      "Epoch 1295/1599:\ttrain Loss: 2.0236 Acc: 0.9831\tval Loss: 2.0143 Acc: 0.9333\t\n",
      "Epoch 1296/1599:\ttrain Loss: 2.0322 Acc: 0.9831\tval Loss: 2.0185 Acc: 0.9000\t\n",
      "Epoch 1297/1599:\ttrain Loss: 2.0278 Acc: 0.9873\tval Loss: 2.0150 Acc: 0.9667\t\n",
      "Epoch 1298/1599:\ttrain Loss: 2.0240 Acc: 0.9873\tval Loss: 2.0136 Acc: 0.9333\t\n",
      "Epoch 1299/1599:\ttrain Loss: 2.0320 Acc: 0.9534\tval Loss: 2.0144 Acc: 0.9667\t\n",
      "Epoch 1300/1599:\ttrain Loss: 2.0160 Acc: 0.9788\tval Loss: 2.0164 Acc: 0.9333\t\n",
      "Epoch 1301/1599:\ttrain Loss: 2.0198 Acc: 0.9788\tval Loss: 2.0144 Acc: 0.9667\t\n",
      "Epoch 1302/1599:\ttrain Loss: 2.0445 Acc: 0.9534\tval Loss: 2.0155 Acc: 0.9333\t\n",
      "Epoch 1303/1599:\ttrain Loss: 2.0285 Acc: 0.9746\tval Loss: 2.0155 Acc: 0.9667\t\n",
      "Epoch 1304/1599:\ttrain Loss: 2.0200 Acc: 0.9873\tval Loss: 2.0152 Acc: 0.9333\t\n",
      "Epoch 1305/1599:\ttrain Loss: 2.0282 Acc: 0.9746\tval Loss: 2.0146 Acc: 1.0000\t\n",
      "Epoch 1306/1599:\ttrain Loss: 2.0363 Acc: 0.9407\tval Loss: 2.0164 Acc: 0.9667\t\n",
      "Epoch 1307/1599:\ttrain Loss: 2.0318 Acc: 0.9746\tval Loss: 2.0152 Acc: 1.0000\t\n",
      "Epoch 1308/1599:\ttrain Loss: 2.0206 Acc: 0.9915\tval Loss: 2.0142 Acc: 0.9333\t\n",
      "Epoch 1309/1599:\ttrain Loss: 2.0285 Acc: 0.9492\tval Loss: 2.0223 Acc: 0.9333\t\n",
      "Epoch 1310/1599:\ttrain Loss: 2.0289 Acc: 0.9534\tval Loss: 2.0144 Acc: 0.9333\t\n",
      "Epoch 1311/1599:\ttrain Loss: 2.0204 Acc: 0.9788\tval Loss: 2.0149 Acc: 0.9333\t\n",
      "Epoch 1312/1599:\ttrain Loss: 2.0361 Acc: 0.9703\tval Loss: 2.0162 Acc: 0.9667\t\n",
      "Epoch 1313/1599:\ttrain Loss: 2.0241 Acc: 0.9831\tval Loss: 2.0173 Acc: 0.8667\t\n",
      "Epoch 1314/1599:\ttrain Loss: 2.0201 Acc: 0.9831\tval Loss: 2.0138 Acc: 0.9667\t\n",
      "Epoch 1315/1599:\ttrain Loss: 2.0324 Acc: 0.9788\tval Loss: 2.0144 Acc: 0.9667\t\n",
      "Epoch 1316/1599:\ttrain Loss: 2.0348 Acc: 0.9788\tval Loss: 2.0158 Acc: 0.9333\t\n",
      "Epoch 1317/1599:\ttrain Loss: 2.0399 Acc: 0.9746\tval Loss: 2.0136 Acc: 0.9667\t\n",
      "Epoch 1318/1599:\ttrain Loss: 2.0319 Acc: 0.9788\tval Loss: 2.0145 Acc: 0.9333\t\n",
      "Epoch 1319/1599:\ttrain Loss: 2.0282 Acc: 0.9788\tval Loss: 2.0142 Acc: 1.0000\t\n",
      "Epoch 1320/1599:\ttrain Loss: 2.0201 Acc: 0.9915\tval Loss: 2.0146 Acc: 0.9667\t\n",
      "Epoch 1321/1599:\ttrain Loss: 2.0235 Acc: 0.9915\tval Loss: 2.0146 Acc: 0.9333\t\n",
      "Epoch 1322/1599:\ttrain Loss: 2.0276 Acc: 0.9831\tval Loss: 2.0159 Acc: 0.9333\t\n",
      "Epoch 1323/1599:\ttrain Loss: 2.0278 Acc: 0.9703\tval Loss: 2.0148 Acc: 0.9667\t\n",
      "Epoch 1324/1599:\ttrain Loss: 2.0442 Acc: 0.9449\tval Loss: 2.0143 Acc: 0.9333\t\n",
      "Epoch 1325/1599:\ttrain Loss: 2.0197 Acc: 0.9915\tval Loss: 2.0141 Acc: 0.9667\t\n",
      "Epoch 1326/1599:\ttrain Loss: 2.0275 Acc: 0.9831\tval Loss: 2.0144 Acc: 0.9000\t\n",
      "Epoch 1327/1599:\ttrain Loss: 2.0272 Acc: 0.9746\tval Loss: 2.0150 Acc: 0.9667\t\n",
      "Epoch 1328/1599:\ttrain Loss: 2.0315 Acc: 0.9831\tval Loss: 2.0139 Acc: 0.9667\t\n",
      "Epoch 1329/1599:\ttrain Loss: 2.0274 Acc: 0.9831\tval Loss: 2.0145 Acc: 0.9667\t\n",
      "Epoch 1330/1599:\ttrain Loss: 2.0189 Acc: 0.9873\tval Loss: 2.0144 Acc: 0.9667\t\n",
      "Epoch 1331/1599:\ttrain Loss: 2.0274 Acc: 0.9788\tval Loss: 2.0145 Acc: 0.9333\t\n",
      "Epoch 1332/1599:\ttrain Loss: 2.0316 Acc: 0.9746\tval Loss: 2.0163 Acc: 0.9667\t\n",
      "Epoch 1333/1599:\ttrain Loss: 2.0165 Acc: 0.9915\tval Loss: 2.0146 Acc: 0.9667\t\n",
      "Epoch 1334/1599:\ttrain Loss: 2.0320 Acc: 0.9831\tval Loss: 2.0132 Acc: 0.9333\t\n",
      "Epoch 1335/1599:\ttrain Loss: 2.0403 Acc: 0.9576\tval Loss: 2.0155 Acc: 0.9000\t\n",
      "Epoch 1336/1599:\ttrain Loss: 2.0284 Acc: 0.9788\tval Loss: 2.0155 Acc: 0.9667\t\n",
      "Epoch 1337/1599:\ttrain Loss: 2.0235 Acc: 0.9703\tval Loss: 2.0141 Acc: 0.9667\t\n",
      "Epoch 1338/1599:\ttrain Loss: 2.0235 Acc: 0.9831\tval Loss: 2.0135 Acc: 0.9333\t\n",
      "Epoch 1339/1599:\ttrain Loss: 2.0235 Acc: 0.9746\tval Loss: 2.0125 Acc: 0.9333\t\n",
      "Epoch 1340/1599:\ttrain Loss: 2.0117 Acc: 1.0000\tval Loss: 2.0154 Acc: 0.9333\t\n",
      "Epoch 1341/1599:\ttrain Loss: 2.0237 Acc: 0.9831\tval Loss: 2.0167 Acc: 0.9333\t\n",
      "Epoch 1342/1599:\ttrain Loss: 2.0283 Acc: 0.9746\tval Loss: 2.0150 Acc: 0.9333\t\n",
      "Epoch 1343/1599:\ttrain Loss: 2.0273 Acc: 0.9703\tval Loss: 2.0173 Acc: 0.9333\t\n",
      "Epoch 1344/1599:\ttrain Loss: 2.0239 Acc: 0.9831\tval Loss: 2.0192 Acc: 0.9333\t\n",
      "Epoch 1345/1599:\ttrain Loss: 2.0318 Acc: 0.9746\tval Loss: 2.0169 Acc: 0.9333\t\n",
      "Epoch 1346/1599:\ttrain Loss: 2.0282 Acc: 0.9831\tval Loss: 2.0195 Acc: 0.9333\t\n",
      "Epoch 1347/1599:\ttrain Loss: 2.0444 Acc: 0.9364\tval Loss: 2.0170 Acc: 0.9000\t\n",
      "Epoch 1348/1599:\ttrain Loss: 2.0316 Acc: 0.9703\tval Loss: 2.0159 Acc: 0.9333\t\n",
      "Epoch 1349/1599:\ttrain Loss: 2.0358 Acc: 0.9746\tval Loss: 2.0165 Acc: 0.9000\t\n",
      "Epoch 1350/1599:\ttrain Loss: 2.0359 Acc: 0.9661\tval Loss: 2.0160 Acc: 0.9667\t\n",
      "Epoch 1351/1599:\ttrain Loss: 2.0240 Acc: 0.9831\tval Loss: 2.0140 Acc: 0.9667\t\n",
      "Epoch 1352/1599:\ttrain Loss: 2.0160 Acc: 0.9958\tval Loss: 2.0161 Acc: 0.9000\t\n",
      "Epoch 1353/1599:\ttrain Loss: 2.0163 Acc: 0.9873\tval Loss: 2.0155 Acc: 0.9667\t\n",
      "Epoch 1354/1599:\ttrain Loss: 2.0323 Acc: 0.9746\tval Loss: 2.0145 Acc: 0.9333\t\n",
      "Epoch 1355/1599:\ttrain Loss: 2.0281 Acc: 0.9619\tval Loss: 2.0172 Acc: 0.9333\t\n",
      "Epoch 1356/1599:\ttrain Loss: 2.0195 Acc: 0.9831\tval Loss: 2.0153 Acc: 0.9667\t\n",
      "Epoch 1357/1599:\ttrain Loss: 2.0198 Acc: 0.9958\tval Loss: 2.0139 Acc: 0.9667\t\n",
      "Epoch 1358/1599:\ttrain Loss: 2.0194 Acc: 0.9915\tval Loss: 2.0157 Acc: 0.9667\t\n",
      "Epoch 1359/1599:\ttrain Loss: 2.0238 Acc: 0.9746\tval Loss: 2.0145 Acc: 0.9667\t\n",
      "Epoch 1360/1599:\ttrain Loss: 2.0236 Acc: 0.9915\tval Loss: 2.0142 Acc: 0.9667\t\n",
      "Epoch 1361/1599:\ttrain Loss: 2.0233 Acc: 0.9746\tval Loss: 2.0195 Acc: 0.9333\t\n",
      "Epoch 1362/1599:\ttrain Loss: 2.0199 Acc: 0.9746\tval Loss: 2.0142 Acc: 0.9333\t\n",
      "Epoch 1363/1599:\ttrain Loss: 2.0359 Acc: 0.9873\tval Loss: 2.0152 Acc: 0.9667\t\n",
      "Epoch 1364/1599:\ttrain Loss: 2.0193 Acc: 0.9915\tval Loss: 2.0183 Acc: 0.9333\t\n",
      "Epoch 1365/1599:\ttrain Loss: 2.0240 Acc: 0.9873\tval Loss: 2.0191 Acc: 0.9000\t\n",
      "Epoch 1366/1599:\ttrain Loss: 2.0240 Acc: 0.9831\tval Loss: 2.0156 Acc: 0.9333\t\n",
      "Epoch 1367/1599:\ttrain Loss: 2.0322 Acc: 0.9703\tval Loss: 2.0157 Acc: 0.9333\t\n",
      "Epoch 1368/1599:\ttrain Loss: 2.0359 Acc: 0.9703\tval Loss: 2.0159 Acc: 0.9333\t\n",
      "Epoch 1369/1599:\ttrain Loss: 2.0354 Acc: 0.9831\tval Loss: 2.0156 Acc: 0.9333\t\n",
      "Epoch 1370/1599:\ttrain Loss: 2.0207 Acc: 0.9788\tval Loss: 2.0176 Acc: 0.9333\t\n",
      "Epoch 1371/1599:\ttrain Loss: 2.0324 Acc: 0.9492\tval Loss: 2.0138 Acc: 1.0000\t\n",
      "Epoch 1372/1599:\ttrain Loss: 2.0238 Acc: 0.9746\tval Loss: 2.0152 Acc: 0.9667\t\n",
      "Epoch 1373/1599:\ttrain Loss: 2.0233 Acc: 0.9873\tval Loss: 2.0150 Acc: 0.9667\t\n",
      "Epoch 1374/1599:\ttrain Loss: 2.0279 Acc: 0.9788\tval Loss: 2.0133 Acc: 1.0000\t\n",
      "Epoch 1375/1599:\ttrain Loss: 2.0282 Acc: 0.9788\tval Loss: 2.0163 Acc: 0.9667\t\n",
      "Epoch 1376/1599:\ttrain Loss: 2.0201 Acc: 0.9958\tval Loss: 2.0174 Acc: 0.9333\t\n",
      "Epoch 1377/1599:\ttrain Loss: 2.0235 Acc: 0.9915\tval Loss: 2.0139 Acc: 0.9667\t\n",
      "Epoch 1378/1599:\ttrain Loss: 2.0319 Acc: 0.9661\tval Loss: 2.0146 Acc: 0.9667\t\n",
      "Epoch 1379/1599:\ttrain Loss: 2.0324 Acc: 0.9661\tval Loss: 2.0154 Acc: 0.9333\t\n",
      "Epoch 1380/1599:\ttrain Loss: 2.0395 Acc: 0.9619\tval Loss: 2.0151 Acc: 0.9667\t\n",
      "Epoch 1381/1599:\ttrain Loss: 2.0238 Acc: 0.9958\tval Loss: 2.0152 Acc: 0.9333\t\n",
      "Epoch 1382/1599:\ttrain Loss: 2.0315 Acc: 0.9788\tval Loss: 2.0143 Acc: 1.0000\t\n",
      "Epoch 1383/1599:\ttrain Loss: 2.0277 Acc: 0.9788\tval Loss: 2.0167 Acc: 0.9667\t\n",
      "Epoch 1384/1599:\ttrain Loss: 2.0321 Acc: 0.9831\tval Loss: 2.0191 Acc: 0.9333\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1385/1599:\ttrain Loss: 2.0366 Acc: 0.9576\tval Loss: 2.0159 Acc: 0.9667\t\n",
      "Epoch 1386/1599:\ttrain Loss: 2.0276 Acc: 0.9661\tval Loss: 2.0153 Acc: 0.9333\t\n",
      "Epoch 1387/1599:\ttrain Loss: 2.0248 Acc: 0.9873\tval Loss: 2.0155 Acc: 0.9333\t\n",
      "Epoch 1388/1599:\ttrain Loss: 2.0395 Acc: 0.9661\tval Loss: 2.0244 Acc: 0.9333\t\n",
      "Epoch 1389/1599:\ttrain Loss: 2.0243 Acc: 0.9915\tval Loss: 2.0132 Acc: 0.9667\t\n",
      "Epoch 1390/1599:\ttrain Loss: 2.0401 Acc: 0.9576\tval Loss: 2.0142 Acc: 0.9667\t\n",
      "Epoch 1391/1599:\ttrain Loss: 2.0193 Acc: 0.9873\tval Loss: 2.0140 Acc: 0.9667\t\n",
      "Epoch 1392/1599:\ttrain Loss: 2.0154 Acc: 0.9915\tval Loss: 2.0141 Acc: 0.9333\t\n",
      "Epoch 1393/1599:\ttrain Loss: 2.0227 Acc: 0.9915\tval Loss: 2.0144 Acc: 0.9333\t\n",
      "Epoch 1394/1599:\ttrain Loss: 2.0202 Acc: 1.0000\tval Loss: 2.0167 Acc: 0.9667\t\n",
      "Epoch 1395/1599:\ttrain Loss: 2.0235 Acc: 0.9831\tval Loss: 2.0153 Acc: 0.9667\t\n",
      "Epoch 1396/1599:\ttrain Loss: 2.0392 Acc: 0.9703\tval Loss: 2.0147 Acc: 0.9667\t\n",
      "Epoch 1397/1599:\ttrain Loss: 2.0317 Acc: 0.9831\tval Loss: 2.0148 Acc: 0.9667\t\n",
      "Epoch 1398/1599:\ttrain Loss: 2.0198 Acc: 0.9873\tval Loss: 2.0137 Acc: 1.0000\t\n",
      "Epoch 1399/1599:\ttrain Loss: 2.0275 Acc: 0.9788\tval Loss: 2.0162 Acc: 0.9333\t\n",
      "Epoch 1400/1599:\ttrain Loss: 2.0358 Acc: 0.9703\tval Loss: 2.0164 Acc: 0.9333\t\n",
      "Epoch 1401/1599:\ttrain Loss: 2.0320 Acc: 0.9703\tval Loss: 2.0146 Acc: 0.9667\t\n",
      "Epoch 1402/1599:\ttrain Loss: 2.0277 Acc: 0.9703\tval Loss: 2.0129 Acc: 1.0000\t\n",
      "Epoch 1403/1599:\ttrain Loss: 2.0242 Acc: 0.9831\tval Loss: 2.0167 Acc: 0.9000\t\n",
      "Epoch 1404/1599:\ttrain Loss: 2.0242 Acc: 0.9788\tval Loss: 2.0168 Acc: 0.9000\t\n",
      "Epoch 1405/1599:\ttrain Loss: 2.0113 Acc: 0.9958\tval Loss: 2.0148 Acc: 0.9667\t\n",
      "Epoch 1406/1599:\ttrain Loss: 2.0320 Acc: 0.9703\tval Loss: 2.0151 Acc: 0.9333\t\n",
      "Epoch 1407/1599:\ttrain Loss: 2.0362 Acc: 0.9449\tval Loss: 2.0137 Acc: 0.9333\t\n",
      "Epoch 1408/1599:\ttrain Loss: 2.0361 Acc: 0.9449\tval Loss: 2.0133 Acc: 0.9333\t\n",
      "Epoch 1409/1599:\ttrain Loss: 2.0197 Acc: 0.9958\tval Loss: 2.0177 Acc: 0.9000\t\n",
      "Epoch 1410/1599:\ttrain Loss: 2.0242 Acc: 0.9958\tval Loss: 2.0139 Acc: 0.9333\t\n",
      "Epoch 1411/1599:\ttrain Loss: 2.0400 Acc: 0.9449\tval Loss: 2.0142 Acc: 0.9333\t\n",
      "Epoch 1412/1599:\ttrain Loss: 2.0284 Acc: 0.9746\tval Loss: 2.0135 Acc: 0.9333\t\n",
      "Epoch 1413/1599:\ttrain Loss: 2.0191 Acc: 0.9915\tval Loss: 2.0136 Acc: 0.9333\t\n",
      "Epoch 1414/1599:\ttrain Loss: 2.0316 Acc: 0.9746\tval Loss: 2.0153 Acc: 0.9333\t\n",
      "Epoch 1415/1599:\ttrain Loss: 2.0440 Acc: 0.9492\tval Loss: 2.0140 Acc: 0.9333\t\n",
      "Epoch 1416/1599:\ttrain Loss: 2.0283 Acc: 0.9788\tval Loss: 2.0137 Acc: 0.9333\t\n",
      "Epoch 1417/1599:\ttrain Loss: 2.0436 Acc: 0.9661\tval Loss: 2.0154 Acc: 1.0000\t\n",
      "Epoch 1418/1599:\ttrain Loss: 2.0201 Acc: 0.9831\tval Loss: 2.0149 Acc: 0.9667\t\n",
      "Epoch 1419/1599:\ttrain Loss: 2.0279 Acc: 0.9958\tval Loss: 2.0178 Acc: 0.9333\t\n",
      "Epoch 1420/1599:\ttrain Loss: 2.0205 Acc: 0.9746\tval Loss: 2.0151 Acc: 0.9667\t\n",
      "Epoch 1421/1599:\ttrain Loss: 2.0273 Acc: 0.9873\tval Loss: 2.0149 Acc: 0.9333\t\n",
      "Epoch 1422/1599:\ttrain Loss: 2.0235 Acc: 0.9788\tval Loss: 2.0150 Acc: 0.9333\t\n",
      "Epoch 1423/1599:\ttrain Loss: 2.0246 Acc: 0.9703\tval Loss: 2.0152 Acc: 1.0000\t\n",
      "Epoch 1424/1599:\ttrain Loss: 2.0281 Acc: 0.9746\tval Loss: 2.0130 Acc: 0.9333\t\n",
      "Epoch 1425/1599:\ttrain Loss: 2.0322 Acc: 0.9746\tval Loss: 2.0161 Acc: 0.9667\t\n",
      "Epoch 1426/1599:\ttrain Loss: 2.0244 Acc: 0.9746\tval Loss: 2.0143 Acc: 0.9333\t\n",
      "Epoch 1427/1599:\ttrain Loss: 2.0275 Acc: 0.9915\tval Loss: 2.0179 Acc: 0.9667\t\n",
      "Epoch 1428/1599:\ttrain Loss: 2.0354 Acc: 0.9619\tval Loss: 2.0156 Acc: 0.9667\t\n",
      "Epoch 1429/1599:\ttrain Loss: 2.0237 Acc: 0.9873\tval Loss: 2.0161 Acc: 0.9333\t\n",
      "Epoch 1430/1599:\ttrain Loss: 2.0197 Acc: 0.9788\tval Loss: 2.0154 Acc: 0.9333\t\n",
      "Epoch 1431/1599:\ttrain Loss: 2.0237 Acc: 0.9831\tval Loss: 2.0146 Acc: 0.9667\t\n",
      "Epoch 1432/1599:\ttrain Loss: 2.0279 Acc: 0.9831\tval Loss: 2.0145 Acc: 0.9667\t\n",
      "Epoch 1433/1599:\ttrain Loss: 2.0272 Acc: 0.9746\tval Loss: 2.0133 Acc: 0.9333\t\n",
      "Epoch 1434/1599:\ttrain Loss: 2.0237 Acc: 0.9873\tval Loss: 2.0139 Acc: 0.9667\t\n",
      "Epoch 1435/1599:\ttrain Loss: 2.0149 Acc: 0.9958\tval Loss: 2.0193 Acc: 0.9333\t\n",
      "Epoch 1436/1599:\ttrain Loss: 2.0159 Acc: 0.9873\tval Loss: 2.0143 Acc: 0.9667\t\n",
      "Epoch 1437/1599:\ttrain Loss: 2.0320 Acc: 0.9746\tval Loss: 2.0156 Acc: 0.9667\t\n",
      "Epoch 1438/1599:\ttrain Loss: 2.0157 Acc: 0.9958\tval Loss: 2.0140 Acc: 1.0000\t\n",
      "Epoch 1439/1599:\ttrain Loss: 2.0312 Acc: 0.9661\tval Loss: 2.0153 Acc: 0.9333\t\n",
      "Epoch 1440/1599:\ttrain Loss: 2.0356 Acc: 0.9703\tval Loss: 2.0148 Acc: 0.9667\t\n",
      "Epoch 1441/1599:\ttrain Loss: 2.0357 Acc: 0.9576\tval Loss: 2.0155 Acc: 0.9667\t\n",
      "Epoch 1442/1599:\ttrain Loss: 2.0313 Acc: 0.9831\tval Loss: 2.0155 Acc: 1.0000\t\n",
      "Epoch 1443/1599:\ttrain Loss: 2.0318 Acc: 0.9703\tval Loss: 2.0146 Acc: 0.9667\t\n",
      "Epoch 1444/1599:\ttrain Loss: 2.0280 Acc: 0.9703\tval Loss: 2.0151 Acc: 1.0000\t\n",
      "Epoch 1445/1599:\ttrain Loss: 2.0393 Acc: 0.9661\tval Loss: 2.0165 Acc: 0.9333\t\n",
      "Epoch 1446/1599:\ttrain Loss: 2.0270 Acc: 0.9831\tval Loss: 2.0208 Acc: 0.9333\t\n",
      "Epoch 1447/1599:\ttrain Loss: 2.0355 Acc: 0.9534\tval Loss: 2.0140 Acc: 1.0000\t\n",
      "Epoch 1448/1599:\ttrain Loss: 2.0237 Acc: 0.9746\tval Loss: 2.0155 Acc: 0.9667\t\n",
      "Epoch 1449/1599:\ttrain Loss: 2.0241 Acc: 0.9831\tval Loss: 2.0151 Acc: 0.9667\t\n",
      "Epoch 1450/1599:\ttrain Loss: 2.0154 Acc: 0.9915\tval Loss: 2.0140 Acc: 0.9667\t\n",
      "Epoch 1451/1599:\ttrain Loss: 2.0275 Acc: 0.9915\tval Loss: 2.0141 Acc: 0.9667\t\n",
      "Epoch 1452/1599:\ttrain Loss: 2.0316 Acc: 0.9831\tval Loss: 2.0152 Acc: 1.0000\t\n",
      "Epoch 1453/1599:\ttrain Loss: 2.0272 Acc: 0.9831\tval Loss: 2.0179 Acc: 0.9333\t\n",
      "Epoch 1454/1599:\ttrain Loss: 2.0309 Acc: 0.9746\tval Loss: 2.0262 Acc: 0.9667\t\n",
      "Epoch 1455/1599:\ttrain Loss: 2.0318 Acc: 0.9746\tval Loss: 2.0137 Acc: 0.9667\t\n",
      "Epoch 1456/1599:\ttrain Loss: 2.0234 Acc: 0.9958\tval Loss: 2.0156 Acc: 1.0000\t\n",
      "Epoch 1457/1599:\ttrain Loss: 2.0195 Acc: 0.9873\tval Loss: 2.0156 Acc: 0.9333\t\n",
      "Epoch 1458/1599:\ttrain Loss: 2.0273 Acc: 0.9788\tval Loss: 2.0150 Acc: 0.9667\t\n",
      "Epoch 1459/1599:\ttrain Loss: 2.0451 Acc: 0.9237\tval Loss: 2.0171 Acc: 0.9333\t\n",
      "Epoch 1460/1599:\ttrain Loss: 2.0278 Acc: 0.9661\tval Loss: 2.0178 Acc: 1.0000\t\n",
      "Epoch 1461/1599:\ttrain Loss: 2.0359 Acc: 0.9492\tval Loss: 2.0157 Acc: 1.0000\t\n",
      "Epoch 1462/1599:\ttrain Loss: 2.0283 Acc: 0.9873\tval Loss: 2.0165 Acc: 0.9667\t\n",
      "Epoch 1463/1599:\ttrain Loss: 2.0283 Acc: 0.9831\tval Loss: 2.0155 Acc: 0.9667\t\n",
      "Epoch 1464/1599:\ttrain Loss: 2.0272 Acc: 0.9915\tval Loss: 2.0246 Acc: 0.9000\t\n",
      "Epoch 1465/1599:\ttrain Loss: 2.0277 Acc: 0.9788\tval Loss: 2.0155 Acc: 0.9333\t\n",
      "Epoch 1466/1599:\ttrain Loss: 2.0275 Acc: 0.9831\tval Loss: 2.0174 Acc: 0.9000\t\n",
      "Epoch 1467/1599:\ttrain Loss: 2.0236 Acc: 0.9873\tval Loss: 2.0155 Acc: 0.9333\t\n",
      "Epoch 1468/1599:\ttrain Loss: 2.0274 Acc: 0.9831\tval Loss: 2.0148 Acc: 0.9333\t\n",
      "Epoch 1469/1599:\ttrain Loss: 2.0239 Acc: 0.9958\tval Loss: 2.0147 Acc: 0.9333\t\n",
      "Epoch 1470/1599:\ttrain Loss: 2.0279 Acc: 0.9915\tval Loss: 2.0146 Acc: 0.9333\t\n",
      "Epoch 1471/1599:\ttrain Loss: 2.0196 Acc: 0.9873\tval Loss: 2.0191 Acc: 0.8667\t\n",
      "Epoch 1472/1599:\ttrain Loss: 2.0314 Acc: 0.9831\tval Loss: 2.0140 Acc: 0.9667\t\n",
      "Epoch 1473/1599:\ttrain Loss: 2.0351 Acc: 0.9619\tval Loss: 2.0201 Acc: 0.9333\t\n",
      "Epoch 1474/1599:\ttrain Loss: 2.0319 Acc: 0.9703\tval Loss: 2.0142 Acc: 0.9667\t\n",
      "Epoch 1475/1599:\ttrain Loss: 2.0314 Acc: 0.9661\tval Loss: 2.0146 Acc: 0.9667\t\n",
      "Epoch 1476/1599:\ttrain Loss: 2.0318 Acc: 0.9703\tval Loss: 2.0139 Acc: 0.9667\t\n",
      "Epoch 1477/1599:\ttrain Loss: 2.0273 Acc: 0.9831\tval Loss: 2.0193 Acc: 0.8667\t\n",
      "Epoch 1478/1599:\ttrain Loss: 2.0358 Acc: 0.9746\tval Loss: 2.0142 Acc: 0.9333\t\n",
      "Epoch 1479/1599:\ttrain Loss: 2.0315 Acc: 0.9703\tval Loss: 2.0133 Acc: 0.9333\t\n",
      "Epoch 1480/1599:\ttrain Loss: 2.0274 Acc: 0.9788\tval Loss: 2.0200 Acc: 0.9333\t\n",
      "Epoch 1481/1599:\ttrain Loss: 2.0244 Acc: 0.9831\tval Loss: 2.0162 Acc: 0.9000\t\n",
      "Epoch 1482/1599:\ttrain Loss: 2.0275 Acc: 0.9788\tval Loss: 2.0131 Acc: 0.9667\t\n",
      "Epoch 1483/1599:\ttrain Loss: 2.0313 Acc: 0.9788\tval Loss: 2.0152 Acc: 0.9333\t\n",
      "Epoch 1484/1599:\ttrain Loss: 2.0363 Acc: 0.9534\tval Loss: 2.0162 Acc: 0.9333\t\n",
      "Epoch 1485/1599:\ttrain Loss: 2.0278 Acc: 0.9831\tval Loss: 2.0150 Acc: 0.9667\t\n",
      "Epoch 1486/1599:\ttrain Loss: 2.0314 Acc: 0.9873\tval Loss: 2.0149 Acc: 0.9667\t\n",
      "Epoch 1487/1599:\ttrain Loss: 2.0317 Acc: 0.9831\tval Loss: 2.0142 Acc: 0.9333\t\n",
      "Epoch 1488/1599:\ttrain Loss: 2.0189 Acc: 0.9958\tval Loss: 2.0138 Acc: 0.9333\t\n",
      "Epoch 1489/1599:\ttrain Loss: 2.0230 Acc: 0.9831\tval Loss: 2.0140 Acc: 0.9667\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1490/1599:\ttrain Loss: 2.0401 Acc: 0.9534\tval Loss: 2.0133 Acc: 0.9667\t\n",
      "Epoch 1491/1599:\ttrain Loss: 2.0404 Acc: 0.9534\tval Loss: 2.0174 Acc: 0.9333\t\n",
      "Epoch 1492/1599:\ttrain Loss: 2.0234 Acc: 0.9788\tval Loss: 2.0146 Acc: 0.9667\t\n",
      "Epoch 1493/1599:\ttrain Loss: 2.0269 Acc: 0.9746\tval Loss: 2.0174 Acc: 0.9000\t\n",
      "Epoch 1494/1599:\ttrain Loss: 2.0234 Acc: 0.9915\tval Loss: 2.0228 Acc: 0.9333\t\n",
      "Epoch 1495/1599:\ttrain Loss: 2.0354 Acc: 0.9788\tval Loss: 2.0163 Acc: 0.9667\t\n",
      "Epoch 1496/1599:\ttrain Loss: 2.0278 Acc: 0.9661\tval Loss: 2.0219 Acc: 0.9000\t\n",
      "Epoch 1497/1599:\ttrain Loss: 2.0193 Acc: 0.9958\tval Loss: 2.0169 Acc: 0.9000\t\n",
      "Epoch 1498/1599:\ttrain Loss: 2.0277 Acc: 0.9746\tval Loss: 2.0176 Acc: 0.9667\t\n",
      "Epoch 1499/1599:\ttrain Loss: 2.0271 Acc: 0.9958\tval Loss: 2.0144 Acc: 0.9333\t\n",
      "Epoch 1500/1599:\ttrain Loss: 2.0350 Acc: 0.9661\tval Loss: 2.0155 Acc: 0.9333\t\n",
      "Epoch 1501/1599:\ttrain Loss: 2.0356 Acc: 0.9576\tval Loss: 2.0132 Acc: 0.9667\t\n",
      "Epoch 1502/1599:\ttrain Loss: 2.0437 Acc: 0.9661\tval Loss: 2.0188 Acc: 0.9000\t\n",
      "Epoch 1503/1599:\ttrain Loss: 2.0281 Acc: 0.9831\tval Loss: 2.0132 Acc: 0.9667\t\n",
      "Epoch 1504/1599:\ttrain Loss: 2.0235 Acc: 0.9788\tval Loss: 2.0140 Acc: 0.9667\t\n",
      "Epoch 1505/1599:\ttrain Loss: 2.0365 Acc: 0.9661\tval Loss: 2.0137 Acc: 0.9667\t\n",
      "Epoch 1506/1599:\ttrain Loss: 2.0317 Acc: 0.9788\tval Loss: 2.0147 Acc: 0.9667\t\n",
      "Epoch 1507/1599:\ttrain Loss: 2.0226 Acc: 0.9831\tval Loss: 2.0139 Acc: 0.9667\t\n",
      "Epoch 1508/1599:\ttrain Loss: 2.0319 Acc: 0.9788\tval Loss: 2.0139 Acc: 0.9333\t\n",
      "Epoch 1509/1599:\ttrain Loss: 2.0276 Acc: 0.9703\tval Loss: 2.0159 Acc: 0.9000\t\n",
      "Epoch 1510/1599:\ttrain Loss: 2.0275 Acc: 0.9703\tval Loss: 2.0178 Acc: 0.9333\t\n",
      "Epoch 1511/1599:\ttrain Loss: 2.0359 Acc: 0.9746\tval Loss: 2.0142 Acc: 0.9667\t\n",
      "Epoch 1512/1599:\ttrain Loss: 2.0282 Acc: 0.9534\tval Loss: 2.0144 Acc: 0.9667\t\n",
      "Epoch 1513/1599:\ttrain Loss: 2.0196 Acc: 0.9915\tval Loss: 2.0174 Acc: 0.9333\t\n",
      "Epoch 1514/1599:\ttrain Loss: 2.0396 Acc: 0.9703\tval Loss: 2.0142 Acc: 0.9333\t\n",
      "Epoch 1515/1599:\ttrain Loss: 2.0408 Acc: 0.9703\tval Loss: 2.0162 Acc: 0.9000\t\n",
      "Epoch 1516/1599:\ttrain Loss: 2.0353 Acc: 0.9576\tval Loss: 2.0134 Acc: 0.9333\t\n",
      "Epoch 1517/1599:\ttrain Loss: 2.0313 Acc: 0.9661\tval Loss: 2.0237 Acc: 0.9333\t\n",
      "Epoch 1518/1599:\ttrain Loss: 2.0319 Acc: 0.9788\tval Loss: 2.0142 Acc: 0.9667\t\n",
      "Epoch 1519/1599:\ttrain Loss: 2.0319 Acc: 0.9788\tval Loss: 2.0143 Acc: 0.9667\t\n",
      "Epoch 1520/1599:\ttrain Loss: 2.0234 Acc: 0.9915\tval Loss: 2.0140 Acc: 0.9333\t\n",
      "Epoch 1521/1599:\ttrain Loss: 2.0195 Acc: 0.9831\tval Loss: 2.0140 Acc: 0.9333\t\n",
      "Epoch 1522/1599:\ttrain Loss: 2.0272 Acc: 0.9746\tval Loss: 2.0139 Acc: 0.9333\t\n",
      "Epoch 1523/1599:\ttrain Loss: 2.0398 Acc: 0.9576\tval Loss: 2.0151 Acc: 0.9667\t\n",
      "Epoch 1524/1599:\ttrain Loss: 2.0312 Acc: 0.9746\tval Loss: 2.0136 Acc: 0.9333\t\n",
      "Epoch 1525/1599:\ttrain Loss: 2.0318 Acc: 0.9534\tval Loss: 2.0137 Acc: 0.9333\t\n",
      "Epoch 1526/1599:\ttrain Loss: 2.0275 Acc: 0.9831\tval Loss: 2.0191 Acc: 0.9000\t\n",
      "Epoch 1527/1599:\ttrain Loss: 2.0312 Acc: 0.9746\tval Loss: 2.0178 Acc: 0.9333\t\n",
      "Epoch 1528/1599:\ttrain Loss: 2.0187 Acc: 0.9915\tval Loss: 2.0134 Acc: 0.9333\t\n",
      "Epoch 1529/1599:\ttrain Loss: 2.0237 Acc: 0.9958\tval Loss: 2.0146 Acc: 0.9333\t\n",
      "Epoch 1530/1599:\ttrain Loss: 2.0317 Acc: 0.9788\tval Loss: 2.0140 Acc: 0.9333\t\n",
      "Epoch 1531/1599:\ttrain Loss: 2.0188 Acc: 0.9831\tval Loss: 2.0139 Acc: 0.9667\t\n",
      "Epoch 1532/1599:\ttrain Loss: 2.0192 Acc: 0.9915\tval Loss: 2.0233 Acc: 0.9667\t\n",
      "Epoch 1533/1599:\ttrain Loss: 2.0317 Acc: 0.9661\tval Loss: 2.0146 Acc: 0.9667\t\n",
      "Epoch 1534/1599:\ttrain Loss: 2.0273 Acc: 0.9788\tval Loss: 2.0135 Acc: 0.9333\t\n",
      "Epoch 1535/1599:\ttrain Loss: 2.0198 Acc: 0.9788\tval Loss: 2.0141 Acc: 0.9667\t\n",
      "Epoch 1536/1599:\ttrain Loss: 2.0519 Acc: 0.9449\tval Loss: 2.0144 Acc: 0.9333\t\n",
      "Epoch 1537/1599:\ttrain Loss: 2.0312 Acc: 0.9746\tval Loss: 2.0129 Acc: 0.9333\t\n",
      "Epoch 1538/1599:\ttrain Loss: 2.0315 Acc: 0.9703\tval Loss: 2.0154 Acc: 0.9333\t\n",
      "Epoch 1539/1599:\ttrain Loss: 2.0273 Acc: 0.9831\tval Loss: 2.0145 Acc: 0.9333\t\n",
      "Epoch 1540/1599:\ttrain Loss: 2.0312 Acc: 0.9746\tval Loss: 2.0140 Acc: 0.9333\t\n",
      "Epoch 1541/1599:\ttrain Loss: 2.0185 Acc: 0.9915\tval Loss: 2.0143 Acc: 0.9333\t\n",
      "Epoch 1542/1599:\ttrain Loss: 2.0231 Acc: 0.9915\tval Loss: 2.0145 Acc: 0.9667\t\n",
      "Epoch 1543/1599:\ttrain Loss: 2.0270 Acc: 0.9661\tval Loss: 2.0123 Acc: 0.9667\t\n",
      "Epoch 1544/1599:\ttrain Loss: 2.0197 Acc: 0.9831\tval Loss: 2.0147 Acc: 0.9333\t\n",
      "Epoch 1545/1599:\ttrain Loss: 2.0239 Acc: 0.9915\tval Loss: 2.0175 Acc: 0.9333\t\n",
      "Epoch 1546/1599:\ttrain Loss: 2.0279 Acc: 0.9873\tval Loss: 2.0142 Acc: 0.9333\t\n",
      "Epoch 1547/1599:\ttrain Loss: 2.0232 Acc: 0.9746\tval Loss: 2.0158 Acc: 0.9333\t\n",
      "Epoch 1548/1599:\ttrain Loss: 2.0359 Acc: 0.9788\tval Loss: 2.0165 Acc: 0.9333\t\n",
      "Epoch 1549/1599:\ttrain Loss: 2.0283 Acc: 0.9788\tval Loss: 2.0162 Acc: 0.9333\t\n",
      "Epoch 1550/1599:\ttrain Loss: 2.0275 Acc: 0.9788\tval Loss: 2.0181 Acc: 0.9667\t\n",
      "Epoch 1551/1599:\ttrain Loss: 2.0322 Acc: 0.9619\tval Loss: 2.0159 Acc: 0.9333\t\n",
      "Epoch 1552/1599:\ttrain Loss: 2.0231 Acc: 0.9873\tval Loss: 2.0174 Acc: 0.9333\t\n",
      "Epoch 1553/1599:\ttrain Loss: 2.0314 Acc: 0.9703\tval Loss: 2.0144 Acc: 0.9667\t\n",
      "Epoch 1554/1599:\ttrain Loss: 2.0154 Acc: 0.9915\tval Loss: 2.0146 Acc: 0.9333\t\n",
      "Epoch 1555/1599:\ttrain Loss: 2.0311 Acc: 0.9788\tval Loss: 2.0154 Acc: 0.9000\t\n",
      "Epoch 1556/1599:\ttrain Loss: 2.0193 Acc: 0.9915\tval Loss: 2.0179 Acc: 0.9000\t\n",
      "Epoch 1557/1599:\ttrain Loss: 2.0320 Acc: 0.9788\tval Loss: 2.0156 Acc: 0.9667\t\n",
      "Epoch 1558/1599:\ttrain Loss: 2.0314 Acc: 0.9746\tval Loss: 2.0147 Acc: 0.9333\t\n",
      "Epoch 1559/1599:\ttrain Loss: 2.0202 Acc: 0.9831\tval Loss: 2.0175 Acc: 0.9333\t\n",
      "Epoch 1560/1599:\ttrain Loss: 2.0354 Acc: 0.9746\tval Loss: 2.0177 Acc: 0.9333\t\n",
      "Epoch 1561/1599:\ttrain Loss: 2.0317 Acc: 0.9831\tval Loss: 2.0136 Acc: 1.0000\t\n",
      "Epoch 1562/1599:\ttrain Loss: 2.0234 Acc: 0.9958\tval Loss: 2.0139 Acc: 0.9333\t\n",
      "Epoch 1563/1599:\ttrain Loss: 2.0241 Acc: 0.9873\tval Loss: 2.0141 Acc: 0.9667\t\n",
      "Epoch 1564/1599:\ttrain Loss: 2.0277 Acc: 0.9788\tval Loss: 2.0158 Acc: 0.9667\t\n",
      "Epoch 1565/1599:\ttrain Loss: 2.0152 Acc: 1.0000\tval Loss: 2.0166 Acc: 0.9667\t\n",
      "Epoch 1566/1599:\ttrain Loss: 2.0273 Acc: 0.9788\tval Loss: 2.0136 Acc: 0.9667\t\n",
      "Epoch 1567/1599:\ttrain Loss: 2.0235 Acc: 0.9873\tval Loss: 2.0129 Acc: 1.0000\t\n",
      "Epoch 1568/1599:\ttrain Loss: 2.0279 Acc: 0.9576\tval Loss: 2.0190 Acc: 0.9667\t\n",
      "Epoch 1569/1599:\ttrain Loss: 2.0230 Acc: 0.9831\tval Loss: 2.0142 Acc: 1.0000\t\n",
      "Epoch 1570/1599:\ttrain Loss: 2.0200 Acc: 0.9915\tval Loss: 2.0141 Acc: 0.9333\t\n",
      "Epoch 1571/1599:\ttrain Loss: 2.0318 Acc: 0.9703\tval Loss: 2.0137 Acc: 0.9667\t\n",
      "Epoch 1572/1599:\ttrain Loss: 2.0361 Acc: 0.9831\tval Loss: 2.0152 Acc: 0.9333\t\n",
      "Epoch 1573/1599:\ttrain Loss: 2.0268 Acc: 0.9958\tval Loss: 2.0139 Acc: 0.9667\t\n",
      "Epoch 1574/1599:\ttrain Loss: 2.0353 Acc: 0.9788\tval Loss: 2.0145 Acc: 1.0000\t\n",
      "Epoch 1575/1599:\ttrain Loss: 2.0279 Acc: 0.9746\tval Loss: 2.0139 Acc: 0.9333\t\n",
      "Epoch 1576/1599:\ttrain Loss: 2.0276 Acc: 0.9831\tval Loss: 2.0131 Acc: 0.9667\t\n",
      "Epoch 1577/1599:\ttrain Loss: 2.0271 Acc: 0.9831\tval Loss: 2.0146 Acc: 0.9667\t\n",
      "Epoch 1578/1599:\ttrain Loss: 2.0192 Acc: 0.9958\tval Loss: 2.0163 Acc: 0.9333\t\n",
      "Epoch 1579/1599:\ttrain Loss: 2.0393 Acc: 0.9703\tval Loss: 2.0142 Acc: 0.9667\t\n",
      "Epoch 1580/1599:\ttrain Loss: 2.0234 Acc: 0.9873\tval Loss: 2.0131 Acc: 1.0000\t\n",
      "Epoch 1581/1599:\ttrain Loss: 2.0161 Acc: 0.9958\tval Loss: 2.0189 Acc: 0.9000\t\n",
      "Epoch 1582/1599:\ttrain Loss: 2.0352 Acc: 0.9703\tval Loss: 2.0156 Acc: 0.9667\t\n",
      "Epoch 1583/1599:\ttrain Loss: 2.0329 Acc: 0.9788\tval Loss: 2.0160 Acc: 0.9000\t\n",
      "Epoch 1584/1599:\ttrain Loss: 2.0233 Acc: 0.9746\tval Loss: 2.0156 Acc: 0.9333\t\n",
      "Epoch 1585/1599:\ttrain Loss: 2.0199 Acc: 0.9915\tval Loss: 2.0266 Acc: 0.9333\t\n",
      "Epoch 1586/1599:\ttrain Loss: 2.0320 Acc: 0.9576\tval Loss: 2.0158 Acc: 0.9333\t\n",
      "Epoch 1587/1599:\ttrain Loss: 2.0199 Acc: 0.9788\tval Loss: 2.0167 Acc: 0.9000\t\n",
      "Epoch 1588/1599:\ttrain Loss: 2.0279 Acc: 0.9873\tval Loss: 2.0228 Acc: 0.9000\t\n",
      "Epoch 1589/1599:\ttrain Loss: 2.0278 Acc: 0.9661\tval Loss: 2.0238 Acc: 0.9333\t\n",
      "Epoch 1590/1599:\ttrain Loss: 2.0277 Acc: 0.9915\tval Loss: 2.0155 Acc: 0.9667\t\n",
      "Epoch 1591/1599:\ttrain Loss: 2.0234 Acc: 0.9831\tval Loss: 2.0152 Acc: 0.9667\t\n",
      "Epoch 1592/1599:\ttrain Loss: 2.0316 Acc: 0.9703\tval Loss: 2.0155 Acc: 0.9667\t\n",
      "Epoch 1593/1599:\ttrain Loss: 2.0199 Acc: 0.9915\tval Loss: 2.0162 Acc: 0.9333\t\n",
      "Epoch 1594/1599:\ttrain Loss: 2.0395 Acc: 0.9788\tval Loss: 2.0181 Acc: 0.9333\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1595/1599:\ttrain Loss: 2.0313 Acc: 0.9788\tval Loss: 2.0185 Acc: 0.9667\t\n",
      "Epoch 1596/1599:\ttrain Loss: 2.0357 Acc: 0.9576\tval Loss: 2.0152 Acc: 0.9667\t\n",
      "Epoch 1597/1599:\ttrain Loss: 2.0316 Acc: 0.9788\tval Loss: 2.0130 Acc: 0.9333\t\n",
      "Epoch 1598/1599:\ttrain Loss: 2.0275 Acc: 0.9831\tval Loss: 2.0153 Acc: 0.9333\t\n",
      "Epoch 1599/1599:\ttrain Loss: 2.0399 Acc: 0.9661\tval Loss: 2.0138 Acc: 0.9333\t\n",
      "Training complete in 66m 57s\n",
      "Best val Acc: 1.000000\n"
     ]
    }
   ],
   "source": [
    "model = VaniliaCNN()\n",
    "model, history = train_model(model=model, optimizer=Adam(model.parameters(), lr=1e-4), epochs=1600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efca47cf240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efca4593c18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(model, history, 'vanilla_pytorch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
